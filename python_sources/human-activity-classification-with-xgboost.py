#!/usr/bin/env python
# coding: utf-8

# ## Ibrahim Abu Alhaol, Ottawa, Canada 
# * [Linkedin](https://www.linkedin.com/in/abualhaol/)
# * [github](https://github.com/alhaol)
# * [kernal](https://www.kaggle.com/abualhaol/human-activity-classification-smart-phone)
# 

# ### Data set information
# [Human activity recognition using smartphones](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)
# 
# * The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. 
# * Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. 
# * Using its embedded accelerometer and gyroscope, 3-axial linear acceleration and 3-axial angular velocity were captured at a constant rate of 50Hz. 
# 
# 

# ### Import Libraries 

# In[3]:


import pandas as pd 
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix,precision_recall_fscore_support, auc
import warnings
warnings.filterwarnings('ignore')


# ### Read Data 

# In[6]:


dataset=pd.read_csv('../input/tidyHARdata.csv')
dataset.drop(dataset.columns[0], axis=1, inplace=True)
dataset.head(10)


# In[7]:


print (f'Number of features = {len(dataset.columns)}')


# In[12]:


print (f'Number of labels = {dataset.Activity.nunique()}')


# In[13]:


print (f'Labels : {dataset.Activity.unique()}')


# In[14]:


# Split data into X and y
X = dataset[dataset.columns[:-1]] ## Remove SubjectID and Activity 
Y = dataset[dataset.columns[-1]]


# In[15]:


# split data into train and test sets
seed = 40
test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)


# In[16]:


# fit model no training data
model = XGBClassifier(n_jobs=2) # using two processors 
model.fit(X_train, y_train)


# In[17]:


from sklearn.feature_selection import SelectFromModel
sfm = SelectFromModel(model, prefit=True)


# In[18]:


X_train_new = sfm.transform(X_train)
X_test_new = sfm.transform(X_test)

print("Original num features: {}, selected num features: {}"
      .format(X_train.shape[1], X_train_new.shape[1]))


# In[19]:


import numpy as np
indices = np.argsort(model.feature_importances_)[::-1]
for idx, i in enumerate(indices):
    print("{}.\t{} - {}".format(idx, X_train.columns[i], model.feature_importances_[i]))


# In[20]:


### Retrain on the important features
# fit model no training data
model = XGBClassifier(n_jobs=2) # using two processors 
model.fit(X_train_new, y_train)


# In[21]:


# make predictions for test data
y_pred = model.predict(X_test_new)
y_pred_prop = model.predict_proba(X_test_new)
#predictions = [round(value) for value in y_pred_prop]
predictions=y_pred.copy()


# In[22]:


# Confusion matrix
conf= confusion_matrix(y_test, predictions)


# In[23]:


Labels=list(dataset.Activity.unique())


# In[24]:


pd.DataFrame(conf,columns=Labels, index=Labels)


# In[25]:


### precsion, recall, fscore, support 


# In[26]:


pr_rec_f_supp=precision_recall_fscore_support(y_test, predictions)
DF_report=pd.DataFrame({'Precision':list(pr_rec_f_supp[0]),
                        'Recall':list(pr_rec_f_supp[1]),
                        'F-Score':list(pr_rec_f_supp[2]),
                        'Support':list(pr_rec_f_supp[3])}, index=Labels)
DF_report


# In[27]:


### ROC and AUC 


# In[ ]:





# In[28]:


#!pip install scikit-plot
import scikitplot as skplt
import matplotlib.pyplot as plt
plt.figure(figsize=(20,20))
y_true = y_test# ground truth labels
y_probas =y_pred_prop # predicted probabilities generated by sklearn classifier
skplt.metrics.plot_roc_curve(y_true, y_probas)
plt.show()


# In[ ]:





# In[29]:


### ROC_AUC


# In[30]:


import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from scipy import interp

# Binarize the output
y = label_binarize(Y, classes=Labels)
n_classes = y.shape[1] # Number of classes 

# Add noisy features to make the problem harder
#random_state = np.random.RandomState(0)
#n_samples, n_features = X.shape
#X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]

# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,
                                                    random_state=0)


# In[33]:



# Learn to predict each class against the other
model = XGBClassifier(n_jobs=10)
classifier = OneVsRestClassifier(model)
y_score = classifier.fit(X_train, y_train).predict(X_test)

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])


# In[34]:


roc_auc


# In[ ]:





# In[ ]:





# In[ ]:




