#!/usr/bin/env python
# coding: utf-8

# In[ ]:


ENABLE_MULTIPROCESSING = True # This allows to solve 4 tasks at the same moment.

import numpy as np

import time
from collections import defaultdict
import os
import random
import copy
from pathlib import Path
import json
import pandas as pd
import multiprocessing

data_path = Path('../input/abstraction-and-reasoning-challenge/')

training_path = data_path / 'training'
evaluation_path = data_path / 'evaluation'
test_path = data_path / 'test'

train_tasks = { task.stem: json.load(task.open()) for task in training_path.iterdir() }
valid_tasks = { task.stem: json.load(task.open()) for task in evaluation_path.iterdir() }
test_path = { task.stem: json.load(task.open()) for task in test_path.iterdir() }

train_task_ids = np.sort(list(train_tasks.keys()))
valid_task_ids = np.sort(list(valid_tasks.keys()))
test_task_ids = np.sort(list(test_path.keys()))

def load_data(p, phase=None):
    """
        Load task data

    """
    if phase in {'training', 'test', 'evaluation'}:
        p = data_path / phase / p

    task = json.loads(Path(p).read_text())
    dict_vals_to_np = lambda x: {k: np.array(v) for k, v in x.items()}
    assert set(task) == {'test', 'train'}
    res = dict(test=[], train=[])
    for t in task['train']:
        assert set(t) == {'input', 'output'}
        res['train'].append(dict_vals_to_np(t))
    for t in task['test']:
        if phase == 'test':
            assert set(t) == {'input'}
        else:
            assert set(t) == {'input', 'output'}
        res['test'].append(dict_vals_to_np(t))

    return res

import numpy as np

from tqdm.notebook import tqdm
from PIL import Image, ImageDraw
import time
from collections import defaultdict
import os
import json
import random
import copy
import networkx as nx
from pathlib import Path

import matplotlib.colors as colors
import matplotlib.pyplot as plt

from itertools import product
import pandas as pd
import multiprocessing
import subprocess

data_path = Path('../input/abstraction-and-reasoning-challenge/')

cmap_lookup = [
    '#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',
    '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'
]

cmap_lookup = [np.array([int(x[1:3], 16), int(x[3:5], 16), int(x[5:], 16)]) for x in cmap_lookup]

def cmap(x):
    """
        Translate a task matrix to a color coded version

        arguments
            x : a h x w task matrix
        returns
            a h x w x 3 matrix with colors instead of numbers
    """
    y = np.zeros((*x.shape, 3))
    y[x < 0, :] = np.array([112, 128, 144])
    y[x > 9, :] = np.array([255, 248, 220])
    for i, c in enumerate(cmap_lookup):
        y[x == i, :] = c
    return y

def draw_one(x, k=20):
    """
        Create a PIL image from a task matrix, the task will be
        drawn using the default color coding with grid lines

        arguments
            x : a task matrix
            k = 20 : an up scaling factor
        returns
            a PIL image

    """
    img = Image.fromarray(cmap(x).astype(np.uint8)).resize((x.shape[1] * k, x.shape[0] * k), Image.NEAREST)

    draw = ImageDraw.Draw(img)
    for i in range(x.shape[0]):
        draw.line((0, i * k, img.width, i * k), fill=(80, 80, 80), width=1)
    for j in range(x.shape[1]):
        draw.line((j * k, 0, j * k, img.height), fill=(80, 80, 80), width=1)
    return img

def vcat_imgs(imgs, border=10):
    """
        Concatenate images vertically

        arguments:
            imgs : an array of PIL images
            border = 10 : the size of space between images
        returns:
            a PIL image
    """

    h = max(img.height for img in imgs)
    w = sum(img.width for img in imgs)
    res_img = Image.new('RGB', (w + border * (len(imgs) - 1), h), color=(255, 255, 255))

    offset = 0
    for img in imgs:
        res_img.paste(img, (offset, 0))
        offset += img.width + border

    return res_img

def plot_task(task):
    n = len(task["train"]) + len(task["test"])
    fig, axs = plt.subplots(2, n, figsize=(n * 4, 8))
    plt.subplots_adjust(wspace=0, hspace=0)
    fig_num = 0

    def go(ax, title, x):
        ax.imshow(draw_one(x), interpolation='nearest')
        ax.set_title(title)
        ax.set_yticks([])
        ax.set_xticks([])

    for i, t in enumerate(task["train"]):
        go(axs[0][fig_num], f'Train-{i} in', t["input"])
        go(axs[1][fig_num], f'Train-{i} out', t["output"])
        fig_num += 1
    for i, t in enumerate(task["test"]):
        go(axs[0][fig_num], f'Test-{i} in', t["input"])
        try:
            go(axs[1][fig_num], f'Test-{i} out', t["output"])
        except:
            go(axs[1][fig_num], f'Test-{i} out', np.zeros_like(t["input"]))
        fig_num += 1

    plt.tight_layout()
    plt.show()


# # How can we solve these tasks using one algorithm?

# In[ ]:


name = '070dd51e'
task = load_data(f'{name}.json', phase='evaluation')

plot_task(task)


# In[ ]:


name = '0d87d2a6'
task = load_data(f'{name}.json', phase='evaluation')

plot_task(task)


# In[ ]:


name = '08ed6ac7'
task = load_data(f'{name}.json', phase='training')

plot_task(task)


# This is the part of the 10th place solution that is described here:
# https://www.kaggle.com/c/abstraction-and-reasoning-challenge/discussion/154294
# 
# Here you can see everything implemented via python. All DSL-commands are presented here. For the competition we used the C++ version of the rules written by my teammate @artyomp. This allows algorithm to learn much faster. 

# > # **DSL**

# "python_trace_param_automata" applies sequence of rules to the input grid. What are these commands are written below.

# In[ ]:



encoded_files = {
"algorithms.h": "H4sIAP57zl4C/81XTY/aSBC9+1dUWIUxwQFyHZhIqz2ttEmkDUgrsZbV2G1oxm4Tu814kvDft/rDxm3MiI1yCAfs7n5VXe9V9YenU2c6hc9ZSqEsaFwmQJJtljOxS4sJDjnOb4ecbFMCGQ+p4ziCpoeECAoL8XygnKDh8r1zzFgEh5xxEbCUbKkbZrwQsIRhRATxAAdgR9l2J/T7E4vEbuR8cwB/cZaDK3uf4QFmc3wsDBjfx+MRaJj8HUoR7kju3n2/G82dprvxUGkPFXpQU+Cr7UA5kXHG7uB1NPBAxrd+hjcaD2OofPRcQ09Oe+rCHXwfmNGTc7pVjCBicdxVpGkSnokdzX8xjVgMbo808OoBTMBd0ToO/qfQSlKgSUH7/NSM3t51TX5apkiek+dzko40bKQ3NAoR0RzzNFjDoBZWiaqNSCkyFPUepGmLxIX56whQjqqJrn8S/18uZ8FhXJ/90ePANQKLOMmIeG94IPCb/GvnRJMwnVdpNBmM65hrN0pj3/iwBC55wbacRpBkfAsrS+UNEwUVZirken+vexYrjBWfN2teykpmupIZVjLaTgr2lbojbNvlLEtZDgtaCJeNuoV6JT/M2gVuy1QjwmWRlQesfxqkpGJpmbqKOhFZysLFEqmb/uBIkpK2NgfVriNeooj0qDHI3LLRwT7tWELBbcEWoJ/DIbyyDCZhlh5ITgNa4driuEs9UfLYMvW0ZaOXtYxaBD1o3jHXOi9c0LygoWAZD1RWbEJFzVDJUPIsRylpFNSFIMgmaVhLh2FW4r9Mdv+yGx5lwSrX7fRqs/EDKIcT1XSP9sLLqShzrqHzqxRVKTeF/WM8W5V+G0FFDR3dwk0VN6J+CrlOuG2aP8SwM5jT4maaiJ3IHQNHvC7VXq7K+fVds4ctIpcQswRJ3souJcXj6LynLvWs06m1n/byMoB6X5KOWoRsQM3/UBa7YEPCR5PgFuRUN06t2dtK2Jvz1WWr9qgtFUHJ2ZcS9wK8AAZ6vRSCCBbq42WBZh9XH4I/Pv316e/PKESYJVleeE26LLBcIxd4dNnIuqp1PhfK9bninH5xzx0ezF48ELTja2eCdLbWkDXz/fHYKiXNaoICSuvznKbgNIne4evxnGEXwejpMA5EMysQVXdFlssTU4W0oVvG3ZFXh0h5JFvroa+uduamvUHvdRUopsQHLeB648/h9GKgxvMV4TR3Haty2ATvW5FLpxzPGo4741eaZwXiFZuYYchGwRYb1TZsZiN4CzZk3pcYy39vbrqI00tHtCz/DZpHjG/xpdLKDFPG8+zJg6aFQTQtUrXHSKXGmk2Ecbwm1eopDJoHUuvVnx+XwYff//FUz97uIZXCzPTrvnssdBOmZpkUO3Kg65l/WeqNjfaED9vmHdrs+78AFMxlHuxHWECzvjt+zUglFxuu6rDvTw3WMNNYUrmqA7H4NfCuD2+0sXzvZTT9vvdd3xLb4/vUf7PTmZY3K01B59q09yobZlyHrfNt2ntZXf8Btumlo04PAAA=",
"dsl.h": "H4sIAP57zl4C/71WTW/iMBC951fMaqXIKVlE9wgFqdJedqWeelkJIZQGFxwgjmyn3W7Ff9/xRxJDEmirVXNxMDNvZt4bjxN8LUSy3ifA85QGQVBKlq9hlahkqV4KClNIN4mYBEG6S6SE21LxfaJ4fq8SReE1KMqHHUvHAeBjfaXiiEgrd4mGLF0mQiQvNzVuDHe3v5c/ft7dw1X9OsMwGucIIeU7jvHt/mo8tkAly1UM32cgN0lB0c8YHGdHtBGwGMyaRTC21uQV97JDhNmDe0yQoaCS/aXEGM1HC8zMvl4vosmJ6SPb7cjIbR9sdPqnQCqYOk0j5blUncmHBr9JzP381LwyyfPr6/H4F64QsrwolZ8Bik6FImZ/yKTVkUSRk8pGPsVxhUIo+LPEHrDeZm/JFN1LcpR4rzvWNEJ3jYJ1nwLUCEbfDWXrjXLWQ0NYFMMzW6mNbmJEcptN5JrQqfOOa2Jxy7gelelpYXGvnJ+fzCMX4DoPQUYTXG6cGb4PBj65HsGmRrboofgyzRVNbNHH83EwRwZMXaGn0ZoyMltGhmVYSiBrV9GdIIRPyc5mNs8Wkw4PpHTOkEfL5wAyzTw6DTHyEteSnpZwCI7fXJM3EyvkBRXY5YJErQnQJC2oKkXuZVArr5OYdEOfQbbFvxvfzbXzI3IGa6qWSKKL2o5WnVLUqGpqv88v4mNXE2+mBGe7oDLsbAREmhsRz1buseuRhb5HxL+NFwxE+lRwvPhZf5CX0eLiIa8MO4+55oX9B1467jn8f8+fqG4Q6V82D0xJqm6aasw4bpPUQpOv9WT8VpGUJlKZi2tmRtUw5WWucEg1I/PQz08M2zfSxB6BfHGDrGvGvL8hPQHINtZNMgVypTZMRkR/B0TtsXQIWlvbwaB/DF3q4265sBEuyKUt3iWXd391CafxauEO/ce8lusiuUYuDYtn/rxcbz0nvlwoz/aT5TLrA+e7etbjDelUOiE+THKuNlT0zn5Tp75gneHQboShnQH+P95HrsvvibMVFIJprVoBzP6S7fEjmRjXGNotUH8EotL/AAW9Jq3mCwAA",
"static_array.h": "H4sIAP57zl4C/9VWUW+bMBB+969wNamCpmuy15DsT4y3KEIOOI1VYzMwXZIp/32HbRwToFHabtL8ArLvvu/u893BdIqmU/xDEcVSTMqSHHDKSVU9wTZCX4qSPOcES5FShJCiecGJonihDgUVJKc4fsQ1EwrnZJ9U7Ei/I+2OK42YGMTfCMOKsVkZUSRZtQ7rSB9qEFjNVhIhVNQbztK5PqP7At6Z6oAGjUN1xEs8Cy1Bs0raIATVMTS4J6QfA56PENAr4W85N2vLOA8au3G8VIqqG9wCZHGK4HsipNrRcoDKnjzptIHiTCtLHGhRWJNiBI+FFQezycSHOmvK1mDbQrZb51ROfgavkmUmOS3DpY7v5wewEcqrOsmClkQB8/I/0tSjV3Up8IPasapTLDF+2NBnJgJgaK00UmT1AQMqst4xnrTRdQT04MzGMKgzNtBDpj0CsG4ORgN1mNbqLX4ttL6Qnp0jbew2UnIMg0Ud+oZ3w/m7Qlmt7X1me+fr7gPGEC1VAGftNXtt7Ue8ApP1xY0NU3wKuO48W6saWtBfuqoH8NsjvFi64veINDHUZ2vW4TlPa81ia9hOaaf8uefGmq7j6DXepd4aDvKCeFRZ0/c3XoNxv/T677YGBPeODjouwnlCf9aEJ0oGdvD/ywQupuK1mDVXKmuhxoLVFibY2ccinXxWpG35ZPP5thapYlIsGk2DOIS64STfZOQvJ2JIgjaf8JZMbuyXu4/2SzvjAv3F8Ko87I+Loq52yYakL0Hvp6V2P0Jm2Eb93xmY89+8faNOdex8rd3kK2RhmHyS2N6QOehTmDH/tUMzInOMt6WEahkVxOgRrmaXM9lGdcXNzEQIxbmfIvQH7i1/GecKAAA=",
"dsl_tables.h": "H4sIAP57zl4C/2VVy27bOBRdj79C6DpogFl22gFkm7GJ0qKHppNmNoQs0RJRmtRIVFK36L8Pn4qSLATD95x77oOH0u3t4vY2o60YsrOQPLO/5Wh0wxXvS8Pr7NzrS1YP8mPVdTdZrTOlTVa1pWr4R5u6WAym/vRpVLqvec9rdim7zz40mF6oxqaUpmTm2vG/sxD6k6vxkn3Jfi3++PWh0t2VVVrqnp2urBY9r4zQ6sNNtsL7R7bCCBO2fGRrSMCKQlz8vglpvW2QVS2vvnsuKQBhqy1YfQ0EdWontFhu51AoMqFBeU4Q6g0FFu9JoedauJlO49Sza3cND5TA5fGl3bMUnYXvENyHQK+N3a4NEUxzClJjUYwzt3V28jv1LUZBwO4I3rElJmtA5n2c7SOUXckwdXFnH1jYtRyiel8+MykUd5Q1yR8YggV4CzKj5zCj+F1vvuLwui1fMmqNSpirhY8FpI8hNHRSGHfArY0f9ghSd6bbN+DzHHwIoLVTKGixXb4PheLkve4Yv3S+2IrgPQO7farowbNoxp4n9A5ujgQk2e+ctVr6Zezyr4BtMUrLaPryKYywIfn9NETFpfTrBQhFZijggkE8hu0Vaa3RnfUw3cJi8+qoppx4TvNMV+NZDJz5gV2lB3gALI2sR9ONxkr0g7E4PtL9kVoFcqCvCLKc4yhPcClFo1hXGsN759ccwU3B9jmlgESr2js8Vt6ZYH1cTeuy+2SXURrRyatfmV0p2x0RhXsU92O08zjF0eInbYy+2MgSU4p3ISj52TWGwF3sqBdN6yIEbrZ00mGRZ8XYCzcoJizIzmCXl+Rc4kwyZiY0ps4I/In31+eWe7eAe0AeH7YgmaXVvfiplSmlBbeYwH9xQXMUQJtoROUhm0bhKgE268nfXptxn25rLcpGK89ew3yDi8RWWnHvlwKkluPlf3fZk3MiTzQN96e9hJsNSCc9XEopQ/ywyxECLxaQ/uDR9K7jP8IrDnyLZxTM8+KaMMY0Q6vjVNFy7l/6U6raqRfruNb/Rj8r+OeYBv3h+d9SQiP1qZSsH6Ubf4PwMkeMHBF4BQtlDVv6L8MbKiysdXP/ZZilVWWirfIU/v3XYvE/VDOS0O4GAAA=",
"helpers.h": "H4sIAP57zl4C/61UbWvbMBD+rl9xq8kqBZO0X+1tkC3tyMi8kXZjHwpCtWVXw5aDXkqh9L/vJCUlY9lgYyYkd+e7e57npMt8TuZzuBoHCd7K1vdgRu+UlnaGLwjJtkZ0g4BR15IQ4q3SHXilHbwGr63qtGwA3ZKQetTWQduPwsHl+pp/XHzDJOuaotB+kEbVvFeDcvZVzHlTFIN4oAwridI9QsL9qBqojbB3lAHnwjmjbr2TnFOqRyOdN5phwZF08kgy1epGtlhY90J3nBPAZ0oD2SmDMyRzVpJM6ka18RXnt171KJY7I7aByRMJ09g3qpYXb7+8J5mPnrBWGkcyQCegJ5+++1QtGdzEhqoF+iJFGDzuguHZGiTR0pNUo0YNpxN7Cq1QPY4P5zWxxaS50Sc5ZKE8R26Xq/UF58Faryq0WHnQcKd6H3qKtGVvZTSOUUwZUTshcXJNZEXTsdV3wsDUOpPDYaCRtv450iLlPJw4hDMIcz8UGHWgGvxENSk7ZOaQeiFEGvQhh9DuXvT/C7v5DTZC/IqdAL7bUZ+fF8UH/IWXwfs3MvG6o8awJraModBs1vhhSy0r/3Zas5pjN8oS72x3sMvPm1V1Tb8uNmwvA228PPH7yN2JO+bACLwAu3mj3T3TTruV2Ick3L9Jyoi4+9q4uPQPRfO0/3SzqJbhDyDS/gHFLtt6ZAQAAA==",
"json11.hpp": "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",
"json11.cpp": "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",
"dsl.cpp": "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",
"setup.py": "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",
}

import base64, gzip
from pathlib import Path

for path, encoded in encoded_files.items():
    print('unpacking', path)
    Path(path).write_bytes(gzip.decompress(base64.b64decode(encoded)))
    

import subprocess

print('invoking pip install')
res = subprocess.run('pip install . --no-color --verbose --no-deps --disable-pip-version-check'.split(),
                     capture_output=True)
print('res', res.returncode)
print('pip\'s stdout')
print(res.stdout.decode())
print('pip\'s stderr')
print(res.stderr.decode())
from dsl import cpp_trace_param_automata


# In[ ]:


def python_trace_param_automata(input, params, n_iter, n_hidden):

    # We never use it. We just store zeros and pass it through all the commands. 
    # We thought we could use it later but we actually never did.
    hidden = np.zeros((n_hidden, *input.shape)) if n_hidden > 0 else None 

    # This is the program that containes these 4 parts. All of them are trained with genetic algorithm.
    global_rules, ca_rules, split_rule, merge_rule = params

    # If there is some split rule, the algorithm makes many grids from one input grid (for example it splits it by figures.)
    grids = apply_split_rule(input, hidden, split_rule)
    
    # At firsy we apply the global rules
    for rule in global_rules:
        for i, (inp, hid) in enumerate(grids):
            # If it just the rule grid->grid we apply it to all grids or to (some grid) - that is parametrized. 
            if rule['macro_type'] == 'global_rule':
                if rule['apply_to'] == 'all' or                     (rule['apply_to'] == 'index' and i == rule['apply_to_index']%len(grids) or
                    (rule['apply_to'] == 'last' and i == len(grids) - 1)):
                    grids[i] = apply_rule(inp, hid, rule)
            
            # There are some rules [grid] -> [grid], so we apply it to the whole set.
            elif rule['macro_type'] == 'global_interaction_rule':
                grids = apply_interaction_rule(grids, rule)
    
    # Then we apply cellular automata rules to the grids
    for i, (input, hidden) in enumerate(grids):
        for _ in range(n_iter):
            output, hidden = compute_parametrized_automata(input, hidden, ca_rules)

            if np.array_equal(input, output):
                break

            input = output

        grids[i] = (output, hidden)
        
    # Then we merge all grids into one output
    output = apply_merge_rule(grids, merge_rule, split_rule)

    return output

# We also have C++ version of the "python_trace_param_automata" command. 
# It's absolutely the same as python version that are written here but works 100x faster.

def trace_param_automata(input, params, n_iter, n_hidden):
    # output = python_trace_param_automata(input, params, n_iter, n_hidden)
    output = cpp_trace_param_automata(input, params, n_iter)
    
    return [[output]]


# ## Interaction rule
# 
# There is only one such command in our DSL since we added interaction rules only in the last days of the competition.
# This rule tries to copy figure from one grid to another grid, while making sure that it fits correctly, and chooses the best position. 
# 
# It is used to solve tasks like this:

# In[ ]:


name = '2c737e39'
task = load_data(f'{name}.json', phase='evaluation')

plot_task(task)


# In[ ]:


def apply_interaction_rule(grids, rule):
    if rule['type'] == 'align_pattern':
        if len(grids) > 5:
            return grids
        for index_from in range(len(grids)):
            for index_to in range(index_from+1, len(grids)):
                input_i = grids[index_from][0]
                input_j = grids[index_to][0]

                i_nonzero_rows = np.arange(input_i.shape[0])[np.max(input_i>0, axis=1)]
                i_nonzero_columns = np.arange(input_i.shape[1])[np.max(input_i>0, axis=0)]
                j_nonzero_rows = np.arange(input_j.shape[0])[np.max(input_j>0, axis=1)]
                j_nonzero_columns = np.arange(input_j.shape[1])[np.max(input_j>0, axis=0)]
                if i_nonzero_rows.shape[0] == 0 or i_nonzero_columns.shape[0] == 0 or                                 j_nonzero_rows.shape[0] == 0 or j_nonzero_columns.shape[0] == 0:
                    continue
                i_minrow = np.min(i_nonzero_rows)
                i_mincol = np.min(i_nonzero_columns)
                i_maxrow = np.max(i_nonzero_rows) + 1
                i_maxcol = np.max(i_nonzero_columns) + 1
                j_minrow = np.min(j_nonzero_rows)
                j_mincol = np.min(j_nonzero_columns)
                j_maxrow = np.max(j_nonzero_rows) + 1
                j_maxcol = np.max(j_nonzero_columns) + 1

                figure_to_align = input_i[i_minrow:i_maxrow, i_mincol:i_maxcol]
                figure_target = input_j[j_minrow:j_maxrow, j_mincol:j_maxcol]

                best_fit = 0
                best_i_fit, best_j_fit = -1, -1

                if figure_to_align.shape[0] < figure_target.shape[0] or figure_to_align.shape[1] < figure_target.shape[1]:
                    continue
                else:
                    for i_start in range((figure_to_align.shape[0] - figure_target.shape[0])+1):
                        for j_start in range((figure_to_align.shape[1] - figure_target.shape[1])+1):
                            fig_1 = figure_to_align[i_start:(i_start + figure_target.shape[0]), j_start:(j_start + figure_target.shape[1])]
                            if np.logical_and(np.logical_and(figure_target > 0, figure_target!=rule['allow_color']), figure_target != fig_1).any():
                                continue
                            fit = np.sum(figure_target==fig_1)
                            if fit > best_fit:
                                best_i_fit, best_j_fit = i_start, j_start
                                best_fit = fit

                    if best_fit == 0:
                        continue

                    imin = j_minrow-best_i_fit
                    imax = j_minrow-best_i_fit + figure_to_align.shape[0]
                    jmin = j_mincol - best_j_fit
                    jmax = j_mincol - best_j_fit + figure_to_align.shape[1]

                    begin_i = max(imin, 0)
                    begin_j = max(jmin, 0)
                    end_i = min(imax, input_j.shape[0])
                    end_j = min(jmax, input_j.shape[1])

                    i_fig_begin = (begin_i-imin)
                    i_fig_end = figure_to_align.shape[0]-(imax-end_i)
                    j_fig_begin = (begin_j-jmin)
                    j_fig_end = figure_to_align.shape[1]-(jmax-end_j)
                    if rule['fill_with_color'] == 0:
                        input_j[begin_i:end_i, begin_j:end_j] = figure_to_align[i_fig_begin:i_fig_end, j_fig_begin:j_fig_end]
                    else:
                        for i, j in product(range(end_i-begin_i + 1), range(end_j-begin_j + 1)):
                            if input_j[begin_i + i, begin_j + j] == 0:
                                input_j[begin_i + i, begin_j + j] = rule['fill_with_color'] * (figure_to_align[i_fig_begin + i, j_fig_begin + j])


    return grids


# #### Connected components in the grid
# This is the function that computes connected components (figures) on the grid. It is also parametrized. It is used is some rules and in other parts of the algorithm.

# In[ ]:


def get_connectivity_info(color: np.array, ignore_black = False, von_neumann_only = False, edge_for_difcolors = False):

    # UnionFind structure allows us to detect all connected areas in a linear time.
    class UnionFind:
        def __init__(self) -> None:
            self.area = np.ones(color.size)
            self.parent = np.arange(color.size)
        def find(self, x: int) -> int:
            if self.parent[x] != x:
                self.parent[x] = self.find(self.parent[x])
            return self.parent[x]
        def union(self, u: int, v: int) -> None:
            root_u, root_v = self.find(u), self.find(v)
            if root_u != root_v:
                area_u, area_v = self.area[root_u], self.area[root_v]
                if area_u < area_v:
                    root_u, root_v = root_v, root_u
                self.parent[root_v] = root_u
                self.area[root_u] = area_u + area_v

    union_find = UnionFind()
    neighbours = [[-1, 0], [0, -1], [1, 0], [0, 1]]
    if not von_neumann_only:
        neighbours.extend([[-1, -1], [1, -1], [1, 1], [-1, 1]])
    nrows, ncols = color.shape
    for i in range(nrows):
        for j in range(ncols):
            for s, t in neighbours:
                u, v = i + s, j + t
                if u >= 0 and u < nrows and v >= 0 and v < ncols and                         (color[u, v] == color[i, j] or (edge_for_difcolors and (color[u, v]>0) == (color[i, j]>0))):
                    union_find.union(u * ncols + v, i * ncols + j)
    # for every cell: write down the area of its corresponding area
    communities = defaultdict(list)
    for i, j in product(range(nrows), range(ncols)):
        if not ignore_black or color[i, j] > 0:
            communities[union_find.find(i * ncols + j)].append((i, j))
    # the result is always sorted for consistency
    communities = sorted(communities.values(), key = lambda area: (len(area), area))
    return communities


# # Global rule 
# These are grid->grid rules. There are many of them, so this function is pretty big.

# In[ ]:


def apply_rule(input, hidden_i, rule):
    output = np.zeros_like(input, dtype=int)
    hidden = np.zeros_like(input)
    output[:, :] = input[:, :]
    if rule['type'] == 'macro_multiply_k':
        output = np.tile(output, rule['k'])
    elif rule['type'] == 'flip':
        if rule['how'] == 'ver':
            output = output[::-1, :]
        elif rule['how'] == 'hor':
            output = output[:, ::-1]

    elif rule['type'] == 'reduce':
        skip_row = np.zeros(input.shape[0])

        for i in range(1, input.shape[0]):
            skip_row[i] = (input[i] == input[i-1]).all() or (input[i] == rule['skip_color']).all()

        if (input[0] == rule['skip_color']).all():
            skip_row[0] = 1

        if np.sum(skip_row==0)>0:
            output = input[skip_row == 0]

        skip_column = np.zeros(input.shape[1])

        for i in range(1, input.shape[1]):
            skip_column[i] = (input[:, i] == input[:, i-1]).all() or (input[:, i] == rule['skip_color']).all()

        if (input[:, 0] == rule['skip_color']).all():
            skip_column[0] = 1

        if np.sum(skip_column==0)>0:
            output = output[:, skip_column == 0]


    elif rule['type'] == 'rotate':
        output = np.rot90(output, rule['rotations_count'])

    elif rule['type'] == 'micro_multiply_by':
        if rule['how_many'] == 'size':
            k = output.shape[0]
        else:
            k = rule['how_many']
        output = np.repeat(output, k, axis=0)
        output = np.repeat(output, k, axis=1)

    elif rule['type'] == 'macro_multiply_by':
        if rule['how_many'] == 'both':
            k = (2, 2)
        elif rule['how_many'] == 'hor':
            k = (1, 2)
        elif rule['how_many'] == 'ver':
            k = (2, 1)
        output = np.tile(output, k)
        if input.shape[0] == input.shape[1]:
            for i in range(k[0]):
                for j in range(k[1]):
                    sub = output[i * input.shape[0]: (i + 1) * input.shape[0],
                          j * input.shape[1]: (j + 1) * input.shape[1]]
                    sub_rotated = np.rot90(sub, rule['rotates'][i * 2 + j])
                    output[i * input.shape[0]: (i + 1) * input.shape[0],
                    j * input.shape[1]: (j + 1) * input.shape[1]] = sub_rotated
        for i in range(k[0]):
            for j in range(k[1]):
                sub = output[i * input.shape[0]: (i + 1) * input.shape[0], j * input.shape[1]: (j + 1) * input.shape[1]]
                if 'ver' in rule['flips'][i * 2 + j]:
                    sub = sub[::-1, :]
                if 'hor' in rule['flips'][i * 2 + j]:
                    sub = sub[:, ::-1]
                output[i * input.shape[0]: (i + 1) * input.shape[0], j * input.shape[1]: (j + 1) * input.shape[1]] = sub

    elif rule['type'] == 'distribute_from_border':
        hidden = np.zeros_like(input)
        for i in range(1, input.shape[0] - 1):
            if output[i, 0] in rule['colors']:
                if not output[i, input.shape[1] - 1] in rule['colors'] or output[i, input.shape[1] - 1] == output[i, 0]:
                    output[i] = output[i, 0]

        for j in range(1, input.shape[1] - 1):
            if output[0, j] in rule['colors']:
                if not output[input.shape[0] - 1, j] in rule['colors'] or output[input.shape[0] - 1, j] == output[0, j]:
                    output[:, j] = output[0, j]

    elif rule['type'] == 'color_for_inners':
        hidden = np.zeros_like(input)
        changed = 1
        while changed == 1:
            changed = 0
            for i, j in product(range(input.shape[0]), range(input.shape[1])):
                i_c = input[i, j]

                if i_c > 0 or hidden[i, j] == 1:
                    continue

                if i == 0 or i == input.shape[0] - 1 or j == 0 or j == input.shape[1] - 1:
                    hidden[i, j] = 1
                    changed = 1
                    continue

                i_nbh = nbh(hidden, i, j)
                # cells adagent to the current one
                i_direct_nbh = {k: v for k, v in i_nbh.items() if k in {(1, 0), (-1, 0), (0, 1), (0, -1)}}

                if sum(1 for v in i_direct_nbh.values() if v == 1) > 0:
                    hidden[i, j] = 1
                    changed = 1
        output[((hidden == 0).astype(np.int) * (input == 0).astype(np.int)) == 1] = rule['color_out']
        hidden = np.copy(hidden)

    elif rule['type'] == 'draw_lines':
        hidden = np.zeros_like(input)
        if rule['direction'] == 'everywhere':
            directions = ['top', 'bottom', 'left', 'right', 'top_left', 'bottom_left', 'top_right', 'bottom_right']
        elif rule['direction'] == 'horizontal':
            directions = ['left', 'right']
        elif rule['direction'] == 'vertical':
            directions = ['top', 'bottom']
        elif rule['direction'] == 'horver':
            directions = ['top', 'bottom', 'left', 'right']
        elif rule['direction'] == 'diagonal':
            directions = ['top_left', 'bottom_left', 'top_right', 'bottom_right']
        else:
            directions = [rule['direction']]

        possible_directions = ['top', 'bottom', 'left', 'right',
                               'top_left', 'bottom_left', 'top_right', 'bottom_right']

        index_change =             [
                [-1, 0],
                [1, 0],
                (0, -1),
                (0, 1),
                (-1, -1),
                (+1, -1),
                (-1, +1),
                (+1, +1)
            ]
        for i_dir, direction in enumerate(possible_directions):
            if direction in directions:
                idx_ch = index_change[i_dir]
                for i in range(input.shape[0]):
                    for j in range(input.shape[1]):
                        if input[i, j] == rule['start_by_color']:
                            tmp_i = i + idx_ch[0]
                            tmp_j = j + idx_ch[1]
                            while 0 <= tmp_i < input.shape[0] and                                     0 <= tmp_j < input.shape[1] and                                     input[tmp_i, tmp_j] == rule['not_stop_by_color']:
                                output[tmp_i, tmp_j] = rule['with_color']
                                tmp_i += idx_ch[0]
                                tmp_j += idx_ch[1]

    elif rule['type'] == 'draw_line_to':
        hidden = np.zeros_like(input)

        index_change =             [
                [-1, 0],
                [1, 0],
                (0, -1),
                (0, 1),
            ]
        for i, j in product(range(input.shape[0]), range(input.shape[1])):
            if input[i, j] != rule['start_by_color']:
                continue

            number_0 = np.sum(output[:i] == rule['direction_color'])
            number_1 = np.sum(output[(i + 1):] == rule['direction_color'])
            number_2 = np.sum(output[:, :j] == rule['direction_color'])
            number_3 = np.sum(output[:, (j + 1):] == rule['direction_color'])
            i_dir = np.argmax([number_0, number_1, number_2, number_3])
            # print([number_0, number_1, number_2, number_3])
            # 1/0

            idx_ch = index_change[i_dir]
            tmp_i = i + idx_ch[0]
            tmp_j = j + idx_ch[1]
            while 0 <= tmp_i < input.shape[0] and                                     0 <= tmp_j < input.shape[1] and                     (input[tmp_i, tmp_j] in [rule['not_stop_by_color'], rule['not_stop_by_color_and_skip']]):

                skip_color = rule['not_stop_by_color_and_skip']
                if skip_color == 0 or input[tmp_i, tmp_j] != skip_color:
                    output[tmp_i, tmp_j] = rule['with_color']
                tmp_i += idx_ch[0]
                tmp_j += idx_ch[1]

    elif rule['type'] == 'distribute_colors':

        non_zero_rows = []
        non_zero_columns = []
        color_for_row = np.zeros(input.shape[0])
        color_for_column = np.zeros(input.shape[1])

        for i in range(input.shape[0]):
            row = input[i]
            colors, counts = np.unique(row, return_counts=True)
            good_colors = np.array([c in rule['colors'] for c in colors])
            if not good_colors.any():
                continue

            colors = colors[good_colors]
            counts = counts[good_colors]

            best_color = colors[np.argmax(counts)]
            color_for_row[i] = best_color
            non_zero_rows.append(i)

        for j in range(input.shape[1]):
            row = input[:, j]
            colors, counts = np.unique(row, return_counts=True)
            good_colors = np.array([c in rule['colors'] for c in colors])
            if not good_colors.any():
                continue

            colors = colors[good_colors]
            counts = counts[good_colors]

            best_color = colors[np.argmax(counts)]
            color_for_column[j] = best_color
            non_zero_columns.append(j)

        if rule['horizontally'] == 1:
            for i in non_zero_rows:
                output[i] = color_for_row[i]

        if rule['vertically'] == 1:
            for j in non_zero_columns:
                output[:, j] = color_for_column[j]

        for i in non_zero_rows:
            for j in non_zero_columns:
                if input[i, j] == 0:
                    output[i, j] = rule['intersect']
        hidden = np.copy(hidden_i)

    elif rule['type'] == 'unity':
        hidden = np.copy(hidden_i)
        if rule['mode'] == 'vertical':
            for j in range(input.shape[1]):
                last_color_now = np.zeros(10, dtype=np.int) - 1
                for i in range(input.shape[0]):
                    if not input[i, j] in rule['ignore_colors'] and last_color_now[input[i, j]] >= 0:
                        if rule['with_color'] == 0:
                            output[(last_color_now[input[i, j]] + 1):i, j] = input[i, j]
                        else:
                            output[(last_color_now[input[i, j]] + 1):i, j] = rule['with_color']
                        last_color_now[input[i, j]] = i
                    elif not input[i, j] in rule['ignore_colors']:
                        last_color_now[input[i, j]] = i


        elif rule['mode'] == 'horizontal':
            for i in range(input.shape[0]):
                last_color_now = np.zeros(10, dtype=np.int) - 1
                for j in range(input.shape[1]):
                    if not input[i, j] in rule['ignore_colors'] and last_color_now[input[i, j]] >= 0:
                        if rule['with_color'] == 0:
                            output[i, (last_color_now[input[i, j]] + 1):j] = input[i, j]
                        else:
                            output[i, (last_color_now[input[i, j]] + 1):j] = rule['with_color']
                        last_color_now[input[i, j]] = j
                    elif not input[i, j] in rule['ignore_colors']:
                        last_color_now[input[i, j]] = j

        elif rule['mode'] == 'horver':
            for j in range(input.shape[1]):
                last_color_now = np.zeros(10, dtype=np.int) - 1
                for i in range(input.shape[0]):
                    if not input[i, j] in rule['ignore_colors'] and last_color_now[input[i, j]] >= 0:
                        if rule['with_color'] == 0:
                            output[(last_color_now[input[i, j]] + 1):i, j] = input[i, j]
                        else:
                            output[(last_color_now[input[i, j]] + 1):i, j] = rule['with_color']
                        last_color_now[input[i, j]] = i
                    elif not input[i, j] in rule['ignore_colors']:
                        last_color_now[input[i, j]] = i

            for i in range(input.shape[0]):
                last_color_now = np.zeros(10, dtype=np.int) - 1
                for j in range(input.shape[1]):
                    if not input[i, j] in rule['ignore_colors'] and last_color_now[input[i, j]] >= 0:
                        if rule['with_color'] == 0:
                            output[i, (last_color_now[input[i, j]] + 1):j] = input[i, j]
                        else:
                            output[i, (last_color_now[input[i, j]] + 1):j] = rule['with_color']
                        last_color_now[input[i, j]] = j
                    elif not input[i, j] in rule['ignore_colors']:
                        last_color_now[input[i, j]] = j

        elif rule['mode'] == 'diagonal':
            for diag_id in range(-input.shape[0] - 1, input.shape[1] + 1):
                last_color_now_x = np.zeros(10, dtype=np.int) - 1
                last_color_now_y = np.zeros(10, dtype=np.int) - 1
                for i, j in zip(np.arange(input.shape[0]), diag_id + np.arange(input.shape[0])):
                    if 0 <= i < input.shape[0] and 0 <= j < input.shape[1]:
                        if not input[i, j] in rule['ignore_colors'] and last_color_now_x[input[i, j]] >= 0:

                            if rule['with_color'] == 0:
                                output[np.arange(last_color_now_x[input[i, j]] + 1, i), np.arange(
                                    last_color_now_y[input[i, j]] + 1, j)] = input[i, j]
                            else:
                                output[np.arange(last_color_now_x[input[i, j]] + 1, i), np.arange(
                                    last_color_now_y[input[i, j]] + 1, j)] = rule[
                                    'with_color']
                            last_color_now_x[input[i, j]] = i
                            last_color_now_y[input[i, j]] = j

                        elif not input[i, j] in rule['ignore_colors']:
                            last_color_now_x[input[i, j]] = i
                            last_color_now_y[input[i, j]] = j

            reflected_input = input[:, ::-1]
            output = output[:, ::-1]
            for diag_id in range(-reflected_input.shape[0] - 1, reflected_input.shape[1] + 1):
                last_color_now_x = np.zeros(10, dtype=np.int) - 1
                last_color_now_y = np.zeros(10, dtype=np.int) - 1
                for i, j in zip(np.arange(reflected_input.shape[0]), diag_id + np.arange(reflected_input.shape[0])):
                    if 0 <= i < reflected_input.shape[0] and 0 <= j < reflected_input.shape[1]:
                        if not reflected_input[i, j] in rule['ignore_colors'] and last_color_now_x[
                            reflected_input[i, j]] >= 0:

                            if rule['with_color'] == 0:
                                output[np.arange(last_color_now_x[reflected_input[i, j]] + 1, i), np.arange(
                                    last_color_now_y[reflected_input[i, j]] + 1, j)] = reflected_input[i, j]
                            else:
                                output[np.arange(last_color_now_x[reflected_input[i, j]] + 1, i), np.arange(
                                    last_color_now_y[reflected_input[i, j]] + 1, j)] = rule[
                                    'with_color']
                            last_color_now_x[reflected_input[i, j]] = i
                            last_color_now_y[reflected_input[i, j]] = j

                        elif not reflected_input[i, j] in rule['ignore_colors']:
                            last_color_now_x[reflected_input[i, j]] = i
                            last_color_now_y[reflected_input[i, j]] = j
            output = output[:, ::-1]
    elif rule['type'] == 'split_by_H':
        hidden = np.copy(hidden_i)

        if output.shape[0] >= 2:
            part1 = output[:int(np.floor(output.shape[0] / 2))]
            part2 = output[int(np.ceil(output.shape[0] / 2)):]

            output = np.zeros_like(part1)
            if rule['merge_rule'] == 'or':
                output[part1 > 0] = part1[part1 > 0]
                output[part2 > 0] = part2[part2 > 0]
            elif rule['merge_rule'] == 'equal':
                idx = np.logical_and(np.logical_and(part1 > 0, part2 > 0), part1 == part2)
                output[idx] = part1[idx]
            elif rule['merge_rule'] == 'and':
                idx = np.logical_and(part1 > 0, part2 > 0)
                output[idx] = part1[idx]
            elif rule['merge_rule'] == 'xor':
                idx = np.logical_xor(part1 > 0, part2 > 0)
                output[idx] = part1[idx]

    elif rule['type'] == 'split_by_W':
        hidden = np.copy(hidden_i)

        if output.shape[1] >= 2:
            part1 = output[:, :int(np.floor(output.shape[1] / 2))]
            part2 = output[:, int(np.ceil(output.shape[1] / 2)):]
            output = np.zeros_like(part1)
            if rule['merge_rule'] == 'or':
                output[part1 > 0] = part1[part1 > 0]
                output[part2 > 0] = part2[part2 > 0]
            elif rule['merge_rule'] == 'equal':
                idx = np.logical_and(np.logical_and(part1 > 0, part2 > 0), part1 == part2)
                output[idx] = part1[idx]
            elif rule['merge_rule'] == 'and':
                idx = np.logical_and(part1 > 0, part2 > 0)
                output[idx] = part1[idx]
            elif rule['merge_rule'] == 'xor':
                idx = np.logical_xor(part1 > 0, part2 > 0)
                output[idx] = part1[idx]


    elif rule['type'] == 'map_color':
        hidden = np.copy(hidden_i)
        output[output == rule['color_in']] = rule['color_out']
    elif rule['type'] == 'crop_empty':

        hidden = np.copy(hidden_i)

        nonzerosi = np.max((output != 0).astype(np.int), axis=1)
        nonzerosj = np.max((output != 0).astype(np.int), axis=0)
        if np.max(nonzerosi) == 0 or np.max(nonzerosj) == 0:
            output = output * 0
        else:
            mini = np.min(np.arange(output.shape[0])[nonzerosi == 1])
            maxi = np.max(np.arange(output.shape[0])[nonzerosi == 1])
            minj = np.min(np.arange(output.shape[1])[nonzerosj == 1])
            maxj = np.max(np.arange(output.shape[1])[nonzerosj == 1])

            output = output[mini:(maxi + 1), minj:(maxj + 1)]

    elif rule['type'] == 'crop_figure':
        hidden = np.copy(hidden_i)

        communities = get_connectivity_info(output, ignore_black=True, edge_for_difcolors=rule['dif_c_edge'])
        if len(communities) == 0:
            output = np.zeros_like(output)
        else:
            if rule['mode'] == 'biggest':
                biggest = list(communities[np.argmax([len(list(com)) for com in communities])])
            else:
                biggest = list(communities[np.argmin([len(list(com)) for com in communities])])
            biggest = np.array(biggest)
            min_bx = np.min(biggest[:, 0])
            min_by = np.min(biggest[:, 1])
            biggest[:, 0] -= min_bx
            biggest[:, 1] -= min_by
            output = np.zeros((np.max(biggest[:, 0]) + 1, np.max(biggest[:, 1]) + 1), dtype=np.int)
            for i in range(biggest.shape[0]):
                output[tuple(biggest[i])] = input[(min_bx + biggest[i][0], min_by + biggest[i][1])]

    elif rule['type'] == 'make_holes':
        hidden = np.copy(hidden_i)

        for i in range(output.shape[0]):
            for j in range(output.shape[1]):
                i_nbh = nbh(output, i, j)
                proper_nbhs = i_nbh.values()
                for color in range(1, 10):
                    if sum(1 for v in proper_nbhs if v == color) == 8:
                        output[i, j] = 0
                        break

    elif rule['type'] == 'gravity':
        changed_smth = 1
        hidden = np.copy(hidden_i)
        im = output

        if rule['gravity_type'] == 'figures':
            communities = get_connectivity_info(im, ignore_black=True)

        else:
            communities = []
            for i in range(output.shape[0]):
                for j in range(output.shape[1]):
                    if output[i, j] > 0:
                        communities.append([[i, j]])

        directions = []

        for com in communities:
            community = list(com)
            color_fig = output[community[0][0], community[0][1]]
            if rule['look_at_what_to_move'] == 1 and color_fig != rule['color_what']:
                directions.append('None')
                continue

            xs = [p[0] for p in community]
            ys = [p[1] for p in community]

            if rule['direction_type'] == 'border':
                direction = rule['direction_border']
            elif rule['direction_type'] == 'color':
                color = rule['direction_color']
                xmin, xmax = np.min(xs), np.max(xs)
                ymin, ymax = np.min(ys), np.max(ys)
                number_0 = np.sum(output[:xmin] == color)
                number_1 = np.sum(output[(xmax + 1):] == color)
                number_2 = np.sum(output[:, :ymin] == color)
                number_3 = np.sum(output[:, (ymax + 1):] == color)
                direction = ['top', 'bottom', 'left', 'right'][np.argmax([number_0, number_1, number_2, number_3])]

            directions.append(direction)

        already_moved = np.zeros(len(communities))
        while changed_smth > 0:

            changed_smth = 0

            for i, com in enumerate(communities):
                community = list(com)
                color_fig = output[community[0][0], community[0][1]]
                xs = [p[0] for p in community]
                ys = [p[1] for p in community]

                direction = directions[i]
                if direction == 'top':
                    toper = np.array([[p[0] - 1, p[1]] for p in community if (p[0] - 1, p[1]) not in community])
                    xs = np.array([p[0] for p in toper])
                    ys = np.array([p[1] for p in toper])
                    if np.min(xs) < 0:
                        continue

                    if (output[xs, ys] == 0).all() and (rule['steps_limit']==1 or already_moved[i]==0):
                        changed_smth = 1
                        already_moved[i]=1
                        com_xs = np.array([p[0] for p in community])
                        com_ys = np.array([p[1] for p in community])
                        output[com_xs, com_ys] = 0
                        output[com_xs - 1, com_ys] = color_fig
                        communities[i] = [(p[0] - 1, p[1]) for p in community]

                if direction == 'bottom':
                    toper = np.array([[p[0] + 1, p[1]] for p in community if (p[0] + 1, p[1]) not in community])
                    xs = np.array([p[0] for p in toper])
                    ys = np.array([p[1] for p in toper])

                    if np.max(xs) == input.shape[0]:
                        continue

                    if (output[xs, ys] == 0).all() and (rule['steps_limit']==1 or already_moved[i]==0):
                        changed_smth = 1
                        already_moved[i]=1
                        com_xs = np.array([p[0] for p in community])
                        com_ys = np.array([p[1] for p in community])

                        output[com_xs, com_ys] = 0
                        output[com_xs + 1, com_ys] = color_fig
                        communities[i] = [(p[0] + 1, p[1]) for p in community]

                if direction == 'left':
                    toper = np.array([[p[0], p[1] - 1] for p in community if (p[0], p[1] - 1) not in community])
                    xs = np.array([p[0] for p in toper])
                    ys = np.array([p[1] for p in toper])

                    if np.min(ys) < 0:
                        continue

                    if (output[xs, ys] == 0).all() and (rule['steps_limit']==1 or already_moved[i]==0):
                        changed_smth = 1
                        already_moved[i]=1
                        com_xs = np.array([p[0] for p in community])
                        com_ys = np.array([p[1] for p in community])
                        output[com_xs, com_ys] = 0
                        output[com_xs, com_ys - 1] = color_fig
                        communities[i] = [(p[0], p[1] - 1) for p in community]

                if direction == 'right':
                    toper = np.array([[p[0], p[1] + 1] for p in community if (p[0], p[1] + 1) not in community])
                    xs = np.array([p[0] for p in toper])
                    ys = np.array([p[1] for p in toper])

                    if np.max(ys) == input.shape[1]:
                        continue

                    if (output[xs, ys] == 0).all() and (rule['steps_limit']==1 or already_moved[i]==0):
                        changed_smth = 1
                        already_moved[i]=1
                        com_xs = np.array([p[0] for p in community])
                        com_ys = np.array([p[1] for p in community])
                        output[com_xs, com_ys] = 0
                        output[com_xs, com_ys + 1] = color_fig
                        communities[i] = [(p[0], p[1] + 1) for p in community]


    return output, hidden


# # Cellular automata
# 
# This is the application of the given cellular automata to the grid.
# 
# CA-rules used to solve something like this:

# In[ ]:


name = '292dd178'
task = load_data(f'{name}.json', phase='evaluation')

plot_task(task)


# In[ ]:


nbh = lambda x, i, j: {
    (ip, jp) : x[i+ip, j+jp]
        for ip, jp in product([1, -1, 0], repeat=2)
            if 0 <= i+ip < x.shape[0] and 0 <= j+jp < x.shape[1] and (not (ip==0 and jp==0))
}

def compute_parametrized_automata(input, hidden_i, rules):
    output = np.zeros_like(input, dtype=int)

    hidden_o = np.copy(hidden_i)

    for i, j in product(range(input.shape[0]), range(input.shape[1])):
        i_c = input[i, j]
        i_nbh = nbh(input, i, j)
        # cells adagent to the current one
        i_direct_nbh = {k: v for k, v in i_nbh.items() if k in {(1, 0), (-1, 0), (0, 1), (0, -1)}}
        i_indirect_nbh = {k: v for k, v in i_nbh.items() if k in {(1, 1), (-1, -1), (-1, 1), (1, -1)}}

        is_top_b, is_bottom_b = i == 0, i == input.shape[0] - 1
        is_left_b, is_right_b = j == 0, j == input.shape[1] - 1
        is_b = is_top_b or is_bottom_b or is_left_b or is_right_b

        if i_c > 0:
            output[i, j] = i_c

        for rule in rules:

            if i_c in rule['ignore_colors']:
                continue

            if rule['type'] == 'copy_color_by_direction':
                if rule['direction'] == 'bottom' or rule['direction'] == 'everywhere':
                    if not is_top_b and input[i - 1, j] in rule['copy_color'] and                             (i == 1 or input[i - 2, j] == rule['look_back_color']):
                        output[i, j] = input[i - 1, j]
                        break

                if rule['direction'] == 'top' or rule['direction'] == 'everywhere':
                    if not is_bottom_b and input[i + 1, j] in rule['copy_color'] and                             (i == input.shape[0] - 2 or input[i + 2, j] == rule['look_back_color']):
                        output[i, j] = input[i + 1, j]
                        break

                if rule['direction'] == 'right' or rule['direction'] == 'everywhere':
                    if not is_left_b and input[i, j - 1] in rule['copy_color'] and                             (j == 1 or input[i, j - 2] == rule['look_back_color']):
                        output[i, j] = input[i, j - 1]
                        break

                if rule['direction'] == 'left' or rule['direction'] == 'everywhere':
                    if not is_right_b and input[i, j + 1] in rule['copy_color'] and                             (j == input.shape[1] - 2 or input[i, j + 2] == rule['look_back_color']):
                        output[i, j] = input[i, j + 1]
                        break
            elif rule['type'] == 'corner_check':
                color_nbh = rule['nbh_check_colors']
                sum_nbh = 3
                out_nbh = rule['nbh_check_out']

                i_uplecorner_nbh = {k: v for k, v in i_nbh.items() if k in {(-1, -1), (-1, 0), (0, -1)}}
                i_upricorner_nbh = {k: v for k, v in i_nbh.items() if k in {(-1, 1), (-1, 0), (0, 1)}}
                i_dolecorner_nbh = {k: v for k, v in i_nbh.items() if k in {(1, -1), (1, 0), (0, -1)}}
                i_doricorner_nbh = {k: v for k, v in i_nbh.items() if k in {(1, 1), (1, 0), (0, 1)}}
                if sum(1 for v in i_nbh.values() if v in color_nbh) < 3:
                    continue
                did_something = False
                for corner_idx in [i_uplecorner_nbh, i_upricorner_nbh, i_dolecorner_nbh, i_doricorner_nbh]:
                    for color in color_nbh:
                        if sum(1 for v in corner_idx.values() if v == color) == sum_nbh:
                            output[i, j] = out_nbh
                            did_something = True
                            break
                    if did_something:
                        break
                if did_something:
                    break


            elif rule['type'] == 'nbh_check':
                color_nbh = rule['nbh_check_colors']
                sum_nbh = rule['nbh_check_sum']
                out_nbh = rule['nbh_check_out']

                proper_nbhs = i_nbh.values()

                if sum(1 for v in proper_nbhs if v in color_nbh) > sum_nbh:
                    output[i, j] = out_nbh
                    break

            elif rule['type'] == 'direct_check':
                color_nbh = rule['nbh_check_colors']
                sum_nbh = rule['nbh_check_sum']
                out_nbh = rule['nbh_check_out']

                proper_nbhs = i_direct_nbh.values()

                if sum(1 for v in proper_nbhs if v in color_nbh) > sum_nbh:
                    output[i, j] = out_nbh
                    break

            elif rule['type'] == 'indirect_check':
                color_nbh = rule['nbh_check_colors']
                sum_nbh = rule['nbh_check_sum']
                out_nbh = rule['nbh_check_out']

                proper_nbhs = i_indirect_nbh.values()

                if sum(1 for v in proper_nbhs if v in color_nbh) > sum_nbh:
                    output[i, j] = out_nbh
                    break


            elif rule['type'] == 'color_distribution':
                directions = ['top', 'bottom', 'left', 'right', 'top_left', 'bottom_left', 'top_right', 'bottom_right']
                not_border_conditions =                     [
                        not is_top_b,
                        not is_bottom_b,
                        not is_left_b,
                        not is_right_b,
                        not is_top_b and not is_left_b,
                        not is_bottom_b and not is_left_b,
                        not is_top_b and not is_right_b,
                        not is_bottom_b and not is_right_b
                    ]
                index_from =                     [
                        (i - 1, j),
                        (i + 1, j),
                        (i, j - 1),
                        (i, j + 1),
                        (i - 1, j - 1),
                        (i + 1, j - 1),
                        (i - 1, j + 1),
                        (i + 1, j + 1)
                    ]

                did_something = False
                for i_dir, direction in enumerate(directions):
                    if rule['direction'] == direction:
                        if not_border_conditions[i_dir]:
                            if (rule['check_in_empty'] == 1 and input[index_from[i_dir]] > 0) or                                     (rule['check_in_empty'] == 0 and input[index_from[i_dir]] == rule['color_in']):
                                output[i, j] = rule['color_out']
                                did_something = True
                                break
                if did_something:
                    break

    return output, hidden_o


# # Split/merge rules.
# 
# Here are grid -> [grid] and [grid] -> grid rules that were added recently.
# Pay attention that here is a small hack. We use information about split rule in the merge. It's not very good but we had no time to make a better solution.
# 
# With these rules we can solve for example the following task:

# In[ ]:


name = '00576224'
task = load_data(f'{name}.json', phase='evaluation')

plot_task(task)


# In[ ]:


def apply_split_rule(input, hidden, split_rule):
    if split_rule['type'] == 'nothing':
        return [(input, hidden)]

    if split_rule['type'] == 'macro_multiply':
        ks = split_rule['k1'] *  split_rule['k2']
        grids = [(np.copy(input), np.copy(hidden)) for _ in range(ks)]
        return grids

    dif_c_edge = split_rule['type'] == 'figures'
    
    # communities are always sorted by the size and 
    communities = get_connectivity_info(input, ignore_black=True, edge_for_difcolors=dif_c_edge)

    if len(communities) > 0:
        if split_rule['sort'] == 'biggest':
            communities = communities[::-1]

        grids = [(np.zeros_like(input), np.zeros_like(hidden)) for _ in range(len(communities))]
        for i in range(len(communities)):
            for point in communities[i]:
                grids[i][0][point] = input[point]
    else:
        grids = [(input, hidden)]

    return grids


def apply_merge_rule(grids, merge_rule, split_rule):

    if split_rule['type'] == 'macro_multiply':
        shape_base = grids[0][0].shape
        shapes = [arr[0].shape for arr in grids]
        if not np.array([shape_base == sh for sh in shapes]).all():
            return np.zeros((1, 1), dtype=np.int)

        ks_1 = split_rule['k1']
        ks_2 = split_rule['k2']
        output = np.zeros((shape_base[0] * ks_1, shape_base[1] * ks_2), dtype=np.int8)
        for k1 in range(ks_1):
            for k2 in range(ks_2):
                output[(k1*shape_base[0]):((k1+1) * shape_base[0]), (k2*shape_base[1]):((k2+1) * shape_base[1])] = grids[k1*ks_2 + k2][0]

        return output

    if merge_rule['type'] == 'cellwise_or':
        output = np.zeros_like(grids[0][0])
        for i in np.arange(len(grids))[::-1]:
            if grids[i][0].shape == output.shape:
                output[grids[i][0]>0] = grids[i][0][grids[i][0]>0]
        return output
    elif merge_rule['type'] == 'output_first':
        output = grids[0][0]
    elif merge_rule['type'] == 'output_last':
        output = grids[-1][0]
    return output


# # Rules generation
# Here in 4 functions random rules of 4 types are generated. In global and ca_rules we use information about the pool of the programs that we have. We compute the statistics about how often each rule is used in our population and adjust the probability distribution over rules to this distribution. We use a temperature parameter that is depended on the time that is passed after the moment when we start learning.

# In[ ]:


def get_random_split_rule(all_colors, best_candidates={}, temp=0, config={}, r_type=None):
    rule = {}
    rule['type'] = random.choice(['nothing', 'color_figures', 'figures', 'macro_multiply'])
    if rule['type'] in ['color_figures', 'figures']:
        rule['sort'] = random.choice(['biggest', 'smallest'])

    if rule['type'] == 'macro_multiply':
        rule['k1'] = np.random.randint(config['mink1'], config['maxk1']+1)
        rule['k2'] = np.random.randint(config['mink2'], config['maxk2']+1)

    return rule


def get_random_merge_rule(all_colors, best_candidates={}, temp=0, config={}, r_type=None):
    rule = {}
    rule['type'] = random.choice(['cellwise_or', 'output_first', 'output_last'])
    return rule


def get_random_ca_rule(all_colors, best_candidates={}, temp=0, config={}, r_type=None):
    types_possible =         [
            'copy_color_by_direction',
            'direct_check',
            'indirect_check',
            'nbh_check',
            'corner_check',
            'color_distribution',
        ]

    ca_rules = []
    best_candidates_items = list(best_candidates.items())
    if len(best_candidates_items) > 0:
        for best_score, best_candidates_score in best_candidates_items:
            for best_c in best_candidates_score:
                gl, ca, _, _ = best_c
                ca_rules += [c['type'] for c in ca]
        type_counts = dict(zip(types_possible, np.zeros(len(types_possible))))

        rules, counts = np.unique(ca_rules, return_counts=True)
        for i in range(rules.shape[0]):
            type_counts[rules[i]] += counts[i]
        counts = np.array(list(type_counts.values()))
        if np.sum(counts) > 0:
            counts /= np.sum(counts)
        else:
            counts = np.ones(counts.shape[0]) / counts.shape[0]
        uniform = np.ones(counts.shape[0]) / counts.shape[0]
        probs = temp * counts + (1 - temp) * uniform

    else:
        probs = np.ones(len(types_possible)) / len(types_possible)

    colors = all_colors[1:]

    type_probs = np.ones(len(types_possible)) / len(types_possible)

    if r_type is None:
        random_type = types_possible[np.random.choice(len(types_possible), p=probs)]
    else:
        random_type = r_type

    def get_random_out_color():
        possible_colors = config['possible_colors_out']
        return np.random.choice(possible_colors)

    def get_random_ignore_colors():
        if config['possible_ignore_colors'].shape[0] > 0:
            possible_colors = config['possible_ignore_colors']
            return possible_colors[np.random.randint(2, size=possible_colors.shape[0]) == 1]
        else:
            return []

    def get_random_all_colors():
        return all_colors[np.random.randint(2, size=all_colors.shape[0]) == 1]

    def get_random_colors():
        return get_random_all_colors()

    def get_random_all_color():
        return np.random.choice(all_colors)

    def get_random_color():
        return get_random_all_color()

    rule = {}
    rule['type'] = random_type
    rule['macro_type'] = 'ca_rule'
    rule['ignore_colors'] = list(config['ignore_colors'])

    if np.random.rand() < 0.5 and config['possible_ignore_colors'].shape[0]:
        rule['ignore_colors'] += [random.choice(config['possible_ignore_colors'])]

    if random_type == 'copy_color_by_direction':
        rule['direction'] = random.choice(['everywhere'])
        rule['copy_color'] = [get_random_out_color()]
        rule['look_back_color'] = rule['copy_color'][0]

    elif random_type == 'corner_check':
        if np.random.rand() < 0.5:
            rule['nbh_check_colors'] = [get_random_all_color()]
        else:
            rule['nbh_check_colors'] = list(np.unique([get_random_all_color(), get_random_all_color()]))
        rule['nbh_check_out'] = get_random_out_color()
        rule['ignore_colors'] = list(np.unique(rule['ignore_colors'] + [rule['nbh_check_out']]))

    elif random_type == 'direct_check':
        rule['nbh_check_sum'] = np.random.randint(4)
        if np.random.rand() < 0.5:
            rule['nbh_check_colors'] = [get_random_all_color()]
        else:
            rule['nbh_check_colors'] = list(np.unique([get_random_all_color(), get_random_all_color()]))
        rule['nbh_check_out'] = get_random_out_color()
        rule['ignore_colors'] = list(np.unique(rule['ignore_colors'] + [rule['nbh_check_out']]))

    elif random_type == 'indirect_check':
        rule['nbh_check_sum'] = np.random.randint(4)
        if np.random.rand() < 0.5:
            rule['nbh_check_colors'] = [get_random_all_color()]
        else:
            rule['nbh_check_colors'] = list(np.unique([get_random_all_color(), get_random_all_color()]))
        rule['nbh_check_out'] = get_random_out_color()
        rule['ignore_colors'] = list(np.unique(rule['ignore_colors'] + [rule['nbh_check_out']]))

    elif random_type == 'nbh_check':
        rule['nbh_check_sum'] = np.random.randint(8)
        if np.random.rand() < 0.5:
            rule['nbh_check_colors'] = [get_random_all_color()]
        else:
            rule['nbh_check_colors'] = list(np.unique([get_random_all_color(), get_random_all_color()]))
        rule['nbh_check_out'] = get_random_out_color()
        rule['ignore_colors'] = list(np.unique(rule['ignore_colors'] + [rule['nbh_check_out']]))

    elif random_type == 'color_distribution':
        rule['direction'] = random.choice(
            ['top', 'bottom', 'left', 'right', 'top_left', 'bottom_left', 'top_right', 'bottom_right'])
        rule['check_in_empty'] = np.random.randint(2)
        rule['color_out'] = get_random_out_color()
        if rule['check_in_empty'] == 0:
            rule['color_in'] = rule['color_out']
        else:
            rule['color_in'] = get_random_all_color()

        rule['ignore_colors'] = list(np.unique(rule['ignore_colors'] + [rule['color_out']]))

    return rule


def get_random_global_rule(all_colors, best_candidates={}, temp=0, config={}, r_type=None):
    types_possible =         [
            'distribute_colors',
            'unity',
            'color_for_inners',
            'map_color',
            'draw_lines',
            'draw_line_to',
            'gravity',
            'make_holes',
            'distribute_from_border',
            'align_pattern',
            'rotate',
            'flip'
        ]

    if config['allow_make_smaller']:
        types_possible +=             [
                'crop_empty',
                'crop_figure',
                'split_by_H',
                'split_by_W',
                'reduce'
            ]

    gl_rules = []
    best_candidates_items = list(best_candidates.items())
    if len(best_candidates_items) > 0:
        for best_score, best_candidates_score in best_candidates_items:
            for best_c in best_candidates_score:
                gl, ca, _, _ = best_c
                gl_rules += [c['type'] for c in gl]
        type_counts = dict(zip(types_possible, np.zeros(len(types_possible))))

        rules, counts = np.unique(gl_rules, return_counts=True)
        for i in range(rules.shape[0]):
            type_counts[rules[i]] += counts[i]
        counts = np.array(list(type_counts.values()))
        if np.sum(counts) > 0:
            counts /= np.sum(counts)
        else:
            counts = np.ones(counts.shape[0]) / counts.shape[0]
        uniform = np.ones(counts.shape[0]) / counts.shape[0]
        probs = temp * counts + (1 - temp) * uniform
    else:
        probs = np.ones(len(types_possible)) / len(types_possible)


    if r_type is None:
        random_type = types_possible[np.random.choice(len(types_possible), p=probs)]
    else:
        random_type = r_type

    def get_random_all_color():
        return np.random.choice(all_colors)

    def get_random_color():
        return get_random_all_color()

    def get_random_out_color():
        possible_colors = config['possible_colors_out']
        return np.random.choice(possible_colors)

    rule = {}
    rule['type'] = random_type
    rule['macro_type'] = 'global_rule'
    rule['apply_to'] = random.choice(['all', 'index'])

    if np.random.rand()<0.2:
        rule['apply_to'] = 'last'

    if rule['apply_to'] == 'index':
        rule['apply_to_index'] = np.random.choice(10)

    if random_type == 'macro_multiply_k':
        rule['k'] = (np.random.randint(1, 4), np.random.randint(1, 4))
    elif random_type == 'flip':
        rule['how'] = random.choice(['ver', 'hor'])

    elif random_type == 'rotate':
        rule['rotations_count'] = np.random.randint(1, 4)

    elif random_type == 'micro_multiply_by':
        rule['how_many'] = random.choice([2, 3, 4, 5, 'size'])

    elif random_type == 'macro_multiply_by':
        rule['how_many'] = random.choice(['both', 'hor', 'ver'])
        rule['rotates'] = [np.random.randint(1) for _ in range(4)]
        rule['flips'] = [random.choice(['hor', 'ver', 'horver', 'no']) for _ in range(4)]


    elif random_type == 'distribute_from_border':
        rule['colors'] = list(np.unique([get_random_out_color(), get_random_all_color()]))

    elif random_type == 'draw_lines':
        rule['direction'] = random.choice(['everywhere', 'horizontal', 'vertical', 'horver', 'diagonal'])
        # 'top', 'bottom', 'left', 'right',
        # 'top_left', 'bottom_left', 'top_right', 'bottom_right'])
        rule['not_stop_by_color'] = 0  # get_random_all_color()
        rule['start_by_color'] = get_random_all_color()
        rule['with_color'] = get_random_out_color()

    elif random_type == 'reduce':
        rule['skip_color'] = get_random_all_color()
    elif random_type == 'draw_line_to':

        rule['direction_color'] = get_random_all_color()

        rule['not_stop_by_color'] = 0
        if np.random.rand() < 0.5:
            rule['not_stop_by_color_and_skip'] = get_random_all_color()
        else:
            rule['not_stop_by_color_and_skip'] = 0

        rule['start_by_color'] = get_random_all_color()
        rule['with_color'] = get_random_out_color()

    elif random_type == 'distribute_colors':
        rule['colors'] = list(np.unique([get_random_out_color(), get_random_all_color()]))
        rule['horizontally'] = np.random.randint(2)
        rule['vertically'] = np.random.randint(2)
        rule['intersect'] = get_random_out_color()

    elif random_type == 'color_for_inners':
        rule['color_out'] = get_random_out_color()

    elif random_type == 'crop_figure':
        rule['mode'] = random.choice(['smallest', 'biggest'])
        rule['dif_c_edge'] = random.choice([True, False])


    elif random_type == 'unity':
        rule['mode'] = random.choice(['diagonal', 'horizontal', 'vertical', 'horver'])
        rule['ignore_colors'] = [0]
        if np.random.rand() < 0.5:
            rule['ignore_colors'] += [get_random_all_color()]
        rule['with_color'] = random.choice([get_random_out_color(), 0])

    elif random_type == 'map_color':
        rule['color_in'] = get_random_all_color()
        rule['color_out'] = get_random_out_color()

    elif random_type == 'gravity':
        rule['gravity_type'] = random.choice(['figures', 'cells'])
        rule['steps_limit'] = np.random.choice(2)
        rule['look_at_what_to_move'] = np.random.choice(2)
        if rule['look_at_what_to_move'] == 1:
            rule['color_what'] = get_random_out_color()
        rule['direction_type'] = random.choice(['border', 'color'])
        if rule['direction_type'] == 'border':
            rule['direction_border'] = random.choice(['top', 'bottom', 'left', 'right'])
        else:
            rule['direction_color'] = get_random_color()

    elif random_type == 'split_by_H' or random_type == 'split_by_W':
        rule['merge_rule'] = random.choice(['and', 'equal', 'or', 'xor'])

    elif random_type == 'align_pattern':
        rule['macro_type'] = 'global_interaction_rule'
        # rule['allow_rotation'] = False
        rule['allow_color'] = get_random_all_color()
        rule['fill_with_color'] = 0 #random.choice([0, get_random_all_color()])

    return rule


# #### "Task metadata"
# 
# This is a function that computes some "facts" about the task that is then used during the training.
# For example, it checks:
# 
# 1) What are colors are produced if we compare input-output
# 
# 2) What colors are never changed 
# 
# 3) Is output smaller than input?
# 
# 4) What are minimum and maximum coefficients by which we can "repeat" our input grid and then merge (there are not many such tasks)

# In[ ]:


def get_task_metadata(task):
    colors = []
    shapes_input = [[], []]
    shapes_output = [[], []]
    for part in ['train']:
        for uni_task in task[part]:
            inp = uni_task['input']
            colors += list(np.unique(inp))
            out = uni_task['output']
            colors += list(np.unique(out))

            shapes_input[0].append(inp.shape[0])
            shapes_input[1].append(inp.shape[1])
            shapes_output[0].append(out.shape[0])
            shapes_output[1].append(out.shape[1])

    all_colors = np.unique(colors)

    min_k1 = int(np.floor(np.min(np.array(shapes_output[0])/np.array(shapes_input[0]))))
    min_k2 = int(np.floor(np.min(np.array(shapes_output[1])/np.array(shapes_input[1]))))
    max_k1 = int(np.ceil(np.max(np.array(shapes_output[0])/np.array(shapes_input[0]))))
    max_k2 = int(np.ceil(np.max(np.array(shapes_output[1])/np.array(shapes_input[1]))))

    max_shape = np.max([shapes_input])

    config = {}

    config['mink1'] = max(1, min(min(min_k1, 30//max_shape), 3))
    config['mink2'] = max(1, min(min(min_k2, 30//max_shape), 3))
    config['maxk1'] = max(1, min(min(max_k1, 30//max_shape), 3))
    config['maxk2'] = max(1, min(min(max_k2, 30//max_shape), 3))


    config['allow_make_smaller'] = False
    config['allow_make_bigger'] = False

    for uni_task in task['train']:
        if uni_task['input'].shape[0] > uni_task['output'].shape[0] or                 uni_task['input'].shape[1] > uni_task['output'].shape[1]:
            config['allow_make_smaller'] = True

        if uni_task['input'].shape[0] < uni_task['output'].shape[0] or                 uni_task['input'].shape[1] < uni_task['output'].shape[1]:
            config['allow_make_bigger'] = True

    colors_out = []
    changed_colors = []
    inp_colors = []
    for uni_task in task['train']:
        inp = uni_task['input']
        out = uni_task['output']
        for i in range(min(inp.shape[0], out.shape[0])):
            for j in range(min(inp.shape[1], out.shape[1])):
                inp_colors.append(inp[i, j])
                if out[i, j] != inp[i, j]:
                    colors_out.append(out[i, j])
                    changed_colors.append(inp[i, j])

    inp_colors = np.unique(inp_colors)
    changed_colors = np.unique(changed_colors)

    config['ignore_colors'] = [c for c in inp_colors if not c in changed_colors]
    config['possible_ignore_colors'] = np.array([c for c in all_colors if not c in config['ignore_colors']])
    if len(colors_out) == 0:
        colors_out = [0]
    config['possible_colors_out'] = np.unique(colors_out)

    return all_colors, config


# ****
# # Quality measurement
# 
# Here we compute the quality of the prediction. We use accuracy and we measure if each possible color is **absolutely correct**

# In[ ]:


def compute_metrics(prediction_grid, answer_grid):

    def get_metrics(prediction, answer):
        right = (prediction == answer).astype(np.int)

        accuracy = np.mean(right)

        color_rights = []

        for color in range(10):
            idx = answer != color
            color_right = float((np.logical_or(idx, right).all() and not (prediction[idx]==color).any()))
            color_rights.append(color_right)

        return [accuracy] + color_rights

    if prediction_grid.shape == answer_grid.shape:
        return get_metrics(prediction_grid, answer_grid) + [1]


    return list(np.array(get_metrics(answer_grid, answer_grid)) * 0) + [0]


# This function takes a program and a task and produces an array of metrics that is used by the genetic algorithm to select the best programs

# In[ ]:


def validate_automata(task_global, params, n_iter_max, n_hidden):
    def validate(task):
        inp = task['input']

        out = trace_param_automata(inp, params, n_iter_max, n_hidden)[-1][0]

        metrics = compute_metrics(out, task['output'])

        return metrics

    metrics = []
    for task in task_global['train']:
        metrics.append(validate(task))

    mean_metrics = list(np.round(np.mean(metrics, axis=0), 3))
    min_metrics = list(np.round(np.min(metrics, axis=0), 3))

    return tuple(mean_metrics + list(np.array(metrics)[:, 0].reshape(-1)))#tuple(mean_metrics + min_metrics)


def product_better(a, b):
    """ Return True iff the two tuples a and b respect a<b for the partial order. """
    a = np.array(a)
    b = np.array(b)
    return (np.array(a) >= np.array(b)).all() and (np.array(a) > np.array(b)).any()


# These functions generate random programs that are then modified by the genetic algorithm

# In[ ]:


def generate_random_ca(all_colors, best_candidates, temp, config, length=1):
    rules = []
    for _ in range(length):
        rules.append(get_random_ca_rule(all_colors, best_candidates, temp, config))
    return rules

def generate_random_global(all_colors, best_candidates, temp, config, length=1):
    rules = []
    for _ in range(length):
        rules.append(get_random_global_rule(all_colors, best_candidates, temp, config))
    return rules

def generate_population(all_colors, config, size=64, length=1):
    population = []
    for i in range(size):
        split_rule = get_random_split_rule(all_colors, {}, 0, config)
        merge_rule = get_random_merge_rule(all_colors, {}, 0, config)
        global_rules = generate_random_global(all_colors, {}, 0, config, np.random.choice(2, p=[0.2, 0.8]))
        ca_rules = generate_random_ca(all_colors, {}, 0, config, np.random.choice(2, p=[0.2, 0.8]))
        population.append([global_rules, ca_rules, split_rule, merge_rule])

    return population


# # "Task mapping"
# 
# Here is another interesting part that I called "mapping".
# Suppose we have a task where we have a grid of cells that are divided by lines of some color (for example 06df4c85)
# 
# We would like to "reduce" this grid (to delete lines) so we can solve our task without them. But then we should map our grid back to match with the real output.
# 
# So how the logic works.
# 
# We have a task:
# 
# unmapped input -> unmapped output
# 
# unmapped test> -> *
# 
# We find a proper mapping and apply to to the train pairs so we have 
# 
# mapped input -> mapped output
# 
# Then we find a DSL-program that solves this task.
# 
# Then to find the final test prediction, we map test input and **map back** the output of the program. How to do it? 
# We store the information about the mapping for each task in the dictionary called "reverse_functions". We use it later at the prediction stage when we make this mapping back.
# 
# There are three mappings in this algorithm:
# 
# - Grid mapping
# 
# As I explained, it is for tasks like 06df4c85
# 
# - Color mapping
# 
# This is our interesting invention (but I am not sure it helped comparing with the simplified version :D)
# It makes a transformation of the grid which gives the same output for every color permutation.
# 
# The main idea:
# 
# 1) We take training input that contains the biggest number of different colors.
# 
# For each color we compute its "features" which is a part of cells of this color and part of *border cells* of this color.
# 
# I do a reversed sort the colors it by the sum of this features and change the color to the color indexed by the index in the sorted array.
# This is our "template". We have colors from 0 to n in this grid. We make a sort because we want a color that is the most frequent to have the number 0.
# 
# 2) Then we map all the other grids:
# 
# For each color we compute its "features" that are mentioned above. Then using K-NN (the only ML we have here :D) we find the closest color from the template grid. Then we map the color to the right color. After the mapping we delete the resulting color from the pool because we shouldn't map 2 different colors to one color.
# 
# 3) Some colors are met only in the outputs. 
# 
# I made an assumption that these colors should stay the same. So if color = 8 exists in all outputs and there is no 8 in the inputs, we should not change this color (at least with respect to each other).
# 
# 4) At the test stage:
# 
# We do the same mapping for the test input and then we map the colors back after the prediction. One thing can go wrong: if there are more colors in the test input than in the "template". In this case I made some strange things:
# 
# I change some colors to black in different ways, do the mapping, apply the program and then I merge these outputs. I have no idea if it works but it's here.
# 
# - "find wall" mapping
# 
# This is **very** simplified version of the previous mapping. At each input grid we find a color with the best sum of features (that are described above) and then change it with the black. 
# 
# Here is all the code that is related to the task mapping.
#     
#     
# 

# In[ ]:


from functools import partial
from itertools import product
from sklearn.preprocessing import MinMaxScaler

def change_color(colors_in, colors_out, grid):
    out_grid = np.zeros_like(grid)
    out_grid[:] = grid[:]
    for i in range(grid.shape[0]):
        for j in range(grid.shape[1]):
            for color_in, color_out in zip(colors_in, colors_out):
                if grid[i, j] == color_in:
                    out_grid[i, j] = color_out
                    break
    return out_grid


def reduce_grid(grid_rows, grid_columns, color, grid):
    out_grid = np.zeros((len(grid_rows), len(grid_columns)), dtype=np.int)
    for i, j in product(range(len(grid_rows)), range(len(grid_columns))):
        out_grid[i, j] = grid[grid_rows[i][0], grid_columns[j][0]]
    return out_grid


def unreduce_grid(line_rows, line_columns, n, m, grid_rows, grid_columns, color, grid):
    out_grid = np.zeros((n, m), dtype=np.int)
    for i in range(len(line_rows)):
        out_grid[line_rows[i]] = color

    for j in range(len(line_columns)):
        out_grid[:, line_columns[j]] = color

    for i, j in product(range(len(grid_rows)), range(len(grid_columns))):
        if grid[i, j] != 0:
            for i_gr_row in list(grid_rows[i]):
                for j_gr_col in list(grid_columns[j]):
                    out_grid[i_gr_row, j_gr_col] = grid[i, j]

    return out_grid


def get_color_features(input_grid):
    colors = np.unique(input_grid)
    colors_numbers = np.array([np.mean(input_grid == color) for color in colors]).reshape((-1, 1))

    colors_borders = np.array([np.mean(input_grid[0] == color) for color in colors]).reshape((-1, 1))
    colors_borders += np.array([np.mean(input_grid[-1] == color) for color in colors]).reshape((-1, 1))
    colors_borders += np.array([np.mean(input_grid[:, 0] == color) for color in colors]).reshape((-1, 1))
    colors_borders += np.array([np.mean(input_grid[:, -1] == color) for color in colors]).reshape((-1, 1))

    colors_borders /= np.sum(colors_borders)

    colors_features = np.concatenate([colors_numbers, colors_borders], axis=1)

    return colors_features, colors


def get_train_color_features(task):
    colors_in_train = []
    colors_in_each_train = []
    for uni_task in task['train']:
        inp = uni_task['input']
        colors_unique, color_numbers = np.unique(inp, return_counts=True)

        colors_in_train += list(colors_unique)
        colors_in_each_train.append(colors_unique)

    max_color_task = np.argmax([clrs.shape[0] for clrs in colors_in_each_train])

    input_grid = task['train'][max_color_task]['input']

    train_colors_features, _ = get_color_features(input_grid)

    scaler = MinMaxScaler()
    train_colors_features = scaler.fit_transform(train_colors_features)

    sums = np.sum(train_colors_features, axis=1)

    train_colors_features = train_colors_features[np.argsort(sums)[::-1]]

    return train_colors_features, scaler, np.unique(colors_in_train)


def build_mapping(task, config):
    reverse_functions = []
    for part in ['train', 'test']:
        for uni_task in task[part]:
            if part == 'test':
                reverse_functions.append({})

    if config['reduce_grid']:
        can_reduce_grid = True
        for uni_task in task['train']:
            if uni_task['input'].shape != uni_task['output'].shape:
                can_reduce_grid = False
                break

            inp = uni_task['input']

            colors_rows = []
            line_rows = []

            for i in range(inp.shape[0]):
                if (inp[i] == inp[i][0]).all():
                    colors_rows.append(inp[i][0])
                    line_rows.append(i)

            row_colors, row_counts = np.unique(colors_rows, return_counts=True)

            colors_columns = []
            line_columns = []

            for i in range(inp.shape[1]):
                if (inp[:, i] == inp[0, i]).all():
                    colors_columns.append(inp[0, i])
                    line_columns.append(i)

            column_colors, column_counts = np.unique(colors_columns, return_counts=True)

            if row_colors.shape[0] != 1 or column_colors.shape[0] != 1 or                     row_counts[0] < 2 or column_counts[0] < 2:

                can_reduce_grid = False
                break

            line_rows.append(inp.shape[0])
            line_rows = [-1] + line_rows

            line_columns.append(inp.shape[1])
            line_columns = [-1] + line_columns

            for i in range(len(line_rows) - 1):
                if (line_rows[i] + 1) < line_rows[i + 1]:
                    for j in range(len(line_columns) - 1):
                        if (line_columns[j] + 1) < line_columns[j + 1]:
                            color = inp[line_rows[i] + 1][line_columns[j] + 1]
                            if not (inp[(line_rows[i] + 1):(line_rows[i + 1]),
                                    (line_columns[j] + 1):(line_columns[j + 1])] == color).all():
                                can_reduce_grid = False
                                break

            for i in range(1, len(line_rows) - 1):
                if not (uni_task['input'][line_rows[i]] == uni_task['output'][line_rows[i]]).all():
                    can_reduce_grid = False
                    break

            for j in range(1, len(line_columns) - 1):
                if not (uni_task['input'][:, line_columns[j]] == uni_task['output'][:, line_columns[j]]).all():
                    can_reduce_grid = False
                    break

            if not can_reduce_grid:
                break

        if can_reduce_grid:
            for part in ['train', 'test']:
                for i_task, uni_task in enumerate(task[part]):
                    inp = uni_task['input']

                    colors_rows = []
                    line_rows = []

                    for i in range(inp.shape[0]):
                        if (inp[i] == inp[i][0]).all():
                            colors_rows.append(inp[i][0])
                            line_rows.append(i)

                    row_colors, row_counts = np.unique(colors_rows, return_counts=True)

                    colors_columns = []
                    line_columns = []

                    for i in range(inp.shape[1]):
                        if (inp[:, i] == inp[0, i]).all():
                            colors_columns.append(inp[0, i])
                            line_columns.append(i)

                    column_colors, column_counts = np.unique(colors_columns, return_counts=True)

                    line_rows.append(inp.shape[0])
                    line_rows = [-1] + line_rows

                    line_columns.append(inp.shape[1])
                    line_columns = [-1] + line_columns

                    grid_rows = []
                    grid_columns = []

                    for i in range(len(line_rows) - 1):
                        if (line_rows[i] + 1) < line_rows[i + 1]:
                            grid_rows.append(np.arange(line_rows[i] + 1, line_rows[i + 1]))

                    for j in range(len(line_columns) - 1):
                        if (line_columns[j] + 1) < line_columns[j + 1]:
                            grid_columns.append(np.arange(line_columns[j] + 1, line_columns[j + 1]))

                    uni_task['input'] = reduce_grid(grid_rows, grid_columns, row_colors[0], inp)
                    if part == 'train':
                        uni_task['output'] = reduce_grid(grid_rows, grid_columns, row_colors[0], uni_task['output'])
                    if part == 'test':
                        reverse_functions[i_task]['unreduce_grid'] = partial(unreduce_grid, line_rows[1:-1],
                                                                             line_columns[1:-1], inp.shape[0],
                                                                             inp.shape[1],
                                                                             grid_rows, grid_columns, row_colors[0])

    if config['map_color']:
        go_map_color = True
        train_colors_features, scaler, unique_train_colors = get_train_color_features(task)

        for uni_task in task['test']:
            inp = uni_task['input']
            colors_test = list(np.unique(inp))
            for color in colors_test:
                if not color in unique_train_colors:
                    go_map_color = True

        if go_map_color:
            colors_in_all = [[], []]
            colors_out_all = [[], []]

            for i_part, part in enumerate(['train', 'test']):
                for i_task, uni_task in enumerate(task[part]):

                    input_grid = uni_task['input']

                    colors_features, colors = get_color_features(input_grid)
                    proper_colors = list(np.arange(train_colors_features.shape[0]))
                    colors_features = scaler.transform(colors_features)
                    colors_in = []
                    colors_out = []
                    for i, color in enumerate(colors):
                        color_features = colors_features[i].reshape((1, -1))
                        distances = np.sum(np.power(train_colors_features - color_features, 2), axis=1)
                        closests = list(np.argsort(distances))
                        for closest in closests:
                            if closest in proper_colors:
                                proper_colors.remove(closest)
                                colors_in.append(color)
                                colors_out.append(closest)
                                break

                    if part == 'train':
                        colors_in_all[i_part].append(colors_in)
                        colors_out_all[i_part].append(colors_out)
                    if part == 'test':
                        colors_in_all[i_part].append(colors_out)
                        colors_out_all[i_part].append(colors_in)
                        reverse_functions[i_task]['train_colors_in'] = colors_out
                        reverse_functions[i_task]['train_colors_out'] = colors_in

            unique_test_colors = []

            for i_task, uni_task in enumerate(task['train']):

                output_grid = uni_task['output']
                colors = np.unique(output_grid)

                for color in colors:
                    if not color in unique_train_colors:
                        unique_test_colors.append(color)

            unique_test_colors = np.unique(unique_test_colors)
            colors_out = 9 - np.arange(unique_test_colors.shape[0])
            for part in ['train', 'test']:
                for i_task, uni_task in enumerate(task[part]):
                    if part == 'train':
                        uni_task['input'] = change_color(colors_in_all[0][i_task], colors_out_all[0][i_task],
                                                         uni_task['input'])
                        colors_in_all[0][i_task] += list(unique_test_colors)
                        colors_out_all[0][i_task] += list(colors_out)
                        uni_task['output'] = change_color(colors_in_all[0][i_task], colors_out_all[0][i_task],
                                                          uni_task['output'])
                    if part == 'test':
                        reverse_functions[i_task]['test_colors_in'] = list(colors_out)
                        reverse_functions[i_task]['test_colors_out'] = list(unique_test_colors)

    if config['find_wall']:
        for i_part, part in enumerate(['train', 'test']):
            for i_task, uni_task in enumerate(task[part]):

                input_grid = uni_task['input']

                colors_features, colors = get_color_features(input_grid)

                sums = np.sum(colors_features, axis=1)

                color_wall = colors[np.argsort(sums)[::-1][0]]
                #print(color_wall)
                if color_wall == 0:
                    continue

                colors_in = [0, color_wall]
                colors_out = [color_wall, 0]

                uni_task['input'] = change_color(colors_in, colors_out, input_grid)
                if part == 'train':
                    uni_task['output'] = change_color(colors_in, colors_out, uni_task['output'])
                if part == 'test':
                    reverse_functions[i_task]['return_wall'] = partial(change_color, colors_out,
                                                                       colors_in)

    return task, reverse_functions


# # The search algorithm
# 
# This is the genetics algorithm that tries to guess the DSL-program.
# 
# It tries to randomly modify and do crossover with the programs from the pool. Then we update the pool with the first function here.
# 
# This was grealy inspired by the https://www.kaggle.com/zenol42/dsl-and-genetic-algorithm-applied-to-arc. I would like to thank @zenol42 for that contribution.
# 
# P.S. Please forgive us for these function names. This is too funny to change.

# In[ ]:


def update_pool(task, best_candidates, candidate, num_params):
    start = time.time()
    score = validate_automata(task, candidate, 25, 1)
    is_uncomp = True
    updated_keys = False
    best_candidates_items = list(best_candidates.items())
    for best_score, best_candidates_score in best_candidates_items:
        if product_better(score, best_score):
            # Remove previous best candidate and add the new one
            del best_candidates[best_score]
            best_candidates[score] = [candidate]
            is_uncomp = False  # The candidates are comparable
            updated_keys = True
        if product_better(best_score, score):
            is_uncomp = False  # The candidates are comparable

    if is_uncomp:  # The two candidates are uncomparable
        best_candidates[score].append(candidate)
        best_candidates[score] = sorted(best_candidates[score], key=lambda x: len(x[0]) + len(x[1]))

        if len(best_candidates[score]) > num_params:
            best_candidates[score] = [cand for cand in best_candidates[score] if
            (len(cand[0]) + len(cand[1])) <= len(best_candidates[score][0][0]) + len(best_candidates[score][0][1]) + 2]

    return updated_keys

def generate_asexual_part(best_candidates, temp, part, generate_func, all_colors, config, alpha_mutate_rule_same_type):
    if type(part) == list:
        if np.random.rand() < (1 / (len(part) + 1))**0.75:
            part.append(generate_func(all_colors, best_candidates, temp, config))
        else:
            index = np.random.randint(len(part))
            if np.random.rand() < 0.3:
                part = part[:index] + part[(index + 1):]
            else:
                r_type = None
                if np.random.rand() < alpha_mutate_rule_same_type:
                    r_type = part[index]['type']
                if np.random.rand() < 0.5:
                    part[index] = generate_func(all_colors, best_candidates, temp, config, r_type)
                else:
                    part = part[:index] + [generate_func(all_colors, best_candidates, temp, config, r_type)] + part[index:]
    else:
        part = generate_func(all_colors, best_candidates, temp, config)
    return part


def generate_sexual_part(best_candidates, temp, first, second, generate_func, all_colors, config, alpha_sexual_mutate,
                         alpha_mutate_rule_same_type, alpha_mutate_rule_same_type_one_parameter):
    if type(first) == list:
        if len(first) == 0 and len(second) == 0:
            child = []

        elif len(first) == 0:
            split2 = np.random.randint(len(second))

            if np.random.rand() <= 0.5:
                child = second[split2:]
            else:
                child = second[:split2]

        elif len(second) == 0:
            split1 = np.random.randint(len(first))

            if np.random.rand() <= 0.5:
                child = first[split1:]
            else:
                child = first[:split1]

        else:
            split1 = np.random.randint(len(first))
            split2 = np.random.randint(len(second))

            if np.random.rand() <= 0.5:
                child = first[:split1] + second[split2:]
            else:
                child = second[:split2] + first[split1:]

        if np.random.rand() < alpha_sexual_mutate:
            index = np.random.randint(len(child) + 1)
            if index == len(child):
                child.append(generate_func(all_colors, best_candidates, temp, config))
            else:
                r_type = None
                same_type = np.random.rand() < alpha_mutate_rule_same_type
                one_param_modification = np.random.rand() < alpha_mutate_rule_same_type_one_parameter
                if same_type:
                    r_type = child[index]['type']
                    same_type_rule = generate_func(all_colors, best_candidates, temp, config, r_type)
                    if not one_param_modification:
                        child[index] = same_type_rule
                    else:
                        key = random.choice(list(child[index].keys()))
                        child[index][key] = same_type_rule[key]
                else:
                    if np.random.rand() < 0.5:
                        child[index] = generate_func(all_colors, best_candidates, temp, config)
                    else:
                        child = child[:index] + [generate_func(all_colors, best_candidates, temp, config, r_type)] + child[
                                                                                                                     index:]
    else:
        if np.random.rand() < 0.5:
            child = copy.deepcopy(first)
        else:
            child = copy.deepcopy(second)
    return child


def generate_asexual_program(best_candidates, temp, parent, all_colors, config, alpha_mutate_rule_same_type):
    child = copy.deepcopy(parent)

    gen_functions = [get_random_global_rule, get_random_ca_rule, get_random_split_rule, get_random_merge_rule]
    idx_to_mutate = np.random.choice(len(child), p =[0.4, 0.4, 0.1, 0.1])
    child[idx_to_mutate] = generate_asexual_part(best_candidates, temp, child[idx_to_mutate], gen_functions[idx_to_mutate],
                                                 all_colors, config, alpha_mutate_rule_same_type)
    return child


def generate_sexual_program(best_candidates, temp, first, second, all_colors, config, alpha_sexual_mutate,
                          alpha_mutate_rule_same_type, alpha_mutate_rule_same_type_one_parameter):

    gen_functions = [get_random_global_rule, get_random_ca_rule, get_random_split_rule, get_random_merge_rule]
    what_to_mutate = np.random.choice(len(gen_functions), p=[0.5, 0.5, 0.0, 0.0])

    child = []
    for idx_to_mutate, gen_func in enumerate(gen_functions):
        child.append(generate_sexual_part(best_candidates, temp, first[idx_to_mutate], second[idx_to_mutate],
                                          gen_func, all_colors, config,
                                          (what_to_mutate==idx_to_mutate) * alpha_sexual_mutate, alpha_mutate_rule_same_type,
                                    alpha_mutate_rule_same_type_one_parameter))

    return child


# # The "postprocess" of the solution
# When the solution is found by the genetics we are not done yet.
# 
# We should do 2 more things:
# 
# 1) We continue to train genetics because we would like to create more **different** programs that solve training samples. This will helps us to generate more than 1 prediction of the test output and prevents overfitting. More over, genetics always prioritizes programs that are shorter because it also helps against overfitting. So this is the moment when genetic algorithm could simplify the program that solves training samples.
# 
# 2) We should predict test outputs and do **"mapping back"**. This was already mentioned above.

# In[ ]:


def post_solved_process(task, solved, all_colors, config, reverse_functions, config_mapping):
    test_preds = []

    best_candidates = defaultdict(list)
    update_pool(task, best_candidates, solved, 1)

    start_time = time.time()

    while time.time() - start_time < 30:
        best_scores = list(best_candidates.keys())
        first_score = random.choice(best_scores)
        idx = np.random.choice(len(list(best_candidates[first_score])))
        first = list(best_candidates[first_score])[idx]
        child = generate_asexual_program(best_candidates, 0.5, first, all_colors, config, 0.)
        update_pool(task, best_candidates, child, 1)

    train_colors_features, scaler, _ = get_train_color_features(task)
    print(list(best_candidates.values())[0][0])
    for i_task, uni_task in enumerate(task['test']):
        predictions = []
        for solved in list(best_candidates.values())[0]:
            if reverse_functions[i_task].get('train_colors_in', None):
                inp = uni_task['input']
                colors_unique, color_numbers = np.unique(inp, return_counts=True)

                input_grid = uni_task['input']
                colors_features, colors = get_color_features(input_grid)
                colors_features = scaler.transform(colors_features)

                colors_in = []
                colors_out = []
                if colors_unique.shape[0] <= train_colors_features.shape[0]:
                    proper_colors = list(np.arange(train_colors_features.shape[0]))
                    for i, color in enumerate(colors):
                        color_features = colors_features[i].reshape((1, -1))
                        distances = np.sum(np.power(train_colors_features - color_features, 2), axis=1)
                        closests = list(np.argsort(distances))
                        for closest in closests:
                            if closest in proper_colors:
                                proper_colors.remove(closest)
                                colors_in.append(color)
                                colors_out.append(closest)
                                break

                    colors_in += list(reverse_functions[i_task]['train_colors_out'])
                    colors_out += list(reverse_functions[i_task]['train_colors_in'])

                    input_task = change_color(colors_in, colors_out, uni_task['input'])

                    trace = trace_param_automata(input_task, solved, 25, 0)
                    t_pred = trace[-1][0]

                    if not reverse_functions[i_task].get('unreduce_grid', None) is None:
                        t_pred = reverse_functions[i_task]['unreduce_grid'](t_pred)
                    if not reverse_functions[i_task].get('train_colors_in', None) is None:
                        colors_in = reverse_functions[i_task]['train_colors_in'] + reverse_functions[i_task][
                            'test_colors_in']
                        colors_out = reverse_functions[i_task]['train_colors_out'] + reverse_functions[i_task][
                            'test_colors_out']
                        t_pred = change_color(colors_in, colors_out, t_pred)
                    predictions.append(t_pred)
                else:
                    closests_to = [[] for _ in range(train_colors_features.shape[0])]
                    for i, color in enumerate(colors):
                        color_features = colors_features[i].reshape((1, -1))
                        distances = np.sum(np.power(train_colors_features - color_features, 2), axis=1)
                        closest = np.argsort(distances)[0]
                        closests_to[closest].append(color)

                    for i in range(len(closests_to)):
                        if len(closests_to[i]) == 0:
                            closests_to[i] = [-1]

                    answers = []
                    for color_map in product(*closests_to):
                        input_task = np.zeros_like(uni_task['input'])

                        for i, color in enumerate(list(color_map)):
                            input_task[uni_task['input'] == color] = i

                        colors_in = np.array(list(color_map) + reverse_functions[i_task]['test_colors_out'])
                        colors_out = list(np.arange(colors_in.shape[0])) + reverse_functions[i_task]['test_colors_in']

                        trace = trace_param_automata(input_task, solved, 25, 0)
                        t_pred = trace[-1][0]
                        t_pred = change_color(colors_out, colors_in, t_pred)
                        if not reverse_functions[i_task].get('unreduce_grid', None) is None:
                            t_pred = reverse_functions[i_task]['unreduce_grid'](t_pred)

                        answers.append(t_pred)

                    shapes = [ans.shape for ans in answers]
                    diff_shapes, counts = np.unique(shapes, return_counts=True, axis=0)
                    best_shape = diff_shapes[np.argmax(counts)]
                    answers = [ans for ans in answers if ans.shape == tuple(best_shape)]
                    final_answer = np.zeros((10, best_shape[0], best_shape[1]))
                    for i in range(10):
                        for ans in answers:
                            final_answer[i][ans == i] += 1
                    final_answer = np.argmax(final_answer, axis=0)

                    predictions.append(final_answer)

            else:
                inp = uni_task['input']

                trace = trace_param_automata(inp, solved, 25, 0)
                t_pred = trace[-1][0]

                if not reverse_functions[i_task].get('unreduce_grid', None) is None:
                    t_pred = reverse_functions[i_task]['unreduce_grid'](t_pred)

                if not reverse_functions[i_task].get('return_wall', None) is None:
                    t_pred = reverse_functions[i_task]['return_wall'](t_pred)

                predictions.append(t_pred)


        shapes = [ans.shape for ans in predictions]
        diff_shapes, counts = np.unique(shapes, return_counts=True, axis=0)
        best_shape = diff_shapes[np.argmax(counts)]
        predictions = [ans for ans in predictions if ans.shape == tuple(best_shape)]

        unique_preds, nums = np.unique(np.array(predictions), return_counts=True, axis=0)

        indexes = np.argsort(nums)[::-1]

        preds = unique_preds[indexes[:3]]
        preds = [pr for pr in preds]
        test_preds.append(preds)

    return test_preds


# ## We are almost ready!
# 
# Here the function do the genetic algorithm: it produces samples, mutations, crossovers and updates the pool.
# It also checks if the task is solved by some program.
# 
# If it solved it passes the program to the "postprocess" that you can find above.

# In[ ]:


def train_model(name, task, params, time_for_task, config_mapping, print_stats=False):
    alpha_asexual_mutation = params['alpha_asexual_mutation']
    alpha_sexual_mutate = params['alpha_sexual_mutate']
    alpha_mutate_rule_same_type = params['alpha_mutate_rule_same_type']
    alpha_mutate_rule_same_type_one_parameter = params['alpha_mutate_rule_same_type_one_parameter']
    add_random = params['add_random']
    num_params = params['num_params']
    start_time = time.time()
    param_name = str([alpha_asexual_mutation,
                      alpha_sexual_mutate,
                      alpha_mutate_rule_same_type,
                      alpha_mutate_rule_same_type_one_parameter,
                      add_random])

    task, reverse_functions = build_mapping(task, config_mapping)

    all_colors, config = get_task_metadata(task)

    print(f'Trying to solve {name}... {param_name}')

    best_candidates = defaultdict(list)
    test_preds = []
    population = generate_population(all_colors, config, size=2500)

    for cand in population:
        if time.time() - start_time >= time_for_task:
            break
        update_pool(task, best_candidates, cand, num_params)

    i_iteration = 0

    while True:
        temp = min(0.9, (time.time() - start_time) / 500)

        if np.random.rand() < add_random:
            split_rule = get_random_split_rule(all_colors, {}, 0, config)
            merge_rule = get_random_merge_rule(all_colors, {}, 0, config)
            child = [generate_random_global(all_colors, best_candidates, temp, config),
                     generate_random_ca(all_colors, best_candidates, temp, config), split_rule, merge_rule]

        else:
            best_scores = list(best_candidates.keys())
            first_score = random.choice(best_scores)
            first = random.choice(list(best_candidates[first_score]))
            if np.random.rand() < alpha_asexual_mutation:
                child = generate_asexual_program(best_candidates, temp, first, all_colors, config,
                                               alpha_mutate_rule_same_type)
            else:

                second_score = random.choice(best_scores)
                second = random.choice(list(best_candidates[second_score]))

                child = generate_sexual_program(best_candidates, temp, first, second, all_colors, config,
                                              alpha_sexual_mutate,
                                              alpha_mutate_rule_same_type,
                                              alpha_mutate_rule_same_type_one_parameter)

        updated_keys = update_pool(task, best_candidates, child, num_params)

        if i_iteration % 100 == 0:
            solved = None
            max_scores = np.zeros(len(list(best_candidates.keys())[0]))
            for score, params in best_candidates.items():
                max_scores = np.maximum(max_scores, score)
                if np.mean(score) == 1.:
                    solved = params[0]
                    break

            # print(np.round(max_scores, 4), len(list(best_candidates.keys())), np.round(temp, 3),
            #      num_successful_sexuals, num_sexuals, num_successful_asexuals, num_asexuals)

            if solved is not None:
                break

        if time.time() - start_time >= time_for_task:
            break
        i_iteration += 1

    if solved is not None:
        print(f'Solved {name}', time.time() - start_time)

        test_preds = post_solved_process(task, solved, all_colors, config, reverse_functions,
                                         config_mapping)


    else:
        for task_test in task['test']:
            test_preds.append([np.zeros_like(task_test['input'])])
    return solved, test_preds


# ## We are ready to solve something!

# The code below just solves all the tasks and generates a submission file. This is not quite interesting except one detail:
# we tries to solve the task with 2 different "color mappings" and then merge the solutions. I don't know how much it helps.

# In[ ]:


if False:
    task_ids = train_task_ids
    mode = 'training'
elif False:
    task_ids = valid_task_ids
    mode = 'evaluation'
else:
    task_ids = test_task_ids
    mode = 'test'

all_tasks = []

for task_id in range(len(task_ids)):
    name = task_ids[task_id]
    task = load_data(f'{name}.json', phase=mode)
    all_tasks.append(task_id)

good_tasks = np.arange(100) # here we just choose what task we solve

# We give this number of seconds to each task. Given the multiprocessing it's about 6 hours for all the tasks.
time_for_task = 100

# Here are some parameters of the genetics. Better not to touch them, it may be dangerous!
num_params = 5
alpha_asexual_mutation = 0.5
alpha_sexual_mutate = 0.5
alpha_mutate_rule_same_type = 0.5
alpha_mutate_rule_same_type_one_parameter = 0.0
alpha_add_random = 0.05
test_predictions = []


def try_to_solve_task(task_id_big):
    
    #Here we get the numbers from 0 to 200 so we solve the 100 tasks with 2 different mapping configs
    if task_id_big >= 100:
        config_mapping = {'map_color': True, 'reduce_grid': True, 'find_wall': False}
    else:
        config_mapping = {'map_color': False, 'reduce_grid': True, 'find_wall': True}

    task_id = task_id_big % 100

    name = task_ids[task_id]
    task = load_data(f'{name}.json', phase=mode)

    exclude_list = []
    
    # Here is the hack: we check the name of the test task to understand whether it is the public or private test. 
    # It's private we solve all the tasks, otherwise we solve only first 4 task (to make sure everything works)
    is_public_test = ('00576224' in test_task_ids)
    
    if not task_id in good_tasks or (task_id in exclude_list) or (is_public_test and task_id > 3):
        test_preds = []
        if task_id in exclude_list:
            for task_test in task['test']:
                test_preds.append([np.ones_like(task_test['input'])])
        else:
            for task_test in task['test']:
                test_preds.append([np.zeros_like(task_test['input'])])

        return (test_preds, False), task_id_big

    params = {}
    params['alpha_asexual_mutation'] = alpha_asexual_mutation
    params['alpha_sexual_mutate'] = alpha_sexual_mutate
    params['alpha_mutate_rule_same_type'] = alpha_mutate_rule_same_type
    params['alpha_mutate_rule_same_type_one_parameter'] = alpha_mutate_rule_same_type_one_parameter
    params['add_random'] = alpha_add_random
    params['num_params'] = num_params
    solved, test_preds = train_model(name, task, params, time_for_task, config_mapping)

    return (test_preds, solved is not None), task_id_big


def main():
    answers = {}
    solved_tasks = 0

    if ENABLE_MULTIPROCESSING:
        pool = multiprocessing.Pool()
        iterator = pool.imap_unordered(try_to_solve_task, range(2*len(task_ids)))
    else:
        iterator = map(try_to_solve_task, range(2*len(task_ids)))


    for (test_preds, solved), answer_id in iterator:
        answers[answer_id] = test_preds

        if solved:
            solved_tasks += 1
            print(answer_id)
            print(test_preds)

    if ENABLE_MULTIPROCESSING:
        pool.close()
        pool.join()

    return answers, solved_tasks

answers, solved_tasks = main()

# Here we merge the answers from 2 mapping configs
map_color_answers = {k:answers[k] for k in answers if k<100}

find_wall_answers = {k:answers[k] for k in answers if k>=100}

test_map_color_predictions = []
for answer_id in sorted(map_color_answers.keys()):
    test_map_color_predictions += map_color_answers[answer_id]

test_find_wall_predictions = []
for answer_id in sorted(find_wall_answers.keys()):
    test_find_wall_predictions += find_wall_answers[answer_id]


def flattener(preds):
    preds = copy.deepcopy(preds)
    str_final = ''
    str_preds = []
    for pred in preds:

        str_pred = str([row for row in pred])
        str_pred = str_pred.replace(', ', '')
        str_pred = str_pred.replace('[[', '|')
        str_pred = str_pred.replace('][', '|')
        str_pred = str_pred.replace(']]', '|')
        str_preds.append(str_pred)
    return " ".join(str_preds)


test_map_color_predictions = [[[list(pred) for pred in test_pred] for test_pred in test_task] for test_task in test_map_color_predictions]
test_find_wall_predictions = [[[list(pred) for pred in test_pred] for test_pred in test_task] for test_task in test_find_wall_predictions]

submission = pd.read_csv(data_path / "sample_submission.csv")

for idx in range(len(test_map_color_predictions)):
    map_color_preds = test_map_color_predictions[idx]
    find_wall_preds = test_find_wall_predictions[idx]

    if np.mean(map_color_preds) == 0 and np.mean(find_wall_preds) == 0:
        submission.loc[idx, "output"] = "|0|"
    elif np.mean(map_color_preds) > 0 and np.mean(find_wall_preds) == 0:
        submission.loc[idx, "output"] = flattener(map_color_preds)
    elif np.mean(map_color_preds) == 0 and np.mean(find_wall_preds) > 0:
        submission.loc[idx, "output"] = flattener(find_wall_preds)
    else:
        preds_here = find_wall_preds + map_color_preds

        preds_here = copy.deepcopy(preds_here)
        str_final = ''
        str_preds = []
        for pred in preds_here:
            str_pred = str([row for row in pred])
            str_pred = str_pred.replace(', ', '')
            str_pred = str_pred.replace('[[', '|')
            str_pred = str_pred.replace('][', '|')
            str_pred = str_pred.replace(']]', '|')
            str_preds.append(str_pred)

        unique_preds, nums = np.unique(str_preds, return_counts=True)

        indexes = np.argsort(nums)[::-1]

        preds = unique_preds[indexes[:3]]
        preds = [pr for pr in preds]

        submission.loc[idx, "output"] = " ".join(preds)

print(submission.head())

submission.to_csv("submission.csv", index=False)

print(solved_tasks)


# # Let's make some fun!
# 
# Since or submission file is generated, now we can show how it actually works and solves some tasks.

# In[ ]:


params = {}
num_params = 5
alpha_asexual_mutation = 0.5
alpha_sexual_mutate = 0.5
alpha_mutate_rule_same_type = 0.5
alpha_mutate_rule_same_type_one_parameter = 0.0
alpha_add_random = 0.05
params['alpha_asexual_mutation'] = alpha_asexual_mutation
params['alpha_sexual_mutate'] = alpha_sexual_mutate
params['alpha_mutate_rule_same_type'] = alpha_mutate_rule_same_type
params['alpha_mutate_rule_same_type_one_parameter'] = alpha_mutate_rule_same_type_one_parameter
params['add_random'] = alpha_add_random
params['num_params'] = num_params
config_mapping = {'map_color': False, 'reduce_grid': True, 'find_wall': True}
is_public_test = ('00576224' in test_task_ids)


# Let's start with a simple one: 070dd51e

# In[ ]:


if is_public_test:
    name = '070dd51e'
    task = load_data(f'{name}.json', phase='test')

    plot_task(task)

    solved, test_preds = train_model(name, task, params, time_for_task=2000, config_mapping=config_mapping)


# So it was simple because there is a command in the DSL called "unity" - it doesn in fact what is required in this task. 
# Let's understand the program.
# 
# 

# In[ ]:


if is_public_test and (solved is not None):
    print(solved[2])
    for rule in solved[0]:
        print(rule)
    for rule in solved[1]:
        print(rule)
    print(solved[1])
    print(solved[3])


# The first row is a split rule. 
# 
# The last row is a merge rule.
# 
# From the second to pre-last row are global rules and CA-rules. 

# ### Let's try something harder!

# In[ ]:


if is_public_test:
    name = '0d87d2a6'
    task = load_data(f'{name}.json', phase='test')

    plot_task(task)

    solved, test_preds = train_model(name, task, params, time_for_task=2000, config_mapping=config_mapping)


# In[ ]:


if is_public_test and (solved is not None):
    print(solved[2])
    for rule in solved[0]:
        print(rule)
    for rule in solved[1]:
        print(rule)
    print(solved[1])
    print(solved[3])


# ### Finally, let's solve something using multi-grid DSL

# In[ ]:


if is_public_test:

    name = '08ed6ac7'
    task = load_data(f'{name}.json', phase='training')

    plot_task(task)

    solved, test_preds = train_model(name, task, params, time_for_task=2000, config_mapping=config_mapping)


# In[ ]:


if is_public_test and (solved is not None):

    print(solved[2])
    for rule in solved[0]:
        print(rule)
    for rule in solved[1]:
        print(rule)
    print(solved[1])
    print(solved[3])


# So what this program does? (Besides junky commands)
# 
# It splits the input grid with gray figures into 4 different grids that are sorted by the size of the figure.
# 
# Then it applies the rule "map color" that maps gray color to some color. It applies it 4 times to different grids so it maps gray to blue in grid 0, gray to red in grid 1 and so on. Then it merges everything back and we obtain the right answer.

# ### A few words about C++

# C++ version works 100x times faster but I think here it's more convienient to see all the parts of the algorithm here. C++ version would solve more tasks in the public and private test in the given 400 seconds. This version should be lucky to solve some hard tasks that should be solved with complex programs.
# 
# Thanks everyone for your interest in our solution!
