#!/usr/bin/env python
# coding: utf-8

# In[93]:


def prepare_tf():
    get_ipython().system('pip uninstall tensorflow -y')
    get_ipython().system('pip install tensorflow-gpu==2.0.0-alpha0')
    from tensorflow.python.ops import control_flow_util
    control_flow_util.ENABLE_CONTROL_FLOW_V2 = True
    from tensorflow.python.client import device_lib 
    print(device_lib.list_local_devices())


# In[29]:


import tensorflow as tf
print(tf.__version__)


# In[94]:


import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import os
print(os.listdir("../input"))
print(os.listdir("../input/train/"))
print(len(os.listdir("../input/train/train/")))
sample_submission_file = pd.read_csv("../input/sample_submission_file.csv")


# In[95]:


print(len(os.listdir("../input/extraimages/extraimages/")))


# In[96]:


df_sample_submission_file.head()


# In[97]:


def append_ext(fn):
    return fn+".jpg"

testdf=pd.read_csv("../input/sample_submission_file.csv",dtype=str)
testdf["Id"]=testdf["Id"].apply(append_ext)


# In[98]:


CLASS_MODE = 'categorical'


# In[99]:


from pathlib import Path
from PIL import Image

def read_pil_image(img_path, height, width):
        with open(img_path, 'rb') as f:
            return np.array(Image.open(f).convert('RGB').resize((width, height)))

def load_all_images(dataset_path, height, width, img_ext='jpg'):
    return np.array([read_pil_image(str(p), height, width) for p in 
                                    Path(dataset_path).rglob("*."+img_ext)]) 


# In[144]:


IMAGE_HT_WID=96
BATCH_SIZE = 32 #100 

from keras_preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import RMSprop
train_datagen = ImageDataGenerator(
                               rotation_range=8,
                               width_shift_range=0.1,
                               height_shift_range=0.1,
                               shear_range=0.01,
                               zoom_range=[0.9, 1.25],
                               horizontal_flip=True,
                               vertical_flip=False,
                              channel_shift_range = 0.1,
                              fill_mode='nearest',
                              #brightness_range=[0.5, 1.5],
                               validation_split=0.25,
                               rescale=1./255)


# In[145]:


train_generator=train_datagen.flow_from_directory(
                    directory="../input/train/train/",
                    subset="training",
                   batch_size=BATCH_SIZE,
                    seed=42,
                    shuffle=True,
                    class_mode='categorical',
                    target_size=(IMAGE_HT_WID,IMAGE_HT_WID))

valid_generator=train_datagen.flow_from_directory(
                    directory="../input/train/train/",
                    subset="validation",
                    batch_size=BATCH_SIZE,
                    seed=42,
                    shuffle=True,
                    class_mode='categorical',
                    target_size=(IMAGE_HT_WID,IMAGE_HT_WID))


# In[146]:


test_datagen=ImageDataGenerator(rescale=1./255.)
test_generator=test_datagen.flow_from_dataframe(
dataframe=testdf,
directory="../input/test/test",
x_col="Id",
y_col=None,
batch_size=32,
seed=42,
shuffle=False,
class_mode=None,
target_size=(IMAGE_HT_WID,IMAGE_HT_WID))


# In[114]:


import tensorflow as tf
keras = tf.keras


# In[115]:


np.random.seed(42)
import random as rn
rn.seed(12345)
session_conf = tf.ConfigProto(intra_op_parallelism_threads=1,
                           inter_op_parallelism_threads=1)

from keras import backend as K

tf.set_random_seed(1234)

sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)
K.set_session(sess)


# In[116]:


#https://www.tensorflow.org/tutorials/images/transfer_learning

from tensorflow import keras
import tensorflow as tf
keras = tf.keras
base_model = tf.keras.applications.MobileNetV2(input_shape=(IMAGE_HT_WID,IMAGE_HT_WID, 3),
                                               include_top=False, 
                                               weights='imagenet')
base_model.trainable = False
print(base_model.summary())
model = tf.keras.Sequential([
  base_model,
  keras.layers.GaussianNoise(0.2),  
  keras.layers.GlobalAveragePooling2D(),
  keras.layers.Dense(5, activation='sigmoid')
])

model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), metrics=['accuracy'])

print(model.summary())
len(base_model.layers)


# In[117]:


reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, 
                                                                    patience=3, verbose=2, mode='auto',
                                                                    min_lr=1e-6)

early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', 
                                            # min_delta=0, 
                                             patience=6, verbose=2, mode='auto',
                                             baseline=None, restore_best_weights=True)


# In[147]:


from keras.models import Sequential
from keras_preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from keras import regularizers, optimizers
model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=(IMAGE_HT_WID,IMAGE_HT_WID,3)))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(output_dim=5, activation='sigmoid'))
model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss="categorical_crossentropy",metrics=["accuracy"])


# In[148]:


STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size
STEP_SIZE_TEST=test_generator.n//test_generator.batch_size
model.fit_generator(generator=train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=valid_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=10
                   )


# In[153]:


model.evaluate_generator(generator=valid_generator,
steps=STEP_SIZE_VALID)


# In[169]:


test_generator.reset()
pred=model.predict_generator(test_generator,
steps=STEP_SIZE_TEST,
verbose=1)


# In[182]:


batch_size=32
nb_validation_samples=1412
steps = nb_validation_samples / batch_size
predicted_class_indices = model.predict_generator(valid_generator, steps)


# In[177]:


labels = (train_generator.class_indices)
labels


# In[179]:


labels = dict((v,k) for k,v in labels.items())
labels


# In[184]:


predicted_class_indices[:10]


# In[191]:


import numpy as np
predicted_class_indices=hash((np.array(predicted_class_indices[:])))
predictions = [labels[k] for k in predicted_class_indices]
filenames=test_generator.filenames
results=pd.DataFrame({"Category":predictions,
                      "id":filenames})
#subm = pd.merge(df_test, results, on='file_name')[['id','Category']]


# In[92]:


results.head()


# In[ ]:


results.Category.value_counts()


# In[ ]:


results.loc[:,'id'] = results.id.str.replace('0/','')


# In[ ]:


results.head()


# In[ ]:


results.to_csv("submission.csv",index=False)

