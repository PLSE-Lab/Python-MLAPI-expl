#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


# In[ ]:


import numpy as np 
import pandas as pd 
import seaborn as sns  
import matplotlib.pyplot as plt
import time
from subprocess import check_output
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_recall_curve
from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_curve, auc
import warnings
from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
from sklearn.feature_selection import RFECV
from sklearn.model_selection import GridSearchCV
warnings.filterwarnings('ignore')


# In[ ]:


data = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')
data.head()


# In[ ]:


label = LabelEncoder()
label.fit(data.diagnosis.drop_duplicates())
data.diagnosis = label.transform(data.diagnosis)


# In[ ]:


y = data.diagnosis          
list = ['Unnamed: 32','id','diagnosis']
x = data.drop(list,axis = 1 )


# In[ ]:


f,ax = plt.subplots(figsize=(18, 18))
sns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)


# In[ ]:


drop_list1 = ['perimeter_mean','radius_mean','compactness_mean','concave points_mean','radius_se','perimeter_se','radius_worst','perimeter_worst','compactness_worst','concave points_worst','compactness_se','concave points_se','texture_worst','area_worst']
x_1 = x.drop(drop_list1,axis = 1 )  
x_1.head()


# In[ ]:


x_train, x_test, y_train, y_test = train_test_split(x_1, y, test_size=0.3, random_state=42)


# In[ ]:


kfolds = 4 
split = KFold(n_splits=kfolds, shuffle=True, random_state=42)
base_models = [("DT_model", DecisionTreeClassifier(random_state=42)),
               ("RF_model", RandomForestClassifier(random_state=42,n_jobs=-1)),
               ("LR_model", LogisticRegression(random_state=42,n_jobs=-1)),
               ("XGB_model", XGBClassifier(random_state=42, n_jobs=-1))]
for name,model in base_models:
    clf = model
    cv_results = cross_val_score(clf, 
                                 x_1, y, 
                                 cv=split,
                                 scoring="accuracy",
                                 n_jobs=-1)
    min_score = round(min(cv_results), 4)
    max_score = round(max(cv_results), 4)
    mean_score = round(np.mean(cv_results), 4)
    std_dev = round(np.std(cv_results), 4)
    print(f"{name} cross validation accuarcy score: {mean_score} +/- {std_dev} (std) min: {min_score}, max: {max_score}")


# In[ ]:


params_dict={'n_estimators':[20,30,40],'booster':['gbtree','dart'],'max_depth':[5,10],'n_jobs':[-1],'random_state':[0,1]}
clf_xgb=GridSearchCV(estimator=XGBClassifier(),param_grid=params_dict,scoring='neg_mean_absolute_error')
clf_xgb.fit(x_train,y_train)
pred=clf_xgb.predict(x_test)
print((mean_absolute_error(pred,y_test)))


# In[ ]:


clf_xgb.best_params_


# In[ ]:


xgb =  XGBClassifier(n_estimators=30,max_depth=10,n_jobs=-1,random_state=0)
clr_xgb=xgb.fit(x_train,y_train)
predict = clr_xgb.predict(x_test)
print('Accuracy is: ',accuracy_score(y_test,predict))


# In[ ]:


cr = classification_report(y_test,predict)
print(cr)


# In[ ]:


rfecv = RFECV(estimator = model, step = 1, cv = 5, scoring = 'accuracy')
rfecv = rfecv.fit(x_train, y_train)
y_pred = rfecv.predict(x_test)

print("Training Accuracy :", rfecv.score(x_train, y_train))
print("Testing Accuracy :", rfecv.score(x_test, y_test))

