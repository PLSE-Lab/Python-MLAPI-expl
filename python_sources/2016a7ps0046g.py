#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import sys


# In[ ]:


import numpy as np
import pandas as pd
get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt
import seaborn as sns


# In[ ]:


#import sklearn.preprocessing as sk
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn import svm


# In[ ]:


dataf=pd.read_csv("../input/dataset.csv", sep=",")
df = dataf
df


# In[ ]:


for x in range(0,1031):
    for y in range(0,24):
        if df.iloc[x][y]=='?':
            print(x,y)


# In[ ]:


df.replace('?',np.NaN)

df['Account1'].replace({'?':'ad'},inplace=True)
df['Monthly Period'].replace({'?':18},inplace=True)
df['History'].replace({'?':'c2'},inplace=True)
df['Motive'].replace({'?':'p3'},inplace=True)
df['Credit1'].replace({'?':3000},inplace=True)
df['InstallmentRate'].replace({'?':4},inplace=True)
df['Tenancy Period'].replace({'?':4},inplace=True)
df['Age'].replace({'?':26},inplace=True)
df['InstallmentCredit'].replace({'?':5.0},inplace=True)
df['Yearly Period'].replace({'?':1},inplace=True)

s = pd.Series(df['Credit1'])
s[979] = 2000
s[1016] = 392
df['Credit1'] = s

t = pd.Series(df['Age'])
t[1] = 30
t[1015] = 27
df['Age'] = t

u = pd.Series(df['InstallmentCredit'])
u[921] = 20
u[1016] = 1.6
df['InstallmentCredit'] = u

v = pd.Series(df['Yearly Period'])
v[26] = 4
v[1002] = 1.5
v[1028] = 0.8
df['Yearly Period'] = v

df.drop(['Class', 'id'],1,inplace=True)


# In[ ]:


df.head()


# In[ ]:


#dataf=pd.read_csv("./dataset.csv", sep=",")
#df = dataf
df.drop(["Gender&Type", "Housing", "Plan", "Sponsors"],1,inplace=True)
df.drop(["History", "Account2", "Employment Period", "Motive", "InstallmentRate", "Post", "Age"],1,inplace=True)
df = pd.get_dummies(df, columns = [ "Monthly Period",  "Tenancy Period", "#Credits","Plotsize", "#Authorities", "Account1", "InstallmentCredit", "Phone", "Expatriate" ])
#print(df)
#"Yearly Period", "Credit1"


# In[ ]:


from sklearn import preprocessing
#Performing Min_Max Normalization
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(df)
dataN1 = pd.DataFrame(np_scaled)
dataN1.head()


# In[ ]:





# In[ ]:


from sklearn.decomposition import PCA
pca1 = PCA(n_components=2)
pca1.fit(dataN1)
T1 = pca1.transform(dataN1)


# In[ ]:


from sklearn.cluster import KMeans

wcss = []
for i in range(2, 10):
    kmean = KMeans(n_clusters = i, random_state = 42)
    kmean.fit(dataN1)
    wcss.append(kmean.inertia_)
    
plt.plot(range(2, 10),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()


# In[ ]:


plt.figure(figsize=(16, 8))
preds1 = []
for i in range(2, 7):
    kmean = KMeans(n_clusters = i, random_state = 42)
    kmean.fit(dataN1)
    pred = kmean.predict(dataN1)
    preds1.append(pred)
    
    plt.subplot(2, 5, i - 1)
    plt.title(str(i)+" clusters")
    plt.scatter(T1[:, 0], T1[:, 1], c=pred)
    
    centroids = kmean.cluster_centers_
    centroids = pca1.transform(centroids)
    plt.plot(centroids[:, 0], centroids[:, 1], 'b+', markersize=30, color = 'brown', markeredgewidth = 3)


# In[ ]:


colors = ['red','green','blue','yellow','purple','pink','palegreen','violet','cyan']


# In[ ]:


plt.figure(figsize=(16, 8))

kmean = KMeans(n_clusters = 5, random_state = 42)
kmean.fit(dataN1)
pred = kmean.predict(dataN1)
pred_pd = pd.DataFrame(pred)
arr = pred_pd[0].unique()

for i in arr:
    meanx = 0
    meany = 0
    count = 0
    for j in range(len(pred)):
        if i == pred[j]:
            count+=1
            meanx+=T1[j,0]
            meany+=T1[j,1]
            plt.scatter(T1[j, 0], T1[j, 1], c=colors[i])
    meanx = meanx/count
    meany = meany/count
    plt.annotate(i,(meanx, meany),size=30, weight='bold', color='black', backgroundcolor=colors[i])


# In[ ]:


from sklearn.neighbors import NearestNeighbors

ns = 80                                                 # If no intuition, keep No. of dim + 1
nbrs = NearestNeighbors(n_neighbors = ns).fit(dataN1)
distances, indices = nbrs.kneighbors(dataN1)

kdist = []

for i in distances:
    avg = 0.0
    for j in i:
        avg += j
    avg = avg/(ns-1)
    kdist.append(avg)

kdist = sorted(kdist)
plt.plot(indices[:,0], kdist)


# In[ ]:


from sklearn.cluster import DBSCAN
dbscan = DBSCAN(eps=2, min_samples=1)
pred = dbscan.fit_predict(dataN1)
plt.scatter(T1[:, 0], T1[:, 1], c=pred)


# In[ ]:


labels1 = dbscan.labels_
#labels1 = labels1[labels1 >= 0]                            #Remove Noise Points
labels1, counts1 = np.unique(labels1, return_counts=True)
print(len(labels1))
print(labels1)
print(len(counts1))
print(counts1)


# In[ ]:


from sklearn.cluster import AgglomerativeClustering as AC
aggclus = AC(n_clusters = 3,affinity='euclidean',linkage='ward',compute_full_tree='auto')
y_aggclus= aggclus.fit_predict(dataN1)
plt.scatter(T1[:, 0], T1[:, 1], c=y_aggclus)


# In[ ]:


from scipy.cluster.hierarchy import dendrogram, linkage, cut_tree
from scipy.cluster.hierarchy import fcluster
linkage_matrix1 = linkage(dataN1, "ward",metric="euclidean")
ddata1 = dendrogram(linkage_matrix1,color_threshold=10)


# In[ ]:


from sklearn.datasets import load_digits
from sklearn.feature_selection import SelectKBest, chi2


# In[ ]:


dataf=pd.read_csv("../input/dataset.csv", sep=",")
df = dataf

df.drop(['Class', 'id'],1,inplace=True)

data1 = df

data1 = pd.get_dummies(data1, columns = ["Account1","History", "Motive", "Account2", "Employment Period", "InstallmentRate", "Gender&Type",  "Sponsors", "Tenancy Period", "Plotsize", "Plan", "Housing", "#Credits", "Post", "#Authorities", "Phone", "Expatriate",])
df = data1
df.head()


# In[ ]:


#df = pd.read_csv("./data.csv", sep=",")


#X.shape

ddf = pd.read_csv("../input/dataset.csv", sep=",")
y = ddf['Class'][:175]
ddf.drop(['id','Class'], 1, inplace=True)

ddf.replace('?',np.NaN)

ddf['Account1'].replace({'?':'ad'},inplace=True)
ddf['Monthly Period'].replace({'?':18},inplace=True)
ddf['History'].replace({'?':'c2'},inplace=True)
ddf['Motive'].replace({'?':'p3'},inplace=True)
ddf['Credit1'].replace({'?':3000},inplace=True)
ddf['InstallmentRate'].replace({'?':4},inplace=True)
ddf['Tenancy Period'].replace({'?':4},inplace=True)
ddf['Age'].replace({'?':26},inplace=True)
ddf['InstallmentCredit'].replace({'?':5.0},inplace=True)
ddf['Yearly Period'].replace({'?':1},inplace=True)

s = pd.Series(ddf['Credit1'])
s[979] = 2000
s[1016] = 392
ddf['Credit1'] = s

t = pd.Series(ddf['Age'])
t[1] = 30
t[1015] = 27
ddf['Age'] = t

u = pd.Series(ddf['InstallmentCredit'])
u[921] = 20
u[1016] = 1.6
ddf['InstallmentCredit'] = u

v = pd.Series(ddf['Yearly Period'])
v[26] = 4
v[1002] = 1.5
v[1028] = 0.8
ddf['Yearly Period'] = v

data1 = ddf
data1 = pd.get_dummies(data1, columns = ["Account1", "History", "Motive", "Account2", "Employment Period", "InstallmentRate", "Gender&Type",  "Sponsors", "Tenancy Period", "Plotsize", "Plan", "Housing", "#Credits", "Post", "#Authorities", "Phone", "Expatriate",])
ddf = data1

from sklearn import preprocessing
#Performing Min_Max Normalization
min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(ddf)
dataN1 = pd.DataFrame(np_scaled)

X = dataN1[:175]


# In[ ]:


a = SelectKBest(chi2, k=10)
X_new = a.fit_transform(X,y)


# In[ ]:


X_new


# In[ ]:


l = a.transform(dataN1)


# In[ ]:


dataN2 = l


# In[ ]:


from sklearn.decomposition import PCA
pca1 = PCA(n_components=2)
pca1.fit(dataN2)
T1 = pca1.transform(dataN2)


# In[ ]:


from sklearn.cluster import KMeans

wcss = []
for i in range(2,10):
    kmean = KMeans(n_clusters = i, random_state = 42)
    kmean.fit(dataN2)
    wcss.append(kmean.inertia_)
    
plt.plot(range(2,10),wcss)
plt.title('The Elbow Method')
plt.xlabel('Number of clusters')
plt.ylabel('WCSS')
plt.show()

plt.figure(figsize=(16, 8))
preds1 = []
for i in range(2,7):
    kmean = KMeans(n_clusters = i, random_state = 42)
    kmean.fit(dataN2)
    pred = kmean.predict(dataN2)
    preds1.append(pred)
    
    plt.subplot(2, 5, i - 1)
    plt.title(str(i)+" clusters")
    plt.scatter(T1[:, 0], T1[:, 1], c=pred)
    
    centroids = kmean.cluster_centers_
    centroids = pca1.transform(centroids)
    plt.plot(centroids[:, 0], centroids[:, 1], 'b+', markersize=30, color = 'brown', markeredgewidth = 3)
    
colors = ['red','green','blue','yellow','purple','pink','palegreen','violet','cyan']

plt.figure(figsize=(16, 8))

kmean = KMeans(n_clusters = 5, random_state = 42)
kmean.fit(dataN2)
pred = kmean.predict(dataN2)
pred_pd = pd.DataFrame(pred)
arr = pred_pd[0].unique()

for i in arr:
    meanx = 0
    meany = 0
    count = 0
    for j in range(len(pred)):
        if i == pred[j]:
            count+=1
            meanx+=T1[j,0]
            meany+=T1[j,1]
            plt.scatter(T1[j, 0], T1[j, 1], c=colors[i])
    meanx = meanx/count
    meany = meany/count
    plt.annotate(i,(meanx, meany),size=30, weight='bold', color='black', backgroundcolor=colors[i])


# In[ ]:


ddf = pd.read_csv("../input/dataset.csv", sep=",")
res = []
for i in range(len(pred)):
    if pred[i] == 0:
        res.append(2)
    elif pred[i] == 1:
        res.append(0)
    elif pred[i] == 2:
        res.append(2)
    elif pred[i] == 3:
        res.append(1)
    elif pred[i] == 4:
        res.append(0)

a=0
for x in range(0,175):
    if ddf['Class'][x]==res[x]:
        a+=1
a


# In[ ]:


res1 = pd.DataFrame(res)
final = pd.concat([ddf["id"], res1], axis=1).reindex()
final = final.rename(columns={0: "Class"})
final.head()


# In[ ]:


sub8 = final[175:]
sub8.to_csv('submission8.csv', index = False)


# In[ ]:


from IPython.display import HTML
import pandas as pd
import numpy as np
import base64

# function that takes in a dataframe and creates a text link to  
# download it (will only work for files < 2MB or so)
def create_download_link(df, title = "Download CSV file", filename = "data.csv"):  
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode())
    payload = b64.decode()
    html = '<a download="{filename}" href="data:text/csv;base64,{payload}" target="_blank">{title}</a>'
    html = html.format(payload=payload,title=title,filename=filename)
    return HTML(html)
create_download_link(sub8)


# In[ ]:




