#!/usr/bin/env python
# coding: utf-8

# In[1]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir("../input"))

# Any results you write to the current directory are saved as output.


# In[2]:


import cv2
import keras
import keras.backend as K
from keras.models import Sequential
from keras.callbacks import Callback
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout,Activation
from glob import glob
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score
get_ipython().run_line_magic('matplotlib', 'inline')


# In[ ]:


def vectorize(n):
    n = int(n)
    a = [0 for i in range(14)]
    if n <= 13:
        a[n] = 1
    else:
        a[0] = 1
    return a


# In[ ]:


X_train = np.load("../input/wildcam-reduced/X_train.npy")
Y_train = np.load("../input/wildcam-reduced/y_train.npy")


# In[ ]:


print(X_train.shape)
print(Y_train.shape)


# In[ ]:


X_test = np.load("../input/wildcam-reduced/X_test.npy")


# In[ ]:


X_train = X_train.astype("float32")/255.0
X_test = X_test.astype("float32")/255.0
# Y_train = Y_train.astype("float32")/255.0


# In[ ]:


# model1 = Sequential()

# model1.add(Conv2D(64,(3,3),strides = 3,padding = "same",activation = "relu",input_shape = (32,32,3)))
# model1.add(Conv2D(64,(3,3),strides = 3,padding = "same",activation = "relu"))
# model1.add(Dropout(0.35))

# model1.add(Conv2D(128,(3,3),strides = 3,padding = "same",activation = "relu"))
# model1.add(Dropout(0.35))


# model1.add(Conv2D(256,(3,3),strides = 3,padding = "same",activation = "relu"))


# model1.add(Conv2D(256,(3,3),strides = 3,padding = "same",activation = "relu"))


# model1.add(Conv2D(512,(3,3),strides = 3,padding = "same",activation = "relu"))
# model1.add(Dropout(0.20))

# model1.add(Flatten())
# model1.add(Dropout(0.20))
# model1.add(Dense(512,activation = "relu"))
# model1.add(Dropout(0.20))
# model1.add(Dense(128,activation = "relu"))
# model1.add(Dropout(0.20))
# model1.add(Dense(64,activation = "relu"))
# model1.add(Dropout(0.20))
# model1.add(Dense(32,activation = "relu"))
# model1.add(Dense(14,activation = "softmax"))
# model1.summary()








# In[ ]:


# model1.compile(optimizer = "adam",loss = "categorical_crossentropy",metrics = ["accuracy"])


# In[ ]:


# model1.fit(X_train,Y_train,batch_size = 150,epochs = 20,validation_split = 0.25)


# In[ ]:



batch_size = 64
num_classes = 14
epochs = 30
val_split = 0.1
save_dir = os.path.join(os.getcwd(), 'models')
model_name = 'keras_cnn_model.h5'
model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=X_train.shape[1:]))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(num_classes))
model.add(Activation('softmax'))

model.compile(
    loss='categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

hist = model.fit(
    X_train, 
    Y_train,
    batch_size=batch_size,
    epochs=epochs,
    validation_split=val_split,
    shuffle=True
)


# In[ ]:


# vgg_light = Sequential()
# vgg_light.add(Conv2D(64,(3,3),padding = "same",strides = 3,activation = "relu",input_shape = (32,32,3)))
# vgg_light.add(Conv2D(64,(3,3),padding = "same",strides = 3,activation = "relu"))
# # vgg_light.add(MaxPooling2D(pool_size = (2,2)))
# vgg_light.add(Conv2D(128,(3,3),padding = "same",strides = 3,activation = "relu"))
# vgg_light.add(MaxPooling2D((2,2)))
# vgg_light.add(Conv2D(512,(3,3),padding = "same",strides = 3,activation = "relu"))
# # vgg_light.add(MaxPooling2D((2,2)))
# vgg_light.add(Dropout(0.3))
# vgg_light.add(Flatten())
# vgg_light.add(Dense(128,activation = "relu"))
# vgg_light.add(Dropout(0.2))
# vgg_light.add(Dense(64,activation = "relu"))
# vgg_light.add(Dropout(0.2))
# vgg_light.add(Dense(14,activation = "softmax"))
# # vgg_light.summary()


# In[ ]:


# vgg_light.compile(optimizer = "adam",loss = "categorical_crossentropy",metrics = ["accuracy"])


# In[ ]:


# vgg_light.fit(X_train,Y_train,batch_size = 80,epochs = 30,validation_split = 0.25)


# In[ ]:


# vgg_light_predict = vgg_light.predict(X_test)
model_predict = model.predict(X_test)
# model1_predict = model1.predict(X_test)


# In[ ]:


# vgg_light_predict.shape


# In[ ]:


# vgg_light_predict[5]


# In[4]:


submission_df = pd.read_csv('../input/iwildcam-2019-fgvc6/sample_submission.csv')
submission_df['Predicted'] = model_predict.argmax(axis=1)


# In[3]:


matched_dict = {0: 0,
 1: 1,
 2: 3,
 3: 4,
 4: 8,
 5: 10,
 6: 11,
 7: 13,
 8: 14,
 9: 16,
 10: 17,
 11: 18,
 12: 19,
 13: 22}


# In[ ]:


submittable = model_predict
for i in range(submittable.shape[0]):
    submittable[i] = matched_dict[submittable[i]]


# In[ ]:





# In[ ]:


print(submission_df.shape)
submission_df.head()


# In[ ]:


submission_df.to_csv('submission_vgg_redefined.csv',index=False)


# In[ ]:


os.listdir()


# In[ ]:


# import the modules we'll need
from IPython.display import HTML
import pandas as pd
import numpy as np
import base64

# function that takes in a dataframe and creates a text link to  
# download it (will only work for files < 2MB or so)
def create_download_link(df, title = "Download CSV file", filename = "data.csv"):  
    csv = df.to_csv()
    b64 = base64.b64encode(csv.encode())
    payload = b64.decode()
    html = '<a download="{filename}" href="data:text/csv;base64,{payload}" target="_blank">{title}</a>'
    html = html.format(payload=payload,title=title,filename=filename)
    return HTML(html)

# create a random sample dataframe
# df = pd.DataFrame(np.random.randn(50, 4), columns=list('ABCD'))

# create a link to download the dataframe
create_download_link(submission_df)

