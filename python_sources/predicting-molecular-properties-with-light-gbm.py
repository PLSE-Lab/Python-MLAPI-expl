#!/usr/bin/env python
# coding: utf-8

# In[1]:


import numpy as np
import pandas as pd
import lightgbm as lgb
import matplotlib
from sklearn.metrics import mean_squared_error
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import StratifiedKFold,KFold
import warnings
import os
from six.moves import urllib
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
warnings.filterwarnings('ignore')
get_ipython().run_line_magic('matplotlib', 'inline')
plt.style.use('seaborn')
from scipy.stats import norm, skew
import plotly
from plotly.plotly import iplot
import plotly.graph_objs as go


# In[2]:


os.listdir('../input/')


# In[3]:


def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2    
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)    
    end_mem = df.memory_usage().sum() / 1024**2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df


# <pre> <b> Define Train and Test Set</b></pre>

# In[4]:


train = reduce_mem_usage(pd.read_csv('../input/train.csv'))
test = reduce_mem_usage(pd.read_csv('../input/test.csv'))
mulliken = reduce_mem_usage(pd.read_csv('../input/mulliken_charges.csv'))
dipole = reduce_mem_usage(pd.read_csv('../input/dipole_moments.csv'))
structure = reduce_mem_usage(pd.read_csv('../input/structures.csv'))
potential = reduce_mem_usage(pd.read_csv('../input/potential_energy.csv'))
magnetic = reduce_mem_usage(pd.read_csv('../input/magnetic_shielding_tensors.csv'))
scaler = reduce_mem_usage(pd.read_csv('../input/scalar_coupling_contributions.csv'))
sub = reduce_mem_usage(pd.read_csv('../input/sample_submission.csv'))


# In[5]:


train.info()


# In[6]:


train.describe()


# In[7]:


train.head(10)


# In[8]:


print(mulliken.shape)
print(mulliken.head(10))


# In[9]:


print(dipole.shape)
print(dipole.head(10))


# In[10]:


print(structure.shape)
print(structure.head(10))


# In[11]:


print(magnetic.shape)
print(magnetic.head(5))


# In[12]:


print(potential.shape)
print(potential.head(10))


# In[13]:


print(scaler.shape)
print(scaler.head(10))


# In[14]:


#Check for Missing Values

obs = train.isnull().sum().sort_values(ascending = False)
percent = round(train.isnull().sum().sort_values(ascending = False)/len(train)*100, 2)
pd.concat([obs, percent], axis = 1,keys= ['Number of Observations', 'Percent'])


# <pre>Prepare One Hot Encoder for Object Datatypes</pre>

# In[15]:


def one_hot_encoder(data):
    original_columns = data.columns.tolist()
    categorical_columns = list(filter(lambda c: c in ['object'], data.dtypes))
    new_data = pd.get_dummies(data, columns=categorical_columns)

    new_columns = list(filter(lambda c: c not in original_columns, new_data.columns))
    return new_data, new_columns


# <pre> Exploratory Analytics </pre>

# In[16]:


#Distribution for Target Variable
plotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP') # Please change the credentials in your version

trace1 = go.Histogram(
    x= train['scalar_coupling_constant'],
    opacity=0.75,
    name = "scalar_coupling_constant",
    marker=dict(color='rgba(171, 50, 96, 0.6)'))

data = [trace1]
layout = go.Layout(barmode='overlay',
                   title='Distribution of scalar coupling constant'
)
fig = go.Figure(data=data, layout=layout)
iplot(fig)


# In[17]:


import gc
gc.collect()


# In[18]:


plotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP')
example = structure.loc[structure['molecule_name'] == 'dsgdb9nsd_000001']
trace1 = go.Scatter3d(
    x=example['x'],
    y=example['y'],
    z=example['z'],
    mode='markers',
    marker=dict(
        size=12,
        line=dict(
            color='rgba(217, 217, 217, 0.14)',
            width=0.5
        ),
        opacity=0.8
    )
)

data = [trace1]
layout = go.Layout(
    margin=dict(
        l=0,
        r=0,
        b=0,
        t=0
    )
)
fig = dict(data = data, layout = layout)
iplot(fig)


# In[19]:


gc.collect()


# In[20]:


# Plot the distribution of mulliken_charges
#Distribution for Target Variable
plotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP') # Please change the credentials in your version

trace1 = go.Histogram(
    x= mulliken['mulliken_charge'],
    opacity=0.75,
    name = "scalar_coupling_constant",
    marker=dict(color='rgba(171, 50, 96, 0.6)'))

data = [trace1]
layout = go.Layout(barmode='overlay',
                   title='Distribution of Mulliken Charges'
)
fig = go.Figure(data=data, layout=layout)
iplot(fig)


# In[21]:


gc.collect()


# In[22]:


# Plot the distribution of Potential Energy
#Distribution for Target Variable
plotly.tools.set_credentials_file('roy.gupta','LIKu6GnqVhkB1BaoUuHP') # Please change the credentials in your version

trace1 = go.Histogram(
    x= potential['potential_energy'],
    opacity=0.75,
    name = "scalar_coupling_constant",
    marker=dict(color='rgba(171, 50, 96, 0.6)'))

data = [trace1]
layout = go.Layout(barmode='overlay',
                   title='Potential Energy'
)
fig = go.Figure(data=data, layout=layout)
iplot(fig)


# In[23]:


gc.collect()


# In[24]:


scaler.groupby('type').count()['molecule_name'].sort_values().plot(kind='barh',
                                                                color='grey',
                                                               figsize=(15, 5),
                                                               title='Count of Coupling Type in Train Set')
plt.show()


# <pre><b>Evaluation Matrix</b>
# 
# Evaluation metric is important to understand as it determines how your model will be scored. Ideally we will set the loss function of our machine learning algorithm to use this metric so we can minimize the specific type of error.
# 
# Check out this kernel by @abhishek with code for the evaluation metric: https://www.kaggle.com/abhishek/competition-metric
# </pre>

# In[27]:


def Eval_matrix(data, preds):
    data["prediction"] = preds
    maes = []
    for t in data.type.unique():
        y_true = data[data.type==t].scalar_coupling_constant.values
        y_pred = data[data.type==t].prediction.values
        mae = np.log(metrics.mean_absolute_error(y_true, y_pred))
        maes.append(mae)
    return np.mean(maes)


# <pre> Relationship between Target and Mulliken Features

# In[30]:


smul = mulliken.merge(train)
sns.pairplot(data=smul.sample(500), hue='type', vars=['mulliken_charge','scalar_coupling_constant'])
plt.show()


# <pre>Relationship between Target and Magnetic Features</pre>

# In[25]:


smg = magnetic.merge(train)
sns.pairplot(data=smg.sample(500), hue='type', vars=['XX','YX','ZX','XY','YY','ZY','XZ','YZ','ZZ','scalar_coupling_constant'])
plt.show()


# <pre>Relationship between Target and Scalar Coupling Features</pre>

# In[26]:


scc = scaler.merge(train)
sns.pairplot(data=scc.sample(500), hue='type', vars=['fc','sd','pso','dso','scalar_coupling_constant'])
plt.show()


# In[28]:


gc.collect()


# <pre><b>Feature Creation<b>
# This feature was found from @inversion 's kernel here: https://www.kaggle.com/inversion/atomic-distance-benchmark/output 
# The code was then made faster by @seriousran here: https://www.kaggle.com/seriousran/just-speed-up-calculate-distance-from-benchmark</pre>

# In[ ]:


def map_atom_info(data, atom_idx):
    data = pd.merge(data, structure, how = 'left',
                  left_on  = ['molecule_name', f'atom_index_{atom_idx}'],
                  right_on = ['molecule_name',  'atom_index'])
    
    data = data.drop('atom_index', axis=1)
    data = data.rename(columns={'atom': f'atom_{atom_idx}',
                            'x': f'x_{atom_idx}',
                            'y': f'y_{atom_idx}',
                            'z': f'z_{atom_idx}'})
    return data

train = map_atom_info(train, 0)
train = map_atom_info(train, 1)

test = map_atom_info(test, 0)
test = map_atom_info(test, 1)


# In[ ]:


# https://www.kaggle.com/seriousran/just-speed-up-calculate-distance-from-benchmark
train_p_0 = train[['x_0', 'y_0', 'z_0']].values
train_p_1 = train[['x_1', 'y_1', 'z_1']].values
test_p_0 = test[['x_0', 'y_0', 'z_0']].values
test_p_1 = test[['x_1', 'y_1', 'z_1']].values

train['dist'] = np.linalg.norm(train_p_0 - train_p_1, axis=1)
test['dist'] = np.linalg.norm(test_p_0 - test_p_1, axis=1)


# In[ ]:


# make categorical variables
atom_map = {'H': 0,
            'C': 1,
            'N': 2}
train['atom_0_cat'] = train['atom_0'].map(atom_map).astype('int')
train['atom_1_cat'] = train['atom_1'].map(atom_map).astype('int')
test['atom_0_cat'] = test['atom_0'].map(atom_map).astype('int')
test['atom_1_cat'] = test['atom_1'].map(atom_map).astype('int')


# In[ ]:


# One Hot Encode the Type
train_df = pd.concat([train, pd.get_dummies(train['type'])], axis=1)
test_df = pd.concat([test, pd.get_dummies(test['type'])], axis=1)


# In[ ]:


train['dist_to_type_mean'] = train['dist'] / train.groupby('type')['dist'].transform('mean')
test['dist_to_type_mean'] = test['dist'] / test.groupby('type')['dist'].transform('mean')


# In[ ]:


train.head(10)

