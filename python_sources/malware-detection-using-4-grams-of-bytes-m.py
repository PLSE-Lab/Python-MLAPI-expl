#!/usr/bin/env python
# coding: utf-8

# # Malware detection using 4-grams of bytes
# * First you need to include two data sets, the one of malwares (cmpgramsmals) and the one of benign files (cmpgramslegit)
# * You can find both data sets in the following links: https://www.kaggle.com/isuremu/cmpgramsmals & https://www.kaggle.com/isuremu/cmpgramslegit
# * For more information how we extracted this data, consider checking my github repository, it contains other useful notebooks about malware detection
# * The following code is just an example of use and it's not meant to be a very sophisticated one.
# 

# In[ ]:


#imports
import pandas as pd
import json
import numpy as np
import keras
from keras.layers import Dense, Input
from keras.models import Model
from keras import regularizers


# In[ ]:


#Read the data
legit_grams = pd.read_csv('../input/cmpgramslegit/compressed_legit_min_max_grams.csv')
mals_grams = pd.read_csv('../input/cmpgramsmals/compressed_mals_min_max_grams.csv')

#Generate labels
legit_labels = np.zeros(legit_grams.shape[0])
mals_labels = np.ones(mals_grams.shape[0])


# In[ ]:


#Delete unsused columns
del legit_grams['Unnamed: 0']
del legit_grams['path']
del mals_grams['Unnamed: 0']
del mals_grams['path']


# In[ ]:


#Concat data
dataset = pd.concat([legit_grams, mals_grams], sort = False)
dataset_labels = np.concatenate([legit_labels, mals_labels])


# In[ ]:


#HyperParameters
input_dim = dataset.shape[1]
output_dim = 1
layers_configs = [[1024, 1024]]
training_algorithms = ['adam']
losses = ['mean_squared_error']
dropouts = [1]
regularization = ['dropout', 'early']
regularizers_v = [regularizers.l2(0.)]
hidden_activations = ['relu']
output_activations = ['sigmoid']
callbacks = []
metrics = ['accuracy']
initializers = ['random_normal']
epochs = 100
batch_size = 512


# In[ ]:


#return configuration for keras network
def configs_builder(input_dim, output_dim, layers_configs, training_algorithms, 
                    losses, dropouts, regularizers, 
                    hidden_activations, output_activations, 
                    callbacks, metrics, initializers):
    configs = []
    for layers_config in layers_configs:
        for training_algorithm in training_algorithms:
            for loss in losses:
                for dropout in dropouts:
                    for regularizer in regularizers_v:
                        for hidden_activation in hidden_activations:
                            for output_activation in output_activations:
                                for initializer in initializers:
                                    config = {
                                        'layers': {
                                            'dtype' : 'float32',
                                            'input dim': input_dim,
                                            'number': len(layers_config),
                                            'dims': layers_config,
                                            'names': ['dense'+str(x) for x in range(1, len(layers_config)+1, 1)],
                                            'initializers': [initializer for x in range(len(layers_config))],
                                            'bias initializers': [initializer for x in range(len(layers_config))],
                                            'activations': [hidden_activation for x in range(len(layers_config))],
                                            'kernel regulizers': [regularizer for x in range(len(layers_config))],
                                            'output dim': output_dim,
                                            'output activation' : output_activation,
                                            'ouput initializer' : initializer,
                                            'output bias initializer': initializer,
                                            'output regulizer': regularizer,
                                        },

                                        'compile': {
                                            'optimizer': training_algorithm,
                                            'metrics': metrics,
                                            'loss': loss,
                                            'callbacks': callbacks,
                                        },
                                    }
                                    configs.append(config)
    return configs


# In[ ]:


#build a feedforward network using the configuration
def feed_forward_builder(config):
    input_layer = Input(shape=(config['layers']['input dim'],), dtype = config['layers']['dtype'], name = 'InputLayer')
    if config['layers']['number'] == 0:
        print('No Hidden Layers')
    else:
        layer = Dense(config['layers']['dims'][0], 
                      dtype = config['layers']['dtype'], 
                      name = config['layers']['names'][0], 
                      activation = config['layers']['activations'][0], 
                      kernel_initializer = config['layers']['initializers'][0], 
                      bias_initializer = config['layers']['bias initializers'][0], 
                      kernel_regularizer = config['layers']['kernel regulizers'][0])(input_layer)
        for n in range(1,config['layers']['number'],1):
            layer =   Dense(config['layers']['dims'][n], 
                      dtype = config['layers']['dtype'], 
                      name = config['layers']['names'][n], 
                      activation = config['layers']['activations'][n], 
                      kernel_initializer = config['layers']['initializers'][n], 
                      bias_initializer = config['layers']['bias initializers'][n], 
                      kernel_regularizer = config['layers']['kernel regulizers'][n])(layer)
    output_layer = Dense(config['layers']['output dim'], 
                         dtype =  config['layers']['dtype'], 
                         name = 'OutputLayer', 
                         activation = config['layers']['output activation'], 
                         kernel_initializer = config['layers']['ouput initializer'], 
                         bias_initializer = config['layers']['output bias initializer'], 
                         kernel_regularizer = config['layers']['output regulizer'])(layer)
    fnn = Model(inputs = input_layer, outputs = output_layer)
    fnn.compile(optimizer = config['compile']['optimizer'], 
                metrics = config['compile']['metrics'], 
                loss = config['compile']['loss'])
    return fnn


# In[ ]:


#train
def fnn_trainer(model, params, data, labels):
    return model.fit(data, labels, validation_split = params['validation'], 
                        batch_size = params['batch_size'], epochs = params['epochs'])


# In[ ]:


#start trainer and return history of error
def fnn_evaluate(configs, data, labels):
    params = {
        'epochs' : 10,
        'batch_size' : 512,
        'validation': 0.15,
    }
    histories = []
    for config in configs:
        model = feed_forward_builder(config)
        model.summary()
        histories.append(fnn_trainer(model, params, data, labels))
    return histories, model


# In[ ]:


#Get the configuration for the network
configs = configs_builder(input_dim, output_dim, layers_configs, training_algorithms, 
                    losses, dropouts, regularizers, 
                    hidden_activations, output_activations, 
                    callbacks, metrics, initializers)


# In[ ]:


#Launch training 
histories, model = fnn_evaluate(configs, dataset, dataset_labels)


# In[ ]:


#print history
for h in histories:
    print(h.history)

