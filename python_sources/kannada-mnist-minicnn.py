#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import numpy as np 
import pandas as pd 
from glob import glob
import matplotlib.pyplot as plt
from skimage.io import imread
from skimage.transform import resize
get_ipython().run_line_magic('matplotlib', 'inline')
from sklearn.model_selection import train_test_split
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import print_summary
from keras.models import Sequential
from keras.layers import (  Dense, 
                            Conv2D,
                            MaxPooling2D,
                            MaxPool2D,
                            Dropout,
                            BatchNormalization,
                            Flatten
                         )
from keras.optimizers import Adam, RMSprop
from keras.utils import print_summary
from keras.datasets import mnist
from keras.utils.np_utils import to_categorical


# In[ ]:


def plot(img):
    plt.imshow(img);
    plt.show();


# In[ ]:


def history(History):
    
    fig, ax = plt.subplots(1, 2, figsize=(20, 5))
    
    ax[0].plot(History.history['loss'])
    ax[0].plot(History.history['val_loss'])
    ax[0].legend(['Training loss', 'Validation Loss'],fontsize=18)
    ax[0].set_xlabel('Epochs ',fontsize=16)
    ax[0].set_ylabel('Loss',fontsize=16)
    ax[0].set_title('Training loss x Validation Loss',fontsize=16)

    ax[1].plot(History.history['accuracy'])
    ax[1].plot(History.history['val_accuracy'])
    ax[1].legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)
    ax[1].set_xlabel('Epochs ',fontsize=16)
    ax[1].set_ylabel('Accuracy',fontsize=16)
    ax[1].set_title('Training Accuracy x Validation Accuracy',fontsize=16)


# In[ ]:


train_id = pd.read_csv('../input/Kannada-MNIST/train.csv')
test_id = pd.read_csv('../input/Kannada-MNIST/test.csv')
dig_id = pd.read_csv('../input/Kannada-MNIST/Dig-MNIST.csv')


# In[ ]:


x, y, z = 28, 28, 1
qtd_classes = 10

images = []
images_labels = []

valid = []
valid_labels = []

for count, (index, row) in enumerate(train_id.iterrows()):
    images.append(row.values[1:].reshape(x, y, z))
    images_labels.append(row.values[:1])
    
for count, (index, row) in enumerate(dig_id.iterrows()):
    valid.append(row.values[1:].reshape(x, y, z))
    valid_labels.append(row.values[:1])


# In[ ]:


TESTER = []
for count, (index, row) in enumerate(test_id.iterrows()):
    TESTER.append(row.values[1:].reshape(x, y, z))


# In[ ]:


SUBMIT =  np.asarray(TESTER) / 255.
TEST   =  np.asarray(valid) / 255.
TRAIN  =  np.asarray(images) / 255.

TRAIN_labels = to_categorical(np.asarray(images_labels), qtd_classes)
TEST_labels  = to_categorical(np.asarray(valid_labels), qtd_classes)


# In[ ]:


train = np.concatenate([TEST, TRAIN])
labels = np.concatenate([TRAIN_labels, TEST_labels])


# In[ ]:


plt.figure(figsize = (15, 5))
for i in range(0,10):
    plt.subplot(2,5,i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.title(str(np.argmax(labels[i])))
    plt.imshow(train[i,:,:,0], cmap="inferno")


# In[ ]:


x_train, x_test, y_train, y_test = train_test_split(train, labels, test_size = 0.3)


# In[ ]:


NUM_CLASSES = 10
EPOCHS = 15
BATCH_SIZE = 64
inputShape = (x, y, z)


# In[ ]:


model = Sequential()
model.add(Conv2D(16, kernel_size = 3, padding="same", activation='relu', input_shape = inputShape))

model.add(Conv2D(32, kernel_size = 3, padding="same", activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, kernel_size = 3, padding="same", activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, kernel_size = 3, padding="same", activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(256, kernel_size = 3, padding="same", activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(NUM_CLASSES, activation='softmax'))
    
optmize = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)
model.compile(loss = keras.losses.categorical_crossentropy, optimizer = optmize,  metrics=['accuracy'])
History = model.fit(x_train, y_train,
          batch_size = BATCH_SIZE,
          epochs = EPOCHS,
          verbose = 1,
          validation_data=(x_test, y_test))


# In[ ]:


loss, accu = model.evaluate(x_test, y_test)
print("%s: %.2f%%" % ('Accuracy...', accu))
print("%s: %.2f" % ('Loss...', loss))


# In[ ]:


history(History)


# In[ ]:


History = model.fit(train, labels,
          batch_size = BATCH_SIZE,
          epochs = 100,
          verbose = 1)


# In[ ]:


results = model.predict(SUBMIT)
results = np.argmax(results,axis = 1)
data_out = pd.DataFrame({'id': range(len(SUBMIT)), 'label': results})


# In[ ]:


plt.figure(figsize = (15, 5))
for i in range(0,10):
    plt.subplot(2,5,i + 1)
    plt.xticks([])
    plt.yticks([])
    plt.title(str(results[i]))
    plt.imshow(TESTER[i][:,:,0], cmap="inferno")


# In[ ]:


data_out.head()


# In[ ]:


data_out.to_csv('submission.csv', index = None)


# In[ ]:




