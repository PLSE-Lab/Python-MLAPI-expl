#!/usr/bin/env python
# coding: utf-8

# Transfer learning with pre-trained VGG16 model with imagenet weights.
# The plant-seedlings-classification dataset of kaggle is used.
# The last three layers of the network is popped, and 2 new conv layers and 1 new fully-connected/dense layer is added.Hence only these three layers are learnt.
# The first 13 layers are set as untrainable. Hence the 13th layer acts as the "bottleneck" layer. 
# 
# Cross validation accuracy of 92% and a cross validation loss of 0.25092 was achieved.
# 
# 

# In[ ]:


#!ls ../input/plant-seedlings/
import os
os.listdir('../input/input/input/plant-seedlings-classification/')


# In[ ]:


get_ipython().system('ls ../input/input/input/vgg16/')


# In[ ]:


import os
cache_dir = os.path.expanduser(os.path.join('~', '.keras'))
if not os.path.exists(cache_dir):
    os.makedirs(cache_dir)
models_dir = os.path.join(cache_dir, 'models')
if not os.path.exists(models_dir):
    os.makedirs(models_dir)


# In[ ]:


get_ipython().system('cp ../input/input/input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5 ~/.keras/models/')


# In[ ]:


print(os.listdir('../input/input/input/plant-seedlings-classification/train/'))


# In[ ]:


import fnmatch
import os
import numpy as np
import pandas as pd
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
np.random.seed(21)

path = '../input/input/input/plant-seedlings-classification/train/'
train_label = []
train_img = []
label2num = {'Loose Silky-bent':0, 'Charlock':1, 'Sugar beet':2, 'Small-flowered Cranesbill':3,
             'Common Chickweed':4, 'Common wheat':5, 'Maize':6, 'Cleavers':7, 'Scentless Mayweed':8,
             'Fat Hen':9, 'Black-grass':10, 'Shepherds Purse':11}
for i in os.listdir(path):
    label_number = label2num[i]
    new_path = path+i+'/'
    for j in fnmatch.filter(os.listdir(new_path), '*.png'):
        temp_img = image.load_img(new_path+j, target_size=(200,200))
        train_label.append(label_number)
        temp_img = image.img_to_array(temp_img)
        train_img.append(temp_img)

train_img = np.array(train_img)

train_y=pd.get_dummies(train_label)
train_y = np.array(train_y)
train_img=preprocess_input(train_img)

print('Training data shape: ', train_img.shape)
print('Training labels shape: ', train_y.shape)


# In[ ]:


import keras
from keras.models import Sequential,Model
from keras.layers import Dense, Dropout, Flatten, Activation
from keras.layers import Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
from keras.applications.vgg16 import VGG16
from keras.preprocessing.image import ImageDataGenerator

def vgg16_model(num_classes=None):

    model = VGG16(weights='imagenet', include_top=False,input_shape=(200,200,3))
    model.layers.pop()
    model.layers.pop()
    model.layers.pop()

    model.outputs = [model.layers[-1].output]

    model.layers[-2].outbound_nodes= []
    x=Conv2D(256, kernel_size=(2,2),strides=2)(model.output)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)    
    x=Conv2D(128, kernel_size=(2,2),strides=1)(x)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x=Flatten()(x)
    x=Dense(num_classes, activation='softmax')(x)

    model=Model(model.input,x)

    for layer in model.layers[:14]:

        layer.trainable = False


    return model


# In[ ]:


def precision(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision


def recall(y_true, y_pred):
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall


def fscore(y_true, y_pred):
    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:
        return 0

    p = precision(y_true, y_pred)
    r = recall(y_true, y_pred)
    f_score = 2 * (p * r) / (p + r + K.epsilon())
    return f_score


# In[ ]:


from keras import backend as K
num_classes=12
model = vgg16_model(num_classes)
model.compile(optimizer="nadam", loss='categorical_crossentropy', metrics=['accuracy',fscore])
model.summary()


# In[ ]:


#Split training data into rain set and validation set
from sklearn.model_selection import train_test_split
X_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.1, random_state=42)

#Data augmentation
'''from keras.preprocessing.image import ImageDataGenerator
gen_train = ImageDataGenerator( 
    rotation_range=30,
    width_shift_range=0.2,
   height_shift_range=0.2,
    horizontal_flip=True,
    vertical_flip=True

)
gen_train.fit(X_train)

#Train model
from keras.callbacks import ModelCheckpoint
epochs = 10
batch_size = 32
model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)

model.fit_generator(gen_train.flow(X_train, Y_train, batch_size=batch_size, shuffle=True), 
                    steps_per_epoch=(X_train.shape[0]//(4*batch_size)), 
                    epochs=epochs, 
                    validation_data=(X_valid,Y_valid),
                    callbacks=[model_checkpoint],verbose=1)
'''
from keras.callbacks import ModelCheckpoint
epochs = 10
batch_size = 32
# model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)

model_checkpoint = ModelCheckpoint('./model61.{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.h5',
                           monitor='val_loss',
                             verbose=1,
                            save_best_only=True,
                            mode='min',
                             save_weights_only=False)


model.fit(X_train,Y_train,
          batch_size=128,
          epochs=20,
          verbose=1, shuffle=True, validation_data=(X_valid,Y_valid), callbacks=[model_checkpoint])


# In[ ]:


import matplotlib.pyplot as plt
def plot_model(model):
    plots = [i for i in model.history.history.keys() if i.find('val_') == -1]
    plt.figure(figsize=(10,10))

    for i, p in enumerate(plots):
        plt.subplot(len(plots), 2, i + 1)
        plt.title(p)
        plt.plot(model.history.history[p], label=p)
        plt.plot(model.history.history['val_'+p], label='val_'+p)
        plt.legend()

    plt.show()
    
plot_model(model)


# In[ ]:



from sklearn.metrics import classification_report, confusion_matrix
labelNames=['Loose Silky-bent', 'Charlock', 'Sugar beet', 'Small-flowered Cranesbill',
             'Common Chickweed', 'Common wheat', 'Maize', 'Cleavers', 'Scentless Mayweed',
             'Fat Hen', 'Black-grass', 'Shepherds Purse']
preds = model.predict(X_valid)
print("[INFO] evaluating network...")
print(classification_report(Y_valid.argmax(axis=1), preds.argmax(axis=1),
	target_names=labelNames))
print("The confusion matrix:")
print(confusion_matrix(Y_valid.argmax(axis=1), preds.argmax(axis=1)))
#print(classification_report(predictions, labels))

#X_valid,Y_valid

