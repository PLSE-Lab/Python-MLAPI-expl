#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir("../input"))

# Any results you write to the current directory are saved as output.


# In[ ]:


# import Libraries
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from scipy import stats
from scipy.stats import norm
from sklearn.preprocessing import StandardScaler
get_ipython().run_line_magic('matplotlib', 'inline')


# In[ ]:


# Utilities from kaggle kernels
# Instead of data = pd.read_csv("../input/train_V2.csv")
# We use : data = read_fast("../input/train_V2.csv")
import random
import time

def reduce_mem_usage_func(df):
    """ Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage
        iterate through all the columns of a dataframe and modify the data type
        to reduce memory usage.        
    """
    start_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))

    for col in df.columns:
        col_type = df[col].dtype

        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)

    end_mem = df.memory_usage().sum() / 1024**2
    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))
    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))
    return df

def get_sampled_data(filename, sample_size):
    n = sum(1 for line in open(filename)) - 1 #number of records in file (excludes header)
    skip = sorted(random.sample(range(1,n+1),n-sample_size)) #the 0-indexed header will not be included in the skip list
    df = pd.read_csv(filename, skiprows=skip)
    return df


def read_fast(filename, sample=True, sample_size=2500000, reduce_mem_usage=True):
    start_time = time.time()
    df = get_sampled_data(filename, sample_size) if sample else pd.read_csv(filename)
    new_df = reduce_mem_usage_func(df) if reduce_mem_usage else df
    elapsed_time = int(time.time() - start_time)
    print('Time to get data frame: {:02d}:{:02d}:{:02d}'.format(
               elapsed_time // 3600,
               (elapsed_time % 3600 // 60),
               elapsed_time % 60))
    return new_df


# In[ ]:


train = read_fast("../input/train.csv")
train.head()


# In[ ]:


test = read_fast("../input/test.csv", sample = False)
test.head()


# In[ ]:


# check index of dataframe
train.columns


# In[ ]:


train = train.dropna(thresh=0.70*len(train), axis=1)

test = test.dropna(thresh=0.70*len(test), axis=1)
train = train.drop(['SMode'], axis = 1)


# In[ ]:


train.dtypes


# In[ ]:


from sklearn.preprocessing import LabelEncoder
cols = ('EngineVersion', 'AppVersion','AvSigVersion','Census_OSVersion')
for c in cols:
    lbl = LabelEncoder() 
    lbl.fit(list(train[c].values)) 
    train[c] = lbl.transform(list(train[c].values))
    lbl.fit(list(test[c].values)) 
    test[c] = lbl.transform(list(test[c].values))


# In[ ]:


train = train.select_dtypes(include=[np.number])


# In[ ]:


train = train.fillna(train.mean())


# In[ ]:


y = train["HasDetections"]

X = train.drop(labels = ["HasDetections"],axis = 1)


# In[ ]:


from lightgbm import LGBMClassifier
from sklearn.model_selection import train_test_split

def identify_zero_importance_features(X, y, iterations = 1):
    """
    Identify zero importance features in a training dataset based on the 
    feature importances from a gradient boosting model. 
    
    Parameters
    --------
    train : dataframe
        Training features
        
    train_labels : np.array
        Labels for training data
        
    iterations : integer, default = 2
        Number of cross validation splits to use for determining feature importances
    """
    
    # Initialize an empty array to hold feature importances
    feature_importances = np.zeros(X.shape[1])

    # Create the model with several hyperparameters

    model = LGBMClassifier(objective = 'binary',
                           num_leaves=60,
                        learning_rate=0.1,
                        n_estimators=700,
                        max_depth =  -1,
                      boosting = 'gbdt',
                              bagging_fraction=0.8,
                              bagging_freq=1, 
                              feature_fraction=0.8,
                              bagging_seed=11,
                           metric = 'auc',
                             lambda_l1 = 0.1,
                         random_state = 133,
                         verbosity =  -1)
    # Fit the model multiple times to avoid overfitting
    for i in range(iterations):

        # Split into training and validation set
        train_features, valid_features, train_y, valid_y = train_test_split(X, y, 
                                                                            test_size = 0.25, 
                                                                            random_state = i)

        # Train using early stopping
        model.fit(train_features, train_y, early_stopping_rounds=100, 
                  eval_set = [(valid_features, valid_y)])

        # Record the feature importances
        feature_importances += model.feature_importances_ / iterations
    
    feature_importances = pd.DataFrame({'feature': list(X.columns), 
                            'importance': feature_importances}).sort_values('importance', 
                                                                            ascending = False)
    
    # Find the features with zero importance
    zero_features = list(feature_importances[feature_importances['importance'] == 0.0]['feature'])
    print('\nThere are %d features with 0.0 importance' % len(zero_features))
    
    return zero_features, feature_importances
zero_features, feature_importances = identify_zero_importance_features(X, y, iterations = 1)
print('zero_features:',zero_features)
print('feature_importances : ', feature_importances)


# In[ ]:


feature_importances.describe()


# In[ ]:


pp =np.percentile(feature_importances['importance'], 20) 
print(pp)


# In[ ]:


to_drop = feature_importances[feature_importances['importance'] <= pp]['feature']
X = X.drop(columns = to_drop)


# In[ ]:


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)             


# In[ ]:


from sklearn.metrics import accuracy_score
from sklearn.metrics import mean_squared_error
    # Cross validate model with Kfold stratified cross val
from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold
kfold = StratifiedKFold(n_splits=2, shuffle=False, random_state=42)


# In[ ]:


#lgbm 
import lightgbm as lgb
lbm = lgb.LGBMClassifier()


## Search grid for optimal parameters
lbm_param_grid = {'num_leaves': [2000],
         'min_data_in_leaf': [50],
         'objective': ['binary'],
         'max_depth': [-1],
         'learning_rate': [0.05],
         "boosting": ["gbdt"],
         "feature_fraction": [0.8],
         "bagging_freq": [5],
         "bagging_fraction": [0.8],
         "bagging_seed": [11],
         "lambda_l1": [0.1],
         "lambda_l2": [0.1],
         "random_state": [42],          
         "verbosity": [-1]}
gsExtC = GridSearchCV(lbm,param_grid = lbm_param_grid, cv=kfold, scoring="accuracy", n_jobs= 4)

gsExtC.fit(X_train,y_train)

ExtC_best = gsExtC.best_estimator_

# Best score
gsExtC.best_score_


# In[ ]:


test_id = test['MachineIdentifier']


# In[ ]:


feats = test.drop(['MachineIdentifier'], axis=1)


# In[ ]:


feats = feats.select_dtypes(include=[np.number])

feats = feats[X_train.columns]


# In[ ]:


feats = feats.fillna(feats.mean())


# In[ ]:


predictions = gsExtC.predict(feats)


# In[ ]:


submission = pd.DataFrame()
submission['MachineIdentifier'] = test_id
submission['HasDetections'] = predictions 
submission.to_csv('submission1.csv', index=False)


# In[ ]:


submission.head()

