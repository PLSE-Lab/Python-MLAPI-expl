#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.


# In[ ]:


pd.set_option('display.max_column', 500)
pd.set_option('display.max_rows', 500)


# In[ ]:


df_train_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_identity.csv')
df_train_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')

df_test_identity = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_identity.csv')
df_test_transaction = pd.read_csv('/kaggle/input/ieee-fraud-detection/test_transaction.csv')

df_sample_submission = pd.read_csv('/kaggle/input/ieee-fraud-detection/sample_submission.csv')


# In[ ]:


df_sample_submission.sample(20)


# In[ ]:


print(df_train_identity.shape)
print(df_train_transaction.shape)
print(df_test_identity.shape)
print(df_test_transaction.shape)
print(df_sample_submission.shape)


# In[ ]:


df_train_identity.head()


# In[ ]:


df_train_transaction.head()


# In[ ]:


df_train = pd.merge(df_train_transaction, df_train_identity, on='TransactionID', how='left')
df_test = pd.merge(df_test_transaction, df_test_identity, on='TransactionID', how='left')


# In[ ]:


print(df_train.shape)
print(df_test.shape)


# In[ ]:


df_train.isna().mean().sort_values(ascending=False)


# In[ ]:


df_na_rate = pd.DataFrame(df_train.isna().mean().sort_values(ascending=False), columns=['na_rate']).reset_index()
na_rate_columns = list(df_na_rate.loc[df_na_rate.na_rate > 0.4]['index'])


# In[ ]:


df_train = df_train.drop(columns=na_rate_columns)
df_test = df_test.drop(columns=na_rate_columns)


# In[ ]:


y_train = df_train['isFraud']
X_train = df_train.drop(columns=['isFraud'])
X_test = df_test


# In[ ]:


print(X_train.shape)
print(X_test.shape)


# In[ ]:


y_train.mean()


# In[ ]:


X_train.head()


# In[ ]:


X_test_original = X_test.copy()
X_train = X_train.loc[:, 'C1':]
X_test = X_test.loc[:, 'C1':]


# In[ ]:


X_train = X_train.drop(columns=['M6'])
X_test = X_test.drop(columns=['M6'])


# In[ ]:


from sklearn.linear_model import LogisticRegression


# In[ ]:


model = LogisticRegression()


# In[ ]:


X_train.fillna(-999, inplace=True)
X_test.fillna(-999, inplace=True)


# In[ ]:


model.fit(X_train, y_train)


# In[ ]:


p = model.predict(X_test)
p_prob = model.predict_proba(X_test)


# In[ ]:


p_prob


# In[ ]:


p_prob = p_prob[:, 1]


# In[ ]:


result = pd.Series(p_prob, index=X_test_original['TransactionID'], name='isFraud')


# In[ ]:


result.to_csv('first_model.csv', header=True)


# In[ ]:


result.shape


# In[ ]:




