#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt
import seaborn as sns

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session


# In[ ]:


data=pd.read_csv("/kaggle/input/data.csv")
data


# In[ ]:


data.tail(30)


# In[ ]:


del data["diagnostics_Versions_PyRadiomics"]
del data["diagnostics_Versions_SimpleITK"]
del data["diagnostics_Configuration_Settings"]
del data["diagnostics_Configuration_EnabledImageTypes"]
del data["diagnostics_Image-original_Hash"]
del data["diagnostics_Image-original_Dimensionality"]
del data["diagnostics_Versions_Numpy"]
del data["diagnostics_Versions_PyWavelet"]
del data["diagnostics_Versions_Python"]
del data["Unnamed: 0"]
del data["diagnostics_Image-original_Spacing"]
del data["diagnostics_Image-original_Size"]
del data["diagnostics_Mask-original_Hash"]
del data["diagnostics_Mask-original_Spacing"]
del data["diagnostics_Mask-original_Size"]
del data["diagnostics_Mask-original_BoundingBox"]
del data["diagnostics_Mask-corrected_Size"]
del data["diagnostics_Mask-corrected_Spacing"]
del data["diagnostics_Mask-original_CenterOfMassIndex"]
del data["diagnostics_Mask-original_CenterOfMass"]
del data["diagnostics_Mask-corrected_BoundingBox"]
del data["diagnostics_Mask-corrected_CenterOfMassIndex"]
del data["diagnostics_Mask-corrected_CenterOfMass"]


# In[ ]:


data=data.drop([34],axis=0)


# In[ ]:


data=data.drop(data.columns[[4, 5, 6,7]],axis=1)


# In[ ]:


data.tail(30)


# In[ ]:


data1=data.iloc[:,[0,108,96,62,65,34,18,33,48]]
#data1=data.drop(data.columns[[77,28,9,111,66,5,57,100,101,49,20,60,70,42,87,72,102,95,31]],axis=1)
data1


# In[ ]:


data1.columns[data1.isnull().any()]


# In[ ]:


data1.isnull().sum()


# In[ ]:


sns.countplot(x="CovidORnot", data=data1)
data.loc[:,'CovidORnot'].value_counts()


# In[ ]:


x_data = data1.drop(["CovidORnot"],axis=1)
y = data1.CovidORnot


# In[ ]:


x = (x_data - np.min(x_data))/(np.max(x_data)-np.min(x_data))


# In[ ]:


from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score,confusion_matrix
from sklearn.metrics import accuracy_score

# split data train 70 % and test 30 %
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

#random forest classifier with n_estimators=10 (default)
clf_rf = RandomForestClassifier(random_state=43)      
clr_rf = clf_rf.fit(x_train,y_train)

ac = accuracy_score(y_test,clf_rf.predict(x_test))
print('Accuracy is: ',ac)
cm = confusion_matrix(y_test,clf_rf.predict(x_test))
sns.heatmap(cm,annot=True,fmt="d")


# In[ ]:


from sklearn.feature_selection import RFECV

# The "accuracy" scoring is proportional to the number of correct classifications
clf_rf_4 = RandomForestClassifier() 
rfecv = RFECV(estimator=clf_rf_4, step=1, cv=5,scoring='accuracy')   #5-fold cross-validation
rfecv = rfecv.fit(x_train, y_train)

print('Optimal number of features :', rfecv.n_features_)
print('Best features :', x_train.columns[rfecv.support_])


# In[ ]:


# Plot number of features VS. cross-validation scores
import matplotlib.pyplot as plt
plt.figure()
plt.xlabel("Number of features selected")
plt.ylabel("Cross validation score of number of selected features")
plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)
plt.show()


# In[ ]:


clf_rf_5 = RandomForestClassifier()      
clr_rf_5 = clf_rf_5.fit(x_train,y_train)
importances = clr_rf_5.feature_importances_
std = np.std([tree.feature_importances_ for tree in clf_rf.estimators_],
             axis=0)
indices = np.argsort(importances)[::-1]

# Print the feature ranking
print("Feature ranking:")

for f in range(x_train.shape[1]):
    print("%d. feature %d (%f)" % (f + 1, indices[f], importances[indices[f]]))

# Plot the feature importances of the forest

plt.figure(1, figsize=(14, 13))
plt.title("Feature importances")
plt.bar(range(x_train.shape[1]), importances[indices],
       color="g", yerr=std[indices], align="center")
plt.xticks(range(x_train.shape[1]), x_train.columns[indices],rotation=90)
plt.xlim([-1, x_train.shape[1]])
plt.show()


# In[ ]:





# In[ ]:


# KNN
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 2)
x,y = data1.loc[:,data1.columns != 'CovidORnot'], data1.loc[:,'CovidORnot']
knn.fit(x,y)
prediction = knn.predict(x)
print('Prediction: {}'.format(prediction))


# In[ ]:


# train test split
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state = 1)
knn = KNeighborsClassifier(n_neighbors = 2)
x,y = data1.loc[:,data1.columns != 'CovidORnot'], data1.loc[:,'CovidORnot']
knn.fit(x_train,y_train)
prediction = knn.predict(x_test)
#print('Prediction: {}'.format(prediction))
print('With KNN (K=2) accuracy is: ',knn.score(x_test,y_test)) # accuracy


# In[ ]:





# In[ ]:


# Model complexity
neig = np.arange(1, 25)
train_accuracy = []
test_accuracy = []
# Loop over different values of k
for i, k in enumerate(neig):
    # k from 1 to 25(exclude)
    knn = KNeighborsClassifier(n_neighbors=k)
    # Fit with knn
    knn.fit(x_train,y_train)
    #train accuracy
    train_accuracy.append(knn.score(x_train, y_train))
    # test accuracy
    test_accuracy.append(knn.score(x_test, y_test))
# Plot
plt.figure(figsize=[13,8])
plt.plot(neig, test_accuracy, label = 'Testing Accuracy')
plt.plot(neig, train_accuracy, label = 'Training Accuracy')
plt.legend()
plt.title('-value VS Accuracy')
plt.xlabel('Number of Neighbors')
plt.ylabel('Accuracy')
plt.xticks(neig)
plt.savefig('graph.png')
plt.show()
print("Best accuracy is {} with K = {}".format(np.max(test_accuracy),1+test_accuracy.index(np.max(test_accuracy))))


# In[ ]:


x_datam = data.drop(["CovidORnot"],axis=1)
y = data.CovidORnot


# In[ ]:


x1 = (x_datam - np.min(x_datam))/(np.max(x_datam)-np.min(x_datam))


# In[ ]:


from sklearn.model_selection import GridSearchCV
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
steps = [('scalar', StandardScaler()),
         ('SVM', SVC())]
pipeline = Pipeline(steps)
parameters = {'SVM__C':[1, 10, 100],
              'SVM__gamma':[0.1, 0.01]}
x_train, x_test, y_train, y_test = train_test_split(x1,y,test_size=0.2,random_state = 1)
cv = GridSearchCV(pipeline,param_grid=parameters,cv=3)
cv.fit(x_train,y_train)

y_pred = cv.predict(x_test)

print("Accuracy: {}".format(cv.score(x_test, y_test)))
print("Tuned Model Parameters: {}".format(cv.best_params_))

