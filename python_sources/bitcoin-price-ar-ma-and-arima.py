#!/usr/bin/env python
# coding: utf-8

# # Bitcoin Price Prediction

# Importing the necessary libraries

# In[2]:


import pandas as kunfu
import numpy as dragon
import pylab as p
import matplotlib.pyplot as plot
from collections import Counter
import re

#importing packages for the prediction of time-series data
import statsmodels.api as sm
import statsmodels.tsa.api as smt
import statsmodels.formula.api as smf

from sklearn.metrics import mean_squared_error


# Importing the training data

# In[3]:


train = kunfu.read_csv('../input/bitcoin_price_Training - Training.csv',parse_dates=['Date']).fillna(0)
print(train.head())


# In[4]:


data = train['Close']
Date1 = train['Date']


# In[5]:


print(train.info())


# In[6]:


train1 = train[['Date','Close']]
train1.head()


# In[7]:


# Setting the Date as Index
train2 = train1.set_index('Date')
train2.sort_index(inplace=True)
print (type(train2))
print (train2.head())


# In[8]:


plot.plot(train2)
plot.xlabel('Date', fontsize=12)
plot.ylabel('Price in USD', fontsize=12)
plot.title("Closing price distribution of bitcoin", fontsize=15)


# In[9]:


plot.show()


# # Performing Augmented Dickey Fuller Test

# In[10]:


from statsmodels.tsa.stattools import adfuller

def test_stationarity(x):


    #Determing rolling statistics
    rolmean = x.rolling(window=22,center=False).mean()

    rolstd = x.rolling(window=12,center=False).std()
    
    #Plot rolling statistics:
    orig = plot.plot(x, color='blue',label='Original')
    mean = plot.plot(rolmean, color='red', label='Rolling Mean')
    std = plot.plot(rolstd, color='black', label = 'Rolling Std')
    plot.legend(loc='best')
    plot.title('Rolling Mean & Standard Deviation')
    plot.show(block=False)
    
    #Perform Dickey Fuller test    
    result=adfuller(x)
    print('ADF Stastistic: %f'%result[0])
    print('p-value: %f'%result[1])
    pvalue=result[1]
    for key,value in result[4].items():
         if result[0]>value:
            print("The graph is non stationery")
            break
         else:
            print("The graph is stationery")
            break;
    print('Critical values:')
    for key,value in result[4].items():
        print('\t%s: %.3f ' % (key, value))
        
ts = train2['Close']      
test_stationarity(ts)


# # Making time series stationary

# # Taking log transformation

# In[11]:


ts_log = dragon.log(ts)
plot.plot(ts_log,color="green")
plot.show()

test_stationarity(ts_log)


# # Remove trend and seasonality with decomposition

# In[12]:


# Naive decomposition of our Time Series as explained above
from statsmodels.tsa.seasonal import seasonal_decompose
decomposition = seasonal_decompose(ts_log, model='multiplicative',freq = 7)

trend = decomposition.trend
seasonal = decomposition.seasonal
residual = decomposition.resid


plot.subplot(411)
plot.title('Obeserved = Trend + Seasonality + Residuals')
plot.plot(ts_log,label='Observed')
plot.legend(loc='best')
plot.subplot(412)
plot.plot(trend, label='Trend')
plot.legend(loc='best')
plot.subplot(413)
plot.plot(seasonal,label='Seasonality')
plot.legend(loc='best')
plot.subplot(414)
plot.plot(residual, label='Residuals')
plot.legend(loc='best')
plot.tight_layout()
plot.show()


# In[13]:


ts_log_decompose = residual
#ts_log_decompose.fillna(inplace=True)
#test_stationarity(ts_log_decompose)


# # Remove trend and seasonality with differencing

# In[14]:


ts_log_diff = ts_log - ts_log.shift()
plot.plot(ts_log_diff)
plot.show()


# In[15]:


ts_log_diff.dropna(inplace=True)
test_stationarity(ts_log_diff)


# # Plot the autocorreltaion and partial auto correlation functions

# In[16]:


#ACF and PACF plots
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.tsa.arima_model import ARIMA

lag_acf = acf(ts_log_diff, nlags=10)
lag_pacf = pacf(ts_log_diff, nlags=10, method='ols')

#Plot ACF: 
plot.subplot(1,1,1)

plot.plot(lag_acf)
#print(lag_acf[0.5])

plot.axhline(y=0,linestyle='--',color='g')
plot.title('Autocorrelation Function')
plot.show()

#Plot PACF:
plot.subplot(1,1,1)
plot.plot(lag_pacf)

plot.axhline(y=0,linestyle='--',color='green')
plot.title('Partial Autocorrelation Function ')
plot.tight_layout()
plot.show()


# # AR MODEL

# In[17]:


# follow lag
model = ARIMA(ts_log, order=(1,1,0))  
results_ARIMA = model.fit(disp=-1)  
plot.plot(ts_log_diff)
plot.plot(results_ARIMA.fittedvalues, color='red')
plot.title('RSS: %.7f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))
plot.show()


# # Moving Average (MA) Model

# In[18]:


# follow error
model = ARIMA(ts_log, order=(0,1,1))  
results_MA = model.fit(disp=-1)  
plot.plot(ts_log_diff)
plot.plot(results_MA.fittedvalues, color='red')
plot.title('RSS: %.7f'% sum((results_MA.fittedvalues-ts_log_diff)**2))
plot.show()


# In[19]:


print(results_MA.summary())


# # ARIMA MODEL

# In[20]:


from statsmodels.tsa.arima_model import ARIMA
model = ARIMA(ts_log, order=(8,1,0))  
results_ARIMA = model.fit(disp=-1)  
plot.plot(ts_log_diff)
plot.plot(results_ARIMA.fittedvalues, color='red')
plot.title('RSS: %.7f'% sum((results_ARIMA.fittedvalues-ts_log_diff)**2))
plot.show()


# In[21]:


from statsmodels.tsa.arima_model import ARIMA
from pandas import DataFrame
print(results_ARIMA.summary())


# In[22]:


size = int(len(ts_log)-100)
train_arima, test_arima = ts_log[0:size], ts_log[size:len(ts_log)]
history = [x for x in train_arima]
predictions = list()
originals = list()
error_list = list()

print('Printing Predicted vs Expected Values...')
print('\n')
for t in range(len(test_arima)):
    model = ARIMA(history, order=(2, 1, 0))
    model_fit = model.fit(disp=-1)
    
    output = model_fit.forecast()
    
    pred_value = output[0]
    
        
    original_value = test_arima[t]
    history.append(original_value)
    
    pred_value = dragon.exp(pred_value)
    
    
    original_value = dragon.exp(original_value)
    
    
    error = ((abs(pred_value - original_value)) / original_value) * 100
    error_list.append(error)
    print('predicted = %f,   expected = %f,   error = %f ' % (pred_value, original_value, error), '%')
    
    predictions.append(float(pred_value))
    originals.append(float(original_value))
    
    #error = mean_squared_error(dragon.exp(yhat), dragon.exp(obs))
    #print('mean_squared_error : ', error)
print('\n Means Error in Predicting Test Case Articles : %f ' % (sum(error_list)/float(len(error_list))), '%')


# In[23]:


plot.figure(figsize=(8, 6))
test_day = [t
           for t in range(len(test_arima))]
labels={'Orginal','Predicted'}
plot.plot(test_day, predictions, color= 'green')
plot.plot(test_day, originals, color = 'orange')
plot.title('Expected Vs Predicted Views Forecasting')
plot.xlabel('Day')
plot.ylabel('Closing Price')
plot.legend(labels)
plot.show()


# In[25]:


""""plot.figure(figsize=(8, 6))
test_day = [t+450
                for t in range(len(test_arima))]
labels={'Orginal','Predicted'}
plot.plot(test_day, predictions, color= 'red')
plot.plot(Date1, ts)
plot.title('Expected Vs Predicted Views Forecasting')
plot.xlabel('Date')
plot.ylabel('Closing Prices')
plot.legend(labels)
plot.show()
"""


# In[26]:


test = kunfu.read_csv("../input/bitcoin_price_1week_Test - Test.csv",index_col= 'Date')
test.index = kunfu.to_datetime(test.index)
test = test['Close']
test = test.sort_index()
print(test)


# In[27]:


predictions_ARIMA_diff = kunfu.Series(results_ARIMA.fittedvalues, copy=True)
print(predictions_ARIMA_diff.head())


# In[28]:


predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()
print(predictions_ARIMA_diff_cumsum.head())


# In[29]:


predictions_ARIMA_log = kunfu.Series(ts_log.iloc[0], index=ts_log.index)
predictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)
predictions_ARIMA_log.head()


# In[30]:


predictions_ARIMA = dragon.exp(predictions_ARIMA_log)
plot.plot(ts)
plot.plot(predictions_ARIMA)
plot.title('RMSE: %.4f'% dragon.sqrt(sum((predictions_ARIMA-ts)**2)/len(data)))
plot.show()


# In[31]:


dates = [kunfu.Timestamp('2017-08-01'), kunfu.Timestamp('2017-08-02'), kunfu.Timestamp('2017-08-03'),kunfu.Timestamp('2017-08-04'), kunfu.Timestamp('2017-08-05'), kunfu.Timestamp('2017-08-06'), kunfu.Timestamp('2017-08-07')]

forecast = kunfu.Series(results_ARIMA.forecast(steps=7)[0],dates)
forecast = dragon.exp(forecast)
print(forecast)
error = mean_squared_error(test, forecast)
print('Test MSE: %.3f' % error)


# In[32]:


predictions_MA_diff = kunfu.Series(results_MA.fittedvalues, copy=True)
print(predictions_MA_diff.head())


# In[33]:


predictions_MA_diff_cumsum = predictions_MA_diff.cumsum()
print(predictions_MA_diff_cumsum.head())


# In[34]:


predictions_MA_log = kunfu.Series(ts_log.iloc[0], index=ts_log.index)
predictions_MA_log = predictions_MA_log.add(predictions_MA_diff_cumsum,fill_value=0)
predictions_MA_log.head()


# In[39]:


predictions_MA = dragon.exp(predictions_MA_log)
plot.plot(ts)
plot.plot(predictions_MA)
plot.title('RMSE: %.4f'% dragon.sqrt(sum((predictions_MA-ts)**2)/len(ts)))
plot.show()


# In[ ]:




