#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import matplotlib.pyplot as plt
import numpy as np
import torch
from torch import nn
from torch import optim
import torch.nn.functional as F
from torchvision import datasets, transforms, models
from PIL import Image
from os import listdir
import pandas as pd


# In[ ]:


data_directory = '../input/train'
epochs = 100


# In[ ]:


train_transforms = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.Resize(500),
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
train_data = datasets.ImageFolder(data_directory,transform=train_transforms)
trainloader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)
test_transforms = transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.RandomVerticalFlip(),
        transforms.Resize(500),
        transforms.CenterCrop(500),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
test_data = datasets.ImageFolder(data_directory,transform=test_transforms,)
testloader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)


# In[ ]:


class_names = trainloader.dataset.classes


# In[ ]:


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)


# In[ ]:


model = models.resnet50(pretrained=True)
# model = models.densenet161(pretrained=True)
model.cuda()
# print(model)


# In[ ]:


for param in model.parameters():
    param.requires_grad = False
model.fc = nn.Sequential(nn.Linear(2048, 512),
                                 nn.ReLU(),
                                 nn.Dropout(0.2),
                                 nn.Linear(512, 5),
                                 nn.LogSoftmax(dim=1))
criterion = nn.NLLLoss()
optimizer = optim.Adam(model.fc.parameters(), lr=0.003)
# criterion = nn.CrossEntropyLoss()
# optimizer = optim.SGD(model.fc.parameters(), lr=0.003, momentum=0.9, weight_decay=5e-4)
model.to(device)


# In[ ]:


epoch_list, train_accuracy_list, test_accuracy_list, train_loss_list, validation_loss_list = [], [], [], [], []
for epoch in range(epochs):
    train_loss = 0
    val_loss = 0
    accuracy = 0
    # Training the model
    model.train()
    counter = 0
    for inputs, labels in trainloader:
        # Move to device
        inputs, labels = inputs.to(device), labels.to(device)
        # Clear optimizers
        optimizer.zero_grad()
        # Forward pass
        output = model.forward(inputs)
        # Loss
        loss = criterion(output, labels)
        # Calculate gradients (backpropogation)
        loss.backward()
        # Adjust parameters based on gradients
        optimizer.step()
        # Add the loss to the training set's rnning loss
        train_loss += loss.item()*inputs.size(0)
        # Print the progress of our training
        counter += 1
#         print(counter, "/", len(trainloader))
    # Evaluating the model
    model.eval()
    counter = 0
    # Tell torch not to calculate gradients
    with torch.no_grad():
        for inputs, labels in testloader:
            # Move to device
            inputs, labels = inputs.to(device), labels.to(device)
            # Forward pass
            output = model.forward(inputs)
            # Calculate Loss
            valloss = criterion(output, labels)
            # Add loss to the validation set's running loss
            val_loss += valloss.item()*inputs.size(0)
            # Since our model outputs a LogSoftmax, find the real 
            # percentages by reversing the log function
            output = torch.exp(output)
            # Get the top class of the output
            top_p, top_class = output.topk(1, dim=1)
            # See how many of the classes were correct?
            equals = top_class == labels.view(*top_class.shape)
            # Calculate the mean (get the accuracy for this batch)
            # and add it to the running accuracy for this epoch
            accuracy += torch.mean(equals.type(torch.FloatTensor)).item()
            # Print the progress of our evaluation
            counter += 1
#             print(counter, "/", len(testloader))
    # Get the average loss for the entire epoch
    train_loss = train_loss/len(trainloader.dataset)
    train_loss_list.append(train_loss)
    valid_loss = val_loss/len(testloader.dataset)
    validation_loss_list.append(valid_loss)
    train_acc = accuracy/len(trainloader)
    train_accuracy_list.append(train_acc)
    test_acc = accuracy/len(testloader)
    test_accuracy_list.append(test_acc)
    epoch_list.append(epoch)
#     print(f'Epoch: {epoch}, Accuracy: {acc}, Train loss: {train_loss}, Valid loss: {valid_loss}')


# In[ ]:


max_train_accuracy = max(train_accuracy_list)
max_test_accuracy = max(test_accuracy_list)
epoch_train = epoch_list[train_accuracy_list.index(max_train_accuracy)]
epoch_test = epoch_list[test_accuracy_list.index(max_test_accuracy)]
print(f'Max Accuracy Score: {max_train_accuracy}, Epoch: {epoch_train}')
print(f'Max Accuracy Score: {max_test_accuracy}, Epoch: {epoch_test}')


# In[ ]:


epochs = range(1, len(train_accuracy_list) + 1)
#Train and validation accuracy
plt.plot(epochs, train_accuracy_list, 'b', label='Train accurarcy')
plt.plot(epochs, test_accuracy_list, 'r', label='Validation accurarcy')
plt.title('Training and Validation accurarcy')
plt.legend()

plt.figure()
#Train and validation loss
plt.plot(epochs, train_loss_list, 'b', label='Training loss')
plt.plot(epochs, validation_loss_list, 'r', label='Validation loss')
plt.title('Training and Validation loss')
plt.legend()
plt.show()


# In[ ]:


model.eval()
torch.save(model, "Saved_model.h5")


# In[ ]:


def process_image(image_dir):
    # Process a PIL image for use in a PyTorch model
    # tensor.numpy().transpose(1, 2, 0)
    image = Image.open(image_dir)
    preprocess = transforms.Compose([
        transforms.Resize(500),
        transforms.CenterCrop(450),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = preprocess(image)
    # Convert 2D image to 1D vector
    image = np.expand_dims(image, 0)
    image = torch.from_numpy(image)
    inputs = image.to(device)
    return inputs


# In[ ]:


# Using our model to predict the label
def predict(image, model):
    # Pass the image through our model
    output = model.forward(image)
    # Reverse the log function in our output
    output = torch.exp(output)
    # Get the top predicted class, and the output percentage for
    # that class
    probs, classes = output.topk(1, dim=1)
    return probs.item(), classes.item()


# In[ ]:


test_directory = '../input/test'
predictions, test_image_fileName = [], []
try:
    test_images = listdir(test_directory)
    for images in test_images:
        test_image_fileName.append(images)
        image = process_image(f'{test_directory}/{images}')
        top_prob, top_class = predict(image, model)
        predictions.append(class_names[top_class])
except Exception as e:
    print(e)


# In[ ]:


print("[INFO] Creating pandas dataframe")
submission_data = {"Category":predictions,"Id":test_image_fileName,}
submission_data_frame = pd.DataFrame(submission_data)


# In[ ]:


submission_data_frame.head()


# In[ ]:


print("[INFO] Saving Predicition to CSV")
submission_data_frame.to_csv('sample-submission.csv',columns=["Category","Id"], index = False)

from IPython.display import FileLink
FileLink(r'Saved_model.h5')

