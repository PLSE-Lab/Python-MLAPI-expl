#!/usr/bin/env python
# coding: utf-8

# # Overview
# The notebook has runs various models on the the Pneumonia data, the notebook tries to consistently train the models on the same splits so they are comparable. 
# 1. Basic baseline models
# 1. Simple image features (mean and standard deviation)
# 1. Adding texture features (co-occurence matrix features)

# In[ ]:


get_ipython().run_line_magic('matplotlib', 'inline')
import os
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
from skimage.io import imread
import seaborn as sns # nice visuals
from sklearn.model_selection import train_test_split # splitting data
# quantifying models
from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, confusion_matrix
data_dir = '../input/'


# ## Reading and Formatting
# Here we read in the training data. We perform a few simple transformations to make the analysis easier.
# 1. Replace `PatientSex` with a binary indicator variable `IsMale`
# 1. Replace `ViewPosition` with binary indicator variable `IsAP`
# 1. Read the slice from the full image

# In[ ]:


def categories_to_indicators(in_df):
    new_df = in_df.copy()
    new_df['IsMale'] = in_df['PatientSex'].map(lambda x: 'M' in x).astype(float)
    new_df['IsAP'] = in_df['ViewPosition'].map(lambda x: 'AP' in x).astype(float)
    return new_df.drop(['PatientSex', 'ViewPosition'], axis=1)
full_train_df = categories_to_indicators(pd.read_csv(os.path.join(data_dir, 'train_all.csv')))
full_stack = imread(os.path.join(data_dir, 'train.tif')) # read all slices
full_train_df['image'] = full_train_df['slice_idx'].map(lambda x: full_stack[x]) # get the slice
full_train_df.sample(3)


# ## Show the distribution
# We can use tools like `pairplot` from the `seaborn` package to show the distribution and relationship between multiple variables.

# In[ ]:


sns.pairplot(full_train_df, hue='opacity')


# ## Read the Test Data
# Here we read the test data (that we use for the submission), the same way we read the training data

# In[ ]:


submission_test_df = categories_to_indicators(pd.read_csv(os.path.join(data_dir, 'test_info.csv')))
test_stack = imread(os.path.join(data_dir, 'test.tif')) # read all slices
submission_test_df['image'] = submission_test_df['slice_idx'].map(lambda x: full_stack[x]) # get the slice
submission_test_df.sample(3)


# # Create Training and Validation Groups

# In[ ]:


from sklearn.preprocessing import RobustScaler
def fit_and_score(in_model, feature_maker, rescale=True):
    """
    Take a given model, set of features, and labels
    Break the dataset into training and validation
    Fit the model
    Show how well the model worked
    Input
        in_model: The model to fit (in scikit-learn model format)
        feature_maker: the function to run on the training data to turn it into a feature vector
        rescale: whether or not to rescale all features first
    """
    # compute features on the training data
    full_features = feature_maker(full_train_df)
    full_labels = full_train_df['opacity']
    # compute features on the test data
    submission_feat = feature_maker(submission_test_df)
    # split the training data into a training portion and a validation portion
    # so we can see how well the model works
    train_feat, valid_feat, train_lab, valid_lab = train_test_split(full_features, 
                                                                    full_labels,
                                                                    test_size=0.25,
                                                                    random_state=2018)
    
    if rescale:
        feature_scaler = RobustScaler()
        train_feat = feature_scaler.fit_transform(train_feat)
        valid_feat = feature_scaler.transform(valid_feat)
        submission_feat = feature_scaler.transform(submission_feat)
    # fit the model
    in_model.fit(train_feat, train_lab)
    # predict on the validation feature set
    predictions = in_model.predict_proba(valid_feat)[:, 1]
    # convert predictions to a class (opacity = 1, no-opacity = 0)
    predicted_class = predictions>0.5
    # make an ROC curve based on the known label for the validations et
    tpr, fpr, _ = roc_curve(valid_lab, predictions)
    # compute the AUC score
    auc = roc_auc_score(valid_lab, predictions)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
    ax1.plot(tpr, fpr, 'r.-', label='Prediction (AUC:{:2.2f})'.format(auc))
    ax1.plot(tpr, tpr, 'k-', label='Random Guessing')
    ax1.legend()
    ax1.set_title('ROC Curve')
    # make a full classification report
    print(classification_report(valid_lab, predicted_class, target_names=['opacity', 'no opacity']))
    # create a confusion matrix
    sns.heatmap(confusion_matrix(valid_lab, predicted_class), 
                annot=True, fmt='4d', ax=ax2)
    ax2.set_xlabel('Prediction')
    ax2.set_ylabel('Actual Value')
    ax2.set_title('Confusion Matrix ({:.1%})'.format(accuracy_score(valid_lab, predicted_class)))
    
    # create a submission file as a csv
    sub_df = submission_test_df[['tile_id']].copy()
    sub_df['opacity'] = in_model.predict_proba(submission_feat)[:, 1]
    
    sub_df[['tile_id', 'opacity']].to_csv(
        'm-{model}-f-{features}-s-{auc:2.0f}.csv'.format(
            model=in_model.__class__.__name__, # model name
            features=feature_maker.__name__, # feature name
            auc=100*auc, # add the auc score to the name
        ), index=False)


# # Baseline Models

# In[ ]:


# dummy random guesser
from sklearn.dummy import DummyClassifier
dum_model = DummyClassifier(strategy='stratified', random_state=2018)
def justage(in_df):
    return in_df[['PatientAge']].values
fit_and_score(
    dum_model,
    justage
)


# In[ ]:


# nearest neighbor
from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier(1) # one neighbor
def table_features(in_df):
    return in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].values
fit_and_score(
    knn_model,
    table_features
)


# ## Adding Basic Image Features
# We can easily add the mean and std values from the image

# In[ ]:


def basic_image_features(in_df):
    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()
    out_df['Mean_Intensity'] = in_df['image'].map(np.mean)
    out_df['Std_Intensity'] = in_df['image'].map(np.std)
    return out_df.values
knn_model = KNeighborsClassifier(2) # two neighbor
fit_and_score(
    knn_model,
    basic_image_features
)


# In[ ]:


from sklearn.linear_model import LogisticRegression
lr_model = LogisticRegression(solver='lbfgs', random_state=2018)
fit_and_score(
    lr_model,
    basic_image_features
)


# In[ ]:


from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(random_state=2018)
fit_and_score(
    rf_model,
    basic_image_features
)


# In[ ]:


from sklearn.naive_bayes import GaussianNB
nb_model = GaussianNB()
fit_and_score(
    nb_model,
    basic_image_features
)


# In[ ]:


from sklearn.svm import SVC
svm_model = SVC(probability=True)
fit_and_score(
    svm_model,
    basic_image_features
)


# # Texture Features
# ## Greyscale Co-occurence Matrix
# Here we finally add some more interesting texture features using the [scikit-image feature package](http://scikit-image.org/docs/dev/api/skimage.feature.html). We initially just use the `greycomatrix` which is short for the [greyscale co-occurence matrix](https://en.wikipedia.org/wiki/Co-occurrence_matrix). The matrix shows how likely certain patterns of pixels are to show up together.
# ![greycomatrix](http://www.jpathinformatics.org/articles/2016/7/1/images/JPatholInform_2016_7_1_36_189699_f2.jpg)
# 

# ## Features from greycomatrix
# The matrix itself isn't very useful, since we are trying to build machine learning-based models and they require features. We can create features by focusing on a few different properties as shown in the `greyco_prop_list` section. More details about some of these features can be found [here](https://www.mathworks.com/help/images/ref/graycoprops.html)
# ### Contrast 
# The measure of differentiation in intensity between a pixel and its neighbor over the whole image. If an image is constant the contrast will be 0
# - Formula $ \Sigma_{i,j}|i-j|^2 p(i,j) $
# ### Homogeneity
# A measure of the closeness of the distribution of elements. A purely diagonal greycomatrix would result in a homogeneity of 1
# - Formula $ \Sigma_{i,j} \frac{p(i, j)}{1+|i-j|} $

# In[ ]:


from skimage.feature import greycomatrix, greycoprops
grayco_prop_list = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']
def calc_texture_features(in_slice):
    glcm = greycomatrix(in_slice, [5], [0], 256, symmetric=True, normed=True)
    out_row = {}
    for c_prop in grayco_prop_list:
        out_row[c_prop] = greycoprops(glcm, c_prop)[0, 0]
    return pd.Series(out_row)
def texture_features(in_df):
    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()
    out_df['Mean_Intensity'] = in_df['image'].map(np.mean)
    out_df['Std_Intensity'] = in_df['image'].map(np.std)
    # add the results to the current matrix
    aug_df = pd.concat([
        out_df,
        in_df.apply(lambda x: calc_texture_features(x['image']), axis=1)
    ], 1)
    return aug_df.values


# In[ ]:


svm_model = SVC(probability=True)
fit_and_score(
    svm_model,
    texture_features
)


# # Using Deep Learning
# Rather than doing deep learning from scratch, we can try a technique called transfer learning. Here we take a pretrained model called VGG16 from the [Visual Geometry Group at Oxford](http://www.robots.ox.ac.uk/~vgg/) (the model itself classifies objects into categories like cat, wolf, airplane that do not interest us), but we can use the model to generate features (a few layers before the end, often called the 'top', shown in blue below, which we leave off). The model is described in detail [here](https://arxiv.org/abs/1409.1556). 
# 
# ![VGG16](https://www.cs.toronto.edu/~frossard/post/vgg16/vgg16.png)

# In[ ]:


from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input
from keras import models, layers
c_model = models.Sequential()
c_model.add(PTModel(include_top=False, 
                    # get the shape of the image
                    input_shape=full_train_df['image'].iloc[0].shape+(3,), 
                    weights='imagenet'))
c_model.add(layers.GlobalAvgPool2D())

def vgg_features(in_df):
    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()
    full_image_stack = np.stack(in_df['image'], 0)
    color_image_stack = np.stack([full_image_stack, full_image_stack, full_image_stack], -1).astype(float)
    pp_color_image_stack = preprocess_input(color_image_stack)
    # add the results to the current matrix
    vgg_features = c_model.predict(pp_color_image_stack)
    return np.concatenate([out_df.values, vgg_features], 1)


# In[ ]:


rf_model = RandomForestClassifier(random_state=2018)
fit_and_score(
    rf_model,
    vgg_features
)


# ## Try using a gradient boosting
# Here we can try using a stronger classifier that interatively improves itself using a technique called [gradient boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/). The technique has proved very successful in Kaggle competitions and could provide good results here as well.

# In[ ]:


from xgboost import XGBClassifier
xg_model = XGBClassifier()
fit_and_score(
    xg_model,
    vgg_features
)


# # Train our own CNN
# Here we train our own CNN rather than using a pretrained VGG model. We build a fairly basic model in the spirit of alex net to apply to the tiles. We train the model on a subset of the data 

# In[ ]:


trn_image, vld_image, trn_label , vld_label = train_test_split(full_train_df['image'], 
                                               full_train_df['opacity'],
                                               test_size=0.25,
                                               random_state=2018)
trn_image = np.stack(trn_image, 0)
vld_image = np.stack(vld_image, 0)


# In[ ]:


out_model = models.Sequential()
out_model.add(layers.Reshape((64, 64, 1), input_shape=trn_image.shape[1:]))
out_model.add(layers.Conv2D(16, (3, 3), padding='valid', activation='relu'))
out_model.add(layers.MaxPool2D((2, 2)))
out_model.add(layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))
out_model.add(layers.MaxPool2D((2, 2)))
out_model.add(layers.Conv2D(64, (3, 3), padding='valid', activation='relu'))
out_model.add(layers.MaxPool2D((2, 2)))
out_model.add(layers.Conv2D(128, (3, 3), padding='valid', activation='relu'))
out_model.add(layers.MaxPool2D((2, 2)))
out_model.add(layers.GlobalAveragePooling2D())
out_model.add(layers.Dense(32, activation='relu'))
out_model.add(layers.Dense(1, activation='sigmoid'))
out_model.compile(optimizer='adam', 
                  loss='binary_crossentropy', 
                  metrics=['binary_accuracy'])
out_model.summary()


# # Visualize the Model
# Here we can visualize the different layers in the model and compare them to what we see in AlexNet
# ![AlexNet](https://www.researchgate.net/profile/Huafeng_Wang4/publication/300412100/figure/fig1/AS:388811231121412@1469711229450/AlexNet-Architecture-To-be-noted-is-copied-2.png)

# In[ ]:


from keras.utils.vis_utils import model_to_dot
from IPython.display import Image
model_rep = model_to_dot(out_model, show_shapes=True)
model_rep.set_rankdir('LR')
Image(model_rep.create_png())


# # Train the Model
# Here we train the model for 100 epochs which should be enough to get a reasonable result. We clear the output afterwards since it is messy and we use a plot to show the results instead

# In[ ]:


from IPython.display import clear_output
fit_results = out_model.fit(trn_image, trn_label, 
                            validation_data=(vld_image, vld_label),
                            epochs=100)
clear_output()


# In[ ]:


fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))
ax1.plot(fit_results.history['loss'], label='Training')
ax1.plot(fit_results.history['val_loss'], label='Validation')
ax1.legend()
ax1.set_title('Loss History')
ax2.plot(100*np.array(fit_results.history['binary_accuracy']), label='Training')
ax2.plot(100*np.array(fit_results.history['val_binary_accuracy']), label='Validation')
ax2.legend()
ax2.set_title('Accuracy History')


# ## Custom CNN Features
# We use the prediction from the custom CNN as an additional feature in our model

# In[ ]:


def custom_cnn_features(in_df):
    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()
    full_image_stack = np.stack(in_df['image'], 0)
    # add the results to the current matrix
    model_pred = out_model.predict(full_image_stack)
    return np.concatenate([out_df.values, model_pred], 1)


# In[ ]:


rf_model = RandomForestClassifier(random_state=2018)
fit_and_score(
    rf_model,
    custom_cnn_features
)


# In[ ]:


svm_model = SVC(probability=True)
fit_and_score(
    svm_model,
    custom_cnn_features
)


# In[ ]:


xg_model = XGBClassifier()
fit_and_score(
    xg_model,
    custom_cnn_features
)


# # Show all of the files we have made
# Here we can see all of the submissions we have made and we can choose the best one to submit to the competition. The scores here could be overfitted and so the best AUC on the validation data MIGHT NOT be the best score in the competition

# In[ ]:


get_ipython().system('ls *.csv')


# In[ ]:




