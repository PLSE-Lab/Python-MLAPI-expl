#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Any results you write to the current directory are saved as output.



# In[ ]:


#Import Libraries
import glob
from keras.models import Sequential, load_model
import numpy as np
import pandas as pd
import keras as k
from keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import matplotlib.pyplot as plt


# In[ ]:


df = pd.read_csv('/kaggle/input/chronic-kidney-disease/new_model.csv')
df.head()


# In[ ]:


df.shape


# In[ ]:


#Data Manipulation: Clean The Data
#Create a list of columns to retain
columns_to_retain = ["Sg", "Al", "Sc", "Hemo",
                          "Wbcc", "Rbcc", "Htn", "Class"]

#Drop the columns that are not in columns_to_retain
df = df.drop([col for col in df.columns if not col in columns_to_retain], axis=1)
    
# Drop the rows with na or missing values
df = df.dropna(axis=0)


# In[ ]:


#Transform non-numeric columns into numerical columns
for column in df.columns:
        if df[column].dtype == np.number:
            continue
        df[column] = LabelEncoder().fit_transform(df[column])


# In[ ]:


df.head()


# In[ ]:


#Data Manipulation: Split & Scale The Data
#Split the data
x = df.drop(["Class"], axis=1)
y = df["Class"]


# In[ ]:


#Feature Scaling
x_scaler = MinMaxScaler()
x_scaler.fit(x)
column_names = x.columns
x[column_names] = x_scaler.transform(x)


# In[ ]:


#Split the data into 80% training and 20% testing 
x_train,  x_test, y_train, y_test = train_test_split(
        x, y, test_size= 0.2, shuffle=True)


# In[ ]:


#Build The model
model = Sequential()
model.add(Dense(256, input_dim=len(X.columns),kernel_initializer=k.initializers.random_normal(seed=13), activation="relu"))
model.add(Dense(1, activation="hard_sigmoid"))


# In[ ]:


#Compile the model
model.compile(loss='binary_crossentropy', 
                  optimizer='adam', metrics=['accuracy'])


# In[ ]:


#Train the model
history = model.fit(x_train, y_train, 
                    epochs=2000, 
                    batch_size=x_train.shape[0]) 


# In[ ]:


#Visualize the models accuracy and loss
plt.plot(history.history["accuracy"])
plt.plot(history.history["loss"])
plt.title("model accuracy & loss")
plt.ylabel("accuracy and loss")
plt.xlabel("epoch")
plt.legend(['accuracy', 'loss'], loc='lower right')
plt.show()


# In[ ]:


#Save the model
model.save("Kidney_Disease.model")


# In[ ]:




