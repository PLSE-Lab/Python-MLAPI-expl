#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# Uncomment and run the commands below if imports fail
# !conda install numpy pytorch torchaudio cpuonly -c pytorch -y
# !pip install matplotlib --upgrade --quiet
# !conda install -c conda-forge librosa

# https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html?fbclid=IwAR2kJhAloxNo8aJMOvV5XI3pmgWFTEBRKD1tgLlJgg8dYFfXiRTXLjfGeqg


# ## Download Music Data
# Download data from data scource and unzip tar file into genres folder 
# 
# !mkdir: for creating  directoty
# 
# wget url : data source url
# 
# tar -xvf tag_file_name -d extracted_dir/  : this command for extract tar zip 

# In[ ]:


get_ipython().system('mkdir genres && wget http://opihi.cs.uvic.ca/sound/genres.tar.gz  && tar -xf genres.tar.gz genres/')


# In[ ]:


get_ipython().system('tar -zxvf genres.tar.gz genres/')
# !tar --help


# In[ ]:


# !rmdir data/input/
# !rm genres.tar.gz
# !rm -rf img_data


# In[ ]:


import torch
import torchaudio
import jovian
import numpy as np
import librosa
import librosa.display
import pandas as pd
import os
from PIL import Image
import pathlib
import matplotlib.pyplot as plt
import torch.nn as nn
import torch.nn.functional as F
# from torchvision.datasets import MNIST
# from torchvision.transforms import ToTensor
# from torchvision.utils import make_grid
from torch.utils.data.dataloader import DataLoader
from torch.utils.data import random_split
get_ipython().run_line_magic('matplotlib', 'inline')


# ## Create Data

# In[ ]:


cmap = plt.get_cmap('inferno') # this is for img color
plt.figure(figsize=(8,8)) # img size
genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split() # all possible  music class
for g in genres:
    pathlib.Path(f'img_data/{g}').mkdir(parents=True, exist_ok=True)
    for filename in os.listdir(f'genres/{g}'):
        songname = f'genres/{g}/{filename}'
#         print(songname)
#         break
        y, sr = librosa.load(songname, mono=True, duration=5)
        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');
        plt.axis('off');
        plt.savefig(f'img_data/{g}/{filename[:-3].replace(".", "")}.png')
        plt.clf()


# In[ ]:


audio_data = 'genres/blues/blues.00093.wav'
x , sr = librosa.load(audio_data)
print(type(x), type(sr))
#<class 'numpy.ndarray'> <class 'int'>print(x.shape, sr)#(94316,) 22050


# In[ ]:


plt.figure(figsize=(14, 5))
librosa.display.waveplot(x, sr=sr)


# In[ ]:


import IPython.display as ipd
ipd.Audio(audio_data)


# ## Spectrogram

# In[ ]:


X = librosa.stft(x)
Xdb = librosa.amplitude_to_db(abs(X))
plt.figure(figsize=(14, 5))
librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')
plt.colorbar()


# In[ ]:


import sklearn
spectral_centroids = librosa.feature.spectral_centroid(x, sr=sr)[0]
spectral_centroids.shape


# In[ ]:


# Computing the time variable for visualization
plt.figure(figsize=(12, 4))
frames = range(len(spectral_centroids))
t = librosa.frames_to_time(frames)
# Normalising the spectral centroid for visualisation
def normalize(x, axis=0):
    return sklearn.preprocessing.minmax_scale(x, axis=axis)
#Plotting the Spectral Centroid along the waveform
librosa.display.waveplot(x, sr=sr, alpha=0.4)
plt.plot(t, normalize(spectral_centroids), color='b')


# ## Spectral Rolloff

# In[ ]:


spectral_rolloff = librosa.feature.spectral_rolloff(x+0.01, sr=sr)[0]
plt.figure(figsize=(12, 4))
librosa.display.waveplot(x, sr=sr, alpha=0.4)
plt.plot(t, normalize(spectral_rolloff), color='r')


# Spectral Bandwidth

# In[ ]:


spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr)[0]
spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=3)[0]
spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(x+0.01, sr=sr, p=4)[0]
plt.figure(figsize=(15, 9))
librosa.display.waveplot(x, sr=sr, alpha=0.4)
plt.plot(t, normalize(spectral_bandwidth_2), color='r')
plt.plot(t, normalize(spectral_bandwidth_3), color='g')
plt.plot(t, normalize(spectral_bandwidth_4), color='y')
plt.legend(('p = 2', 'p = 3', 'p = 4'))


# ## Zero-Crossing Rate

# In[ ]:


x, sr = librosa.load('genres/blues/blues.00093.wav')
#Plot the signal:
plt.figure(figsize=(14, 5))
librosa.display.waveplot(x, sr=sr)
# Zooming in
n0 = 9000
n1 = 9100
plt.figure(figsize=(14, 5))
plt.plot(x[n0:n1])
plt.grid()


# In[ ]:


n0 = 9000
n1 = 9100
plt.figure(figsize=(14, 5))
plt.plot(x[n0:n1])
plt.grid()


# ## Mel-Frequency Cepstral Coefficients(MFCCs)

# In[ ]:


fs = 100
mfccs = librosa.feature.mfcc(x, sr=fs)
print(mfccs.shape)
#Displaying  the MFCCs:
plt.figure(figsize=(15, 7))
librosa.display.specshow(mfccs, sr=sr, x_axis='time')


# In[ ]:


hop_length =10
chromagram = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)
plt.figure(figsize=(15, 5))
librosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')


# In[ ]:


import csv


# In[ ]:


header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'
for i in range(1, 21):
    header += f' mfcc{i}'
header += ' label'
header = header.split()


# In[ ]:


file = open('dataset.csv', 'w', newline='')
with file:
    writer = csv.writer(file)
    writer.writerow(header)
genres = 'blues classical country disco hiphop jazz metal pop reggae rock'.split()
for g in genres:
    for filename in os.listdir(f'genres/{g}'):
        songname = f'genres/{g}/{filename}'
        y, sr = librosa.load(songname, mono=True, duration=30)
        rmse = librosa.feature.rms(y=y)
        chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
        spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)
        spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)
        rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
        zcr = librosa.feature.zero_crossing_rate(y)
        mfcc = librosa.feature.mfcc(y=y, sr=sr)
        to_append = f'{filename} {np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'    
        for e in mfcc:
            to_append += f' {np.mean(e)}'
        to_append += f' {g}'
        file = open('dataset.csv', 'a', newline='')
        with file:
            writer = csv.writer(file)
            writer.writerow(to_append.split())


# In[ ]:


data = pd.read_csv('dataset.csv')
data.head()


# In[ ]:


get_ipython().system('pip install jovian --upgrade --quiet')


# In[ ]:


import jovian


# In[ ]:


jovian.commit(project='music-classification-using-deep-learning-with-pytorch', environment=None)


# In[ ]:




