#!/usr/bin/env python
# coding: utf-8

# # Just like the old saying:
# ### *All happy families resemble each other, while unhappy ones each have their own problems.*
# # So we can assume:
# ### Duplicated questions resemble each other, while unduplicated questions have their own differences.

# Suppose  if A=B and B=C, we assume that A=C
# 
# For example:  if we have this kind of data, and they are duplicated
# 
#     [qid1,qid2]
#     [1,2]
#     [1,3]
#     [11,2]
#     [12,2]
# 
# so we can get [1,2,3,11,12] are duplicated questions, 
# so we can generate more positive training data:
# 
#     [1,2]
#     [1,3]
#     [1,11]
#     [1,12]
#     [2,3]
#     [2,11]
#     [2,12]
#     [3,11]
#     [3,12]
#     [11,12]

# Let's do it

# In[ ]:


import numpy as np
import pandas as pd
from IPython.display import  display
from collections import defaultdict
from itertools import combinations
pd.set_option('display.max_colwidth',-1)


# In[ ]:


train_df=pd.read_csv('../input/train.csv')
train_df.head(2)


# In[ ]:


# only duplicated questions
ddf=train_df[train_df.is_duplicate==1]
print('Duplicated questions shape:',ddf.shape)
ddf.head(2)


# There are 149263 pairs duplicated questions

# In[ ]:


# get all duplicated questions
clean_ddf1=ddf[['qid1','question1']].drop_duplicates()
clean_ddf1.columns=['qid','question']
clean_ddf2=ddf[['qid2','question2']].drop_duplicates()
clean_ddf2.columns=['qid','question']
all_dqdf=clean_ddf1.append(clean_ddf2,ignore_index=True)
print(all_dqdf.shape)
all_dqdf.head(2)


# There are 172286 questions in the above df

# In[ ]:


# groupby qid1, and then we get all the combinations of id in each group
dqids12=ddf[['qid1','qid2']]
df12list=dqids12.groupby('qid1', as_index=False)['qid2'].agg({'dlist':(lambda x: list(x))})
print(len(df12list))
d12list=df12list.values
d12list=[[i]+j for i,j in d12list]
# get all the combinations of id, like (id1,id2)...
d12ids=set()
for ids in d12list:
    ids_len=len(ids)
    for i in range(ids_len):
        for j in range(i+1,ids_len):
            d12ids.add((ids[i],ids[j]))
print(len(d12ids))


# In[ ]:


# the same operation of qid2
dqids21=ddf[['qid2','qid1']]
display(dqids21.head(2))
df21list=dqids21.groupby('qid2', as_index=False)['qid1'].agg({'dlist':(lambda x: list(x))})
print(len(df21list))
ids2=df21list.qid2.values
d21list=df21list.values
d21list=[[i]+j for i,j in d21list]
d21ids=set()
for ids in d21list:
    ids_len=len(ids)
    for i in range(ids_len):
        for j in range(i+1,ids_len):
            d21ids.add((ids[i],ids[j]))
len(d21ids)


# In[ ]:


# merge two set
dids=list(d12ids | d21ids)
len(dids)


# In[ ]:


# let's define union-find function
def indices_dict(lis):
    d = defaultdict(list)
    for i,(a,b) in enumerate(lis):
        d[a].append(i)
        d[b].append(i)
    return d

def disjoint_indices(lis):
    d = indices_dict(lis)
    sets = []
    while len(d):
        que = set(d.popitem()[1])
        ind = set()
        while len(que):
            ind |= que 
            que = set([y for i in que 
                         for x in lis[i] 
                         for y in d.pop(x, [])]) - ind
        sets += [ind]
    return sets

def disjoint_sets(lis):
    return [set([x for i in s for x in lis[i]]) for s in disjoint_indices(lis)]


# In[ ]:


# split data into groups, so that each question in each group are duplicated
did_u=disjoint_sets(dids)
new_dids=[]
for u in did_u:
    new_dids.extend(list(combinations(u,2)))
len(new_dids)


# In[ ]:


new_ddf=pd.DataFrame(new_dids,columns=['qid1','qid2'])
print('New duplicated shape:',new_ddf.shape)
display(new_ddf.head(2))


# In[ ]:


# merge with all_dqdf to get question1 description
new_ddf=new_ddf.merge(all_dqdf,left_on='qid1',right_on='qid',how='left')
new_ddf.drop('qid',inplace=True,axis=1)
new_ddf.columns=['qid1','qid2','question1']
new_ddf.drop_duplicates(inplace=True)
print(new_ddf.shape)
new_ddf.head(2)


# In[ ]:


# the same operation with qid2
new_ddf=new_ddf.merge(all_dqdf,left_on='qid2',right_on='qid',how='left')
new_ddf.drop('qid',inplace=True,axis=1)
new_ddf.columns=['qid1','qid2','question1','question2']
new_ddf.drop_duplicates(inplace=True)
print(new_ddf.shape)
new_ddf.head(2)


# In[ ]:


# is_duplicate flag
new_ddf['is_duplicate']=1
new_ddf.head(2)


# In[ ]:


# let random select 10 rows to check the result
new_ddf.sample(10)


# ### It seemed quite make sense

# In[ ]:


# the orininal duplicated pairs count:
print(len(all_dqdf))
# after we generate more data, then the duplicated pairs count:
print(len(new_ddf))


# In[ ]:




