#!/usr/bin/env python
# coding: utf-8

# In[ ]:


# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir("../input"))

# Any results you write to the current directory are saved as output.


# In[ ]:


import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
import tensorflow as tf
import keras
import glob
import cv2

import os
print(os.listdir("../input"))


# In[ ]:


fruit_images = []
labels = [] 
for fruit_dir_path in glob.glob("../input/*/fruits-360/Training/*"):
    fruit_label = fruit_dir_path.split("/")[-1]
    for image_path in glob.glob(os.path.join(fruit_dir_path, "*.jpg")):
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        
        image = cv2.resize(image, (45, 45))
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        fruit_images.append(image)
        labels.append(fruit_label)
fruit_images = np.array(fruit_images)
labels = np.array(labels)


# In[ ]:


label_to_id_dict = {v:i for i,v in enumerate(np.unique(labels))}
id_to_label_dict = {v: k for k, v in label_to_id_dict.items()}


# In[ ]:


id_to_label_dict


# In[ ]:


label_ids = np.array([label_to_id_dict[x] for x in labels])


# In[ ]:





# In[ ]:


fruit_images.shape, label_ids.shape, labels.shape


# In[ ]:


validation_fruit_images = []
validation_labels = [] 
for fruit_dir_path in glob.glob("../input/*/fruits-360/Test/*"):
    fruit_label = fruit_dir_path.split("/")[-1]
    for image_path in glob.glob(os.path.join(fruit_dir_path, "*.jpg")):
        image = cv2.imread(image_path, cv2.IMREAD_COLOR)
        
        image = cv2.resize(image, (45, 45))
        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        validation_fruit_images.append(image)
        validation_labels.append(fruit_label)
validation_fruit_images = np.array(validation_fruit_images)
validation_labels = np.array(validation_labels)


# In[ ]:


validation_label_ids = np.array([label_to_id_dict[x] for x in validation_labels])


# In[ ]:


validation_fruit_images.shape, validation_label_ids.shape


# In[ ]:


X_train, X_test = fruit_images, validation_fruit_images
Y_train, Y_test = label_ids, validation_label_ids


# In[ ]:



#Normalize color values to between 0 and 1
X_train = X_train/255
X_test = X_test/255

#Make a flattened version for some of our models
X_flat_train = X_train.reshape(X_train.shape[0], 45*45*3)
X_flat_test = X_test.reshape(X_test.shape[0], 45*45*3)


# In[ ]:


from sklearn.preprocessing import LabelEncoder, OneHotEncoder


# In[ ]:


onehotencoder = OneHotEncoder(categorical_features=[0])


# In[ ]:


len(Y_test)


# In[ ]:


Y_train=Y_train.reshape(1,47585)


# In[ ]:


Y_test=Y_test.reshape(1,15975)


# In[ ]:


Y_train=onehotencoder.fit_transform(Y_train.T).toarray()
Y_test=onehotencoder.transform(Y_test.T).toarray()


# In[ ]:






print('Original Sizes:', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)
print('Flattened:', X_flat_train.shape, X_flat_test.shape)


# In[ ]:


Y_train.shape


# In[ ]:


Y_test.shape


# In[ ]:





# In[ ]:





# In[ ]:


print(X_train[0].shape)
plt.imshow(X_train[0])
plt.show()


# In[ ]:


from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D
from keras.layers import LSTM, Input, TimeDistributed
from keras.models import Model
from keras.optimizers import RMSprop, SGD

# Import the backend
from keras import backend as K


# In[ ]:


model_dense = Sequential()

# Add dense layers to create a fully connected MLP
# Note that we specify an input shape for the first layer, but only the first layer.
# Relu is the activation function used
model_dense.add(Dense(128, activation='relu', input_shape=(X_flat_train.shape[1],)))
# Dropout layers remove features and fight overfitting
model_dense.add(Dropout(0.1))
model_dense.add(Dense(100, activation='relu'))
model_dense.add(Dropout(0.1))
# End with a number of units equal to the number of classes we have for our outcome
model_dense.add(Dense(93, activation='softmax'))

model_dense.summary()

# Compile the model to put it all together.
model_dense.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(),
              metrics=['accuracy'])

history_dense = model_dense.fit(X_flat_train, Y_train,
                          batch_size=128,
                          epochs=50,
                          verbose=1,
                          validation_data=(X_flat_test, Y_test))
score = model_dense.evaluate(X_flat_test, Y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])


# In[ ]:


import os
from keras.models import model_from_json

# serialize model to JSON
model_json = model_dense.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model_dense.save_weights("model.h5")
print("Saved model to disk")


# In[ ]:


# load json and create model
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model.h5")
print("Loaded model from disk")


# In[ ]:


from PIL import Image
import numpy as np
from skimage import transform
def load(filename):
   np_image = Image.open(filename)
   np_image = np.array(np_image).astype('float32')/255
   np_image = transform.resize(np_image, (256, 256, 3))
   np_image = np.expand_dims(np_image, axis=0)
   return np_image

image = load('../input/fruits-360_dataset/fruits-360/Test/Lemon/r_28_100.jpg')
 
loaded_model.predict(image)


# In[ ]:


import pickle


# In[ ]:


with open("mypickle.pickle","wb") as f:     #to save model in harddisk as binary file
    pickle.dump(model_dense,f)


# In[ ]:


with open("mypickle.pickle","rb") as f:     #tto callback the model
    model=pickle.load(f)


# In[ ]:





# In[ ]:





# In[ ]:





# In[ ]:


os.listdir("../input/fruits-360_dataset/fruits-360/Test/Lemonr_28_100.jpg")


# In[ ]:


image = cv2.imread("../input/fruits-360_dataset/fruits-360/Test/Lemon/r_28_100.jpg", cv2.IMREAD_COLOR)
image = cv2.resize(image, (45, 45))
image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
image=np.array(image)
image = image/255
image=np.array([image])
image_flat = image.reshape(image.shape[0], 45*45*3)


# In[ ]:





# In[ ]:


pred=model.predict(image_flat)


# In[ ]:


np.argmax(pred)


# In[ ]:




